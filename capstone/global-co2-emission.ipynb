{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "annual-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import os\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import plotly.express as px\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.serializers import IdentitySerializer\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-yukon",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "earned-stewart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso_code</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>co2</th>\n",
       "      <th>co2_growth_prct</th>\n",
       "      <th>co2_growth_abs</th>\n",
       "      <th>consumption_co2</th>\n",
       "      <th>trade_co2</th>\n",
       "      <th>trade_co2_share</th>\n",
       "      <th>co2_per_capita</th>\n",
       "      <th>...</th>\n",
       "      <th>ghg_per_capita</th>\n",
       "      <th>methane</th>\n",
       "      <th>methane_per_capita</th>\n",
       "      <th>nitrous_oxide</th>\n",
       "      <th>nitrous_oxide_per_capita</th>\n",
       "      <th>primary_energy_consumption</th>\n",
       "      <th>energy_per_capita</th>\n",
       "      <th>energy_per_gdp</th>\n",
       "      <th>population</th>\n",
       "      <th>gdp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1949</td>\n",
       "      <td>0.015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7663783.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1950</td>\n",
       "      <td>0.084</td>\n",
       "      <td>475.000</td>\n",
       "      <td>0.070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7752000.0</td>\n",
       "      <td>1.949480e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1951</td>\n",
       "      <td>0.092</td>\n",
       "      <td>8.696</td>\n",
       "      <td>0.007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7840000.0</td>\n",
       "      <td>2.006385e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1952</td>\n",
       "      <td>0.092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7936000.0</td>\n",
       "      <td>2.074235e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1953</td>\n",
       "      <td>0.106</td>\n",
       "      <td>16.000</td>\n",
       "      <td>0.015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8040000.0</td>\n",
       "      <td>2.201546e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23703</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2015</td>\n",
       "      <td>12.170</td>\n",
       "      <td>1.653</td>\n",
       "      <td>0.198</td>\n",
       "      <td>13.308</td>\n",
       "      <td>1.138</td>\n",
       "      <td>9.350</td>\n",
       "      <td>0.881</td>\n",
       "      <td>...</td>\n",
       "      <td>4.885</td>\n",
       "      <td>11.87</td>\n",
       "      <td>0.859</td>\n",
       "      <td>6.68</td>\n",
       "      <td>0.484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13815000.0</td>\n",
       "      <td>2.503057e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23704</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2016</td>\n",
       "      <td>10.815</td>\n",
       "      <td>-11.139</td>\n",
       "      <td>-1.356</td>\n",
       "      <td>12.171</td>\n",
       "      <td>1.356</td>\n",
       "      <td>12.542</td>\n",
       "      <td>0.771</td>\n",
       "      <td>...</td>\n",
       "      <td>4.703</td>\n",
       "      <td>11.92</td>\n",
       "      <td>0.850</td>\n",
       "      <td>6.55</td>\n",
       "      <td>0.467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14030000.0</td>\n",
       "      <td>2.515176e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23705</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2017</td>\n",
       "      <td>10.247</td>\n",
       "      <td>-5.251</td>\n",
       "      <td>-0.568</td>\n",
       "      <td>11.774</td>\n",
       "      <td>1.527</td>\n",
       "      <td>14.902</td>\n",
       "      <td>0.720</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14237000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23706</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2018</td>\n",
       "      <td>11.341</td>\n",
       "      <td>10.674</td>\n",
       "      <td>1.094</td>\n",
       "      <td>12.815</td>\n",
       "      <td>1.475</td>\n",
       "      <td>13.006</td>\n",
       "      <td>0.785</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14439000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23707</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2019</td>\n",
       "      <td>10.374</td>\n",
       "      <td>-8.521</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.708</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14645000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23708 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      iso_code      country  year     co2  co2_growth_prct  co2_growth_abs  \\\n",
       "0          AFG  Afghanistan  1949   0.015              NaN             NaN   \n",
       "1          AFG  Afghanistan  1950   0.084          475.000           0.070   \n",
       "2          AFG  Afghanistan  1951   0.092            8.696           0.007   \n",
       "3          AFG  Afghanistan  1952   0.092              NaN             NaN   \n",
       "4          AFG  Afghanistan  1953   0.106           16.000           0.015   \n",
       "...        ...          ...   ...     ...              ...             ...   \n",
       "23703      ZWE     Zimbabwe  2015  12.170            1.653           0.198   \n",
       "23704      ZWE     Zimbabwe  2016  10.815          -11.139          -1.356   \n",
       "23705      ZWE     Zimbabwe  2017  10.247           -5.251          -0.568   \n",
       "23706      ZWE     Zimbabwe  2018  11.341           10.674           1.094   \n",
       "23707      ZWE     Zimbabwe  2019  10.374           -8.521          -0.966   \n",
       "\n",
       "       consumption_co2  trade_co2  trade_co2_share  co2_per_capita  ...  \\\n",
       "0                  NaN        NaN              NaN           0.002  ...   \n",
       "1                  NaN        NaN              NaN           0.011  ...   \n",
       "2                  NaN        NaN              NaN           0.012  ...   \n",
       "3                  NaN        NaN              NaN           0.012  ...   \n",
       "4                  NaN        NaN              NaN           0.013  ...   \n",
       "...                ...        ...              ...             ...  ...   \n",
       "23703           13.308      1.138            9.350           0.881  ...   \n",
       "23704           12.171      1.356           12.542           0.771  ...   \n",
       "23705           11.774      1.527           14.902           0.720  ...   \n",
       "23706           12.815      1.475           13.006           0.785  ...   \n",
       "23707              NaN        NaN              NaN           0.708  ...   \n",
       "\n",
       "       ghg_per_capita  methane  methane_per_capita  nitrous_oxide  \\\n",
       "0                 NaN      NaN                 NaN            NaN   \n",
       "1                 NaN      NaN                 NaN            NaN   \n",
       "2                 NaN      NaN                 NaN            NaN   \n",
       "3                 NaN      NaN                 NaN            NaN   \n",
       "4                 NaN      NaN                 NaN            NaN   \n",
       "...               ...      ...                 ...            ...   \n",
       "23703           4.885    11.87               0.859           6.68   \n",
       "23704           4.703    11.92               0.850           6.55   \n",
       "23705             NaN      NaN                 NaN            NaN   \n",
       "23706             NaN      NaN                 NaN            NaN   \n",
       "23707             NaN      NaN                 NaN            NaN   \n",
       "\n",
       "       nitrous_oxide_per_capita  primary_energy_consumption  \\\n",
       "0                           NaN                         NaN   \n",
       "1                           NaN                         NaN   \n",
       "2                           NaN                         NaN   \n",
       "3                           NaN                         NaN   \n",
       "4                           NaN                         NaN   \n",
       "...                         ...                         ...   \n",
       "23703                     0.484                         NaN   \n",
       "23704                     0.467                         NaN   \n",
       "23705                       NaN                         NaN   \n",
       "23706                       NaN                         NaN   \n",
       "23707                       NaN                         NaN   \n",
       "\n",
       "       energy_per_capita  energy_per_gdp  population           gdp  \n",
       "0                    NaN             NaN   7663783.0           NaN  \n",
       "1                    NaN             NaN   7752000.0  1.949480e+10  \n",
       "2                    NaN             NaN   7840000.0  2.006385e+10  \n",
       "3                    NaN             NaN   7936000.0  2.074235e+10  \n",
       "4                    NaN             NaN   8040000.0  2.201546e+10  \n",
       "...                  ...             ...         ...           ...  \n",
       "23703                NaN             NaN  13815000.0  2.503057e+10  \n",
       "23704                NaN             NaN  14030000.0  2.515176e+10  \n",
       "23705                NaN             NaN  14237000.0           NaN  \n",
       "23706                NaN             NaN  14439000.0           NaN  \n",
       "23707                NaN             NaN  14645000.0           NaN  \n",
       "\n",
       "[23708 rows x 55 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# source: https://github.com/owid/co2-data\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/owid/co2-data/master/owid-co2-data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hidden-relaxation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23708 entries, 0 to 23707\n",
      "Data columns (total 55 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   iso_code                             20930 non-null  object \n",
      " 1   country                              23708 non-null  object \n",
      " 2   year                                 23708 non-null  int64  \n",
      " 3   co2                                  23170 non-null  float64\n",
      " 4   co2_growth_prct                      21910 non-null  float64\n",
      " 5   co2_growth_abs                       22017 non-null  float64\n",
      " 6   consumption_co2                      3350 non-null   float64\n",
      " 7   trade_co2                            3318 non-null   float64\n",
      " 8   trade_co2_share                      3318 non-null   float64\n",
      " 9   co2_per_capita                       22383 non-null  float64\n",
      " 10  consumption_co2_per_capita           3350 non-null   float64\n",
      " 11  share_global_co2                     23103 non-null  float64\n",
      " 12  cumulative_co2                       23578 non-null  float64\n",
      " 13  share_global_cumulative_co2          23578 non-null  float64\n",
      " 14  co2_per_gdp                          14918 non-null  float64\n",
      " 15  consumption_co2_per_gdp              3088 non-null   float64\n",
      " 16  co2_per_unit_energy                  6743 non-null   float64\n",
      " 17  cement_co2                           12182 non-null  float64\n",
      " 18  coal_co2                             16991 non-null  float64\n",
      " 19  flaring_co2                          4302 non-null   float64\n",
      " 20  gas_co2                              8693 non-null   float64\n",
      " 21  oil_co2                              19711 non-null  float64\n",
      " 22  other_industry_co2                   1563 non-null   float64\n",
      " 23  cement_co2_per_capita                12153 non-null  float64\n",
      " 24  coal_co2_per_capita                  16471 non-null  float64\n",
      " 25  flaring_co2_per_capita               4301 non-null   float64\n",
      " 26  gas_co2_per_capita                   8665 non-null   float64\n",
      " 27  oil_co2_per_capita                   19393 non-null  float64\n",
      " 28  other_co2_per_capita                 1563 non-null   float64\n",
      " 29  share_global_coal_co2                16991 non-null  float64\n",
      " 30  share_global_oil_co2                 19711 non-null  float64\n",
      " 31  share_global_gas_co2                 8693 non-null   float64\n",
      " 32  share_global_flaring_co2             4302 non-null   float64\n",
      " 33  share_global_cement_co2              12182 non-null  float64\n",
      " 34  cumulative_coal_co2                  18552 non-null  float64\n",
      " 35  cumulative_oil_co2                   19963 non-null  float64\n",
      " 36  cumulative_gas_co2                   9187 non-null   float64\n",
      " 37  cumulative_flaring_co2               4933 non-null   float64\n",
      " 38  cumulative_cement_co2                12563 non-null  float64\n",
      " 39  share_global_cumulative_coal_co2     18552 non-null  float64\n",
      " 40  share_global_cumulative_oil_co2      19963 non-null  float64\n",
      " 41  share_global_cumulative_gas_co2      9187 non-null   float64\n",
      " 42  share_global_cumulative_flaring_co2  4933 non-null   float64\n",
      " 43  share_global_cumulative_cement_co2   12563 non-null  float64\n",
      " 44  total_ghg                            5208 non-null   float64\n",
      " 45  ghg_per_capita                       5155 non-null   float64\n",
      " 46  methane                              5211 non-null   float64\n",
      " 47  methane_per_capita                   5157 non-null   float64\n",
      " 48  nitrous_oxide                        5211 non-null   float64\n",
      " 49  nitrous_oxide_per_capita             5157 non-null   float64\n",
      " 50  primary_energy_consumption           6044 non-null   float64\n",
      " 51  energy_per_capita                    6044 non-null   float64\n",
      " 52  energy_per_gdp                       6044 non-null   float64\n",
      " 53  population                           21071 non-null  float64\n",
      " 54  gdp                                  13002 non-null  float64\n",
      "dtypes: float64(52), int64(1), object(2)\n",
      "memory usage: 9.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# data info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "disciplinary-means",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/ipykernel/__main__.py:3: FutureWarning:\n",
      "\n",
      "The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1750-12-31</th>\n",
       "      <td>46.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751-12-31</th>\n",
       "      <td>46.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752-12-31</th>\n",
       "      <td>46.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753-12-31</th>\n",
       "      <td>46.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754-12-31</th>\n",
       "      <td>46.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-31</th>\n",
       "      <td>123813.289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31</th>\n",
       "      <td>123890.716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>125438.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>127746.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>127568.915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   co2\n",
       "1750-12-31      46.755\n",
       "1751-12-31      46.755\n",
       "1752-12-31      46.770\n",
       "1753-12-31      46.770\n",
       "1754-12-31      46.790\n",
       "...                ...\n",
       "2015-12-31  123813.289\n",
       "2016-12-31  123890.716\n",
       "2017-12-31  125438.734\n",
       "2018-12-31  127746.944\n",
       "2019-12-31  127568.915\n",
       "\n",
       "[270 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group co2 feature by year\n",
    "ts = df[['year', 'co2']].groupby('year').sum()\n",
    "ts.index = pd.date_range(start=pd.datetime(ts.index.min(), 1, 1), periods=270, freq='A')\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "automated-refrigerator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4AAAAD4CAYAAAC9rYhmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdd3xV9f3H8dfnZm8ghBlG2HuGYZ2tFnFUtLWKdVDFUbG1tj9b9dehbW1/Wm1ttWqLE60Kjqo4KuJqXUwBWSJhhxkSMsi+935/f+QEL5BASEJuxvv5eNxHzv2c7znfz7mcB7mffM/5HnPOISIiIiIiIq2fL9wJiIiIiIiISNNQASgiIiIiItJGqAAUERERERFpI1QAioiIiIiItBEqAEVERERERNqIyHAn0Ng6duzoevfuHe40REREREREwmLp0qV7nXNpNa1rdQVg7969WbJkSbjTEBERERERCQsz21LbOl0CKiIiIiIi0kaoABQREREREWkjVACKiIiIiIi0Ea3uHsCaVFZWkp2dTVlZWbhTEQEgNjaW9PR0oqKiwp2KiIiIiLQhbaIAzM7OJikpid69e2Nm4U5H2jjnHLm5uWRnZ5ORkRHudERERESkDWkTl4CWlZWRmpqq4k+aBTMjNTVVI9IiIiIi0uTaRAEIqPiTZkXno4iIiIiEQ5u4BFRERERERKS1emvVLrbmFZOaEEPHpJgjtlUBKCIiIiIi0kI9v3gbP3/p8zq3VwEoIiIiIiLSAv33yxxue3klpwxI4/6po9hXUsne/eWMv7v2bVQAtgCvvPIKb7zxBnv27OGGG25g0qRJ4U5JRERERETCaO3OQmY88xn9OyXy4PdGkxQbRbv4aDI6JhxxuzYzCUxz8cILLzBhwgRGjBhBv379+M1vfgPASy+9xIQJExg5ciSZmZnMmzfvwDbnn38+jzzyCE8++SRz5sw5Lnl97Wtfa5JtjqfNmzczbNiwcKdxmDvuuIN777033GmIiIiISCuxbOs+pj2+iMSYSJ64chxJsXV/trRGAJvQrFmzeOCBB3jllVdIT09n//79PPzwwzz77LM88MADvPrqq3Tp0oX169dz8skns3jxYnr06HFg+zvvvJMbbrjhuOT2ySefNMk2LYlzDuccPp/+TiIiIiIi4eec4+kFW/jd62vonBzLY9PG0TUl7pj2oW+2TaSwsJCf/vSnPP/886SnpwOQmJjIjBkzuPXWW3n++efp0qULAP379+e0007j3XffBar+oW+55RbOOussxowZU+P+//nPfzJ+/HhGjRrFddddRyAQYPPmzQwaNIirr76aYcOGcemll/LOO+9w4okn0r9/fxYtWnRg+8TERACKi4s555xzGDlyJMOGDWPOnDk1xkK3Afjzn//MsGHDGDZsGH/5y1+AqhG5wYMHc8011zB06FAmTZpEaWlprfs7FjX1B+D3+5k2bRojRozgwgsvpKSkpNb+avvMBg8ezIwZMxgzZgzTp0/noYceOrD/O+64gz/96U+1bl/t97//PQMHDuSMM85g3bp1x3x8IiIiItL2OOfYnl/K+1/s4fXPd/DCkm089elm/vGfDfzlnS+55qml/PrV1ZzcP43Xf3QSA7skHXMfGgFsIi+//DITJkygT58+B8Vnz57NmDFjDhrpA4iJiaGgoACABx54gHfeeYeCggKysrL4wQ9+cFDbtWvXMmfOHD7++GOioqKYMWMGzzzzDKeccgpZWVm88MILzJw5k3HjxvHss8/y0UcfMXfuXP7whz/wyiuvHLSvt956i27duvHGG28AUFBQUGMs1NKlS3niiSdYuHAhzjkmTJjAqaeeSvv27Vm/fj3PPfccjzzyCBdddBEvvfQScXFxR9zf0Rypv3Xr1vHYY49x4oknctVVV/HQQw+RkZFxWH9H+szWrVvHE088wUMPPcSyZcu46aabmDFjBgDPP/88b731Vq3bX3HFFSxdupTZs2ezbNky/H4/Y8aMYezYscd0jCIiIiLSulX4gyzfls/m3GK25Bbz5e79LN+WT05Rea3bJERHcPOkAcw4rR8+X/2eK93mCsDfvLaaNTsKG3WfQ7olc/u3hh6xzerVqxk1atRh8VWrVjFy5MjD4itWrGDatGkA3Hjjjdx444217vvdd99l6dKljBs3DoDS0lI6derEKaecQkZGBsOHDwdg6NChnH766ZgZw4cPZ/PmzYfta/jw4dx8883ccsstnHvuuZx88sk1xkJ99NFHXHDBBSQkVN1w+u1vf5sPP/yQ8847j4yMjAPHPXbsWDZv3sxFF110xP0dzZH669GjByeeeCIAl112Gffffz/nnXfeYf09/fTTtX5mvXr1YuLEiQCMHj2aPXv2sGPHDnJycmjfvj09e/bkb3/7W43bA3z44YdccMEFxMfHA3Deeecd0/GJiIiISOuWV1zBlU8sYkV21UBIhM/o1SGek/p1ZHTPdgztlkxybBSxURHERUcQF1X1qm/RF6rNFYDhkpCQQGlp6WHxlJQUyssPrvI//fRTCgsLOfXUU+u0b+cc06ZN4//+7/8Oim/evJmYmK8eBOnz+Q689/l8+P3+w/Y1YMAAli5dyptvvsltt93GpEmT+PWvf11jLLT/2oT2HxERQWlpaa19hHrwwQd55JFHAHjzzTfp1q1bnfozs8Pe19Rf+/bta/3MqgvLahdeeCEvvvgiu3btYurUqQdyqGn72vIQEREREQHYkV/K5Y8tJHtfKX+8cAQTMjrQrV0cURFNdHde9UQXtb2Ax4E9wKqQ2D3AF8DnwMtAu5B1twFZwDrgzJD4ZC+WBdwaEs8AFgLrgTlAtBeP8d5neet7Hy1X5xxjx451h1qzZs1hsaa2aNEi16dPH7dr1y7nnHNlZWVu5syZbvHixa5Pnz5uz549zjnn1q1b54YMGeI++OCDOu979erVrl+/fm737t3OOedyc3Pd5s2b3aZNm9zQoUMPtJs2bZp74YUXnHPusHUJCQnOOee2b9/uSktLnXPOvfzyy27KlCk1xkK3Wbp0qRs+fLgrLi52+/fvd0OHDnWfffbZYX3cc8897vbbb691f3V1pP4A98knnzjnnLv66qvdvffeW2N/df3MnHNu1apV7oQTTnD9+/d3O3bsOOJnHppfSUmJKywsdP369XP33HPPYcfRHM5LEREREWk6WXuK3Al/eMcN+/VbbsGGvcetH2CJq6VeqssI4JPA34CnQmLzgducc34zu9sr+m4xsyHAVGAo0A14x8wGeNs8CHwTyAYWm9lc59wa4G7gPufcbDP7OzAdeNj7uc8518/MpnrtLq5Dvs3SuHHjuOOOOzjzzDMJBAL4/X4uu+wyMjMz+dWvfnXg0syUlBT+/ve/H9NlkUOGDOHOO+9k0qRJBINBoqKiePDBBw9MKnMsVq5cyc9+9jN8Ph9RUVE8/PDDNcZCjRkzhu9///uMHz8egKuvvprRo0fXeIlpbX0ciyP1N3jwYGbNmsV1111H//79uf766/nwww8P6+9YPrOhQ4dSVFRE9+7d6dq1K1D7Z96rVy/GjBnDxRdfzKhRo+jVq9cxX+IqIiIiIq1PhT/IdU8vpdwf5LlrJzKse0pY8jB3hMvpDjQy6w287pw77CFrZnYBcKFz7lIzuw3AOfd/3rp5wB1e0zucc2d68du82F1ADtDFKyZPqG5Xva1z7lMziwR2AWnuKAlnZma6JUuWHBRbu3YtgwcPPupxijQlnZciIiIibceD72dxz7x1PPH9cXx9UKfj2peZLXXOZda0rjEuNL0K+Le33B3YFrIu24vVFk8F8p1z/kPiB+3LW1/gtT+MmV1rZkvMbElOTk6DD0hERERERKSxbMsr4YH31jN5aJfjXvwdTYMKQDP7BeAHnqkO1dDM1SN+pH0dHnRupnMu0zmXmZaWduSkRUREREREmtBvXluNz4xff2tIuFOpfwFoZtOAc4FLQy7LzAZCH2iXDuw4Qnwv0M67xDM0ftC+vPUpQF598xUREREREWlqb6/exTtr93DTGf3p1i4u3OnUrwA0s8nALcB5zrmSkFVzgalmFmNmGUB/YBGwGOhvZhlmFk3VRDFzvcLxfeBCb/tpwKsh+5rmLV8IvHe0+/+OpAGbijQ6nY8iIiIirZ9zjj/OW8eAzolceWJGuNMB6lAAmtlzwKfAQDPLNrPpVM0KmgTMN7Pl3uydOOdWA88Da4C3gBuccwHvHr4fAvOAtcDzXluoKiR/amZZVN3j95gXfwxI9eI/BW6t70HGxsaSm5urL93SLDjnyM3NJTY2NtypiIiIiMhxtGp7IVl79nPliRlN95y/o6jTLKAtSU2zgFZWVpKdnU1ZWVmYshI5WGxsLOnp6URFRYU7FRERERE5Tn73+hqe/nQLi39xBinxTfe970izgNblOYAtXlRUFBkZzWPIVUREREREWr9A0PHaih2cNjCtSYu/o2ke45AiIiIiIiIt2La8EioDwQPvP92Qy56ics4f3f0IWzU9FYAiIiIiIiIN8NLSbE69531mPPMZwWDVLXavLN9OUkwk3wjzc/8OpQJQRERERESknuYs3srNL66gR4d45q/ZzZ/nf0lZZYC3Vu1i8rAuxEZFhDvFg7SJewBFREREREQa2z8XbOGXr6zilAFpzLx8LHfMXc3f3s9i274S9pf7mTKqeV3+CSoARUREREREjtl7X+zml6+s4vRBnXjw0jHERkXw2ynD2JhTzKvLd9ApKYYT+qaGO83D6BJQERERERGRY7CnsIybX/icQV2SDhR/ANGRPh6+bAyDuiRx5YkZRPgszJkeTiOAIiIiIiIidRQMOv7nhRWUVPj52/cmHnaPX2piDP/+8cmYNb/iDzQCKCIiIiIiUmePfrSRD9fv5dfnDqVfp6Qa2zTX4g9UAIqIiIiIiNTJmh2F3DNvHZOHduGS8T3CnU69qAAUERERERE5ikDQcdu/PiclLoq7vjO8WY/yHYkKQBERERERkaN4+tPNrMgu4FfnDqFdfHS406k3FYAiIiIiIiJHsCO/lHvmreOUAWmcN7JbuNNpEBWAIiIiIiIiR3D73NUEnOP35w9rsZd+VlMBKCIiIiIiUos3V+5k/prd3HTGAHp0iA93Og2mAlBERERERKQGewrL+N+XVzK8ewrTT8oIdzqNQgWgiIiIiIjIIZxz/OzFzymrDHDfxaOIimgdpVPrOAoREREREZFG9M+FW/nPlzn879mD6dcpMdzpNBoVgCIiIiIiIiE25uzn92+s4ZQBaVw+sVe402lUKgBFRERERERC3P3WF0T5fNxz4YgWP+vnoVQAioiIiIiIeL7YVci81bu58sTedE6ODXc6jU4FoIiIiIiIiOdv72WREB3BVa1k1s9DHbUANLPHzWyPma0KiXUws/lmtt772d6Lm5ndb2ZZZva5mY0J2Waa1369mU0LiY81s5XeNvebN8ZaWx8iIiIiIiLHQ9ae/byxcieXn9CbdvHR4U7nuKjLCOCTwORDYrcC7zrn+gPveu8BzgL6e69rgYehqpgDbgcmAOOB20MKuoe9ttXbTT5KHyIiIiIiIo3uofeziIn0cfXJrXP0D+pQADrn/gvkHRKeAszylmcB54fEn3JVFgDtzKwrcCYw3zmX55zbB8wHJnvrkp1znzrnHPDUIfuqqQ8REREREZFGtSW3mFdX7ODSCb3omBgT7nSOm/reA9jZObcTwPvZyYt3B7aFtMv2YkeKZ9cQP1IfhzGza81siZktycnJqechiYiIiIhIW/X3/2wgwmdcd0qfcKdyXDX2JDA1zZHq6hE/Js65mc65TOdcZlpa2rFuLiIiIiIibdjuwjJeWrqdizLT6dQKZ/4MVd8CcLd3+Sbezz1ePBvoEdIuHdhxlHh6DfEj9SEiIiIiItJoHv9oE/5gkGtP7hvuVI67+haAc4HqmTynAa+GxK/wZgOdCBR4l2/OAyaZWXtv8pdJwDxvXZGZTfRm/7zikH3V1IeIiIiIiEijKCit5JmFWzlnRDd6psaHO53jLvJoDczsOeA0oKOZZVM1m+ddwPNmNh3YCnzXa/4mcDaQBZQAVwI45/LM7HfAYq/db51z1RPLXE/VTKNxwL+9F0foQ0REREREpFH8c8EW9pf7+cGprfvev2pWNflm65GZmemWLFkS7jRERERERKSZK6sMcNLd7zG0Wwqzrhof7nQajZktdc5l1rSusSeBERERERERaRHmLN7G3v0VXH9a67/3r5oKQBERERERaXPmrtjBnW+sYXxGByZkdAh3Ok1GBaCIiIiIiLQpj364kRufW8bonu155IpMquajbBuOOgmMiIiIiIhIa7C7sIz75n/J7MXbOHt4F/580ShioyLCnVaTUgEoIiIiIiKt2o78Uh7+YANzlmwjEHRcc3IGt541mAhf2xn5q6YCUEREREREWq0NOfv59kOfUFLh58KxPbj+1L5t4nl/tVEBKCIiIiIirdK+4gqmP7mYSJ/x9k9OJaNjQrhTCjsVgCIiIiIi0upU+INc/8xSduSX8dy1E1T8eVQAioiIiIhIq1Jc7udXr65iwcY8/nLxKMb2ajuPeTgaFYAiIiIiItJi7Cuu4NlFWykoraSkwk8g6OjfKYmRPdrRo30csxdv4/GPN5FfUsmPT+/P+aO7hzvlZkUFoIiIiIiItAhllQGumrWYZVvziYn0kRBTVc48t2jbQe3OGNyJGV/vx5ie7cORZrOmAlBERERERI67ykCQFdvy+Tgrl8Wb85gyqhvfzexR5+2dc/zsxc9ZtjWfhy8dw1nDux5Yt6ugjBXZ+WTt2c/XB3ZiSLfk43EIrYIKQBEREREROa7W7Sri8scWsqeoHDNoHx/Nos15jEhvx8AuSXXax33vrOe1FTu4ZfKgg4o/gC4psXRJ6cKZQ49H9q2LL9wJiIiIiIhI6/Xl7iK+98gCzODB743hs19+k7d/cgrJsZH8ePYyyv2BI24fDDoe/mAD97+7nosy0/nBqX2aKPPWSQWgiIiIiIgcF+u94i/CZzx3zUTOGdGV9gnRdEyM4Y8XjuCLXUX86e0va91+e34p33t0AXe/9QVnD+/CnecPx8ya8AhaH10CKiIiIiIijSoYdMxdsYM731iDmfHctRPpk5Z4UJtvDOrMZRN7MvO/GzGgoLSSrXkllFYGSIiOJCEmgk825BIMOv544Qi+OzZdxV8jUAEoIiIiIiKN5pMNe/nDm2tZtb2Qod2S+evU0fQ9pPir9ouzh7BwYx7/+O9GOibG0KNDHIkxkRSX+8kpKmdsr/b89rxh9EyNb+KjaL1UAIqIiIiISKN4Zdl2bpqznO7t4rjv4pFMGdkdn6/2Ubu46Ahev/EkAkFHfLRKk6agT1lERERERBps895ifvHySsb37sBT08cTGxVRp+1iIuvWThqHJoEREREREZEGqfAHuXH2MiIjfPxl6qg6F3/S9DQCKCIiIiIiDXLv2+v4PLuAv182lm7t4sKdjhyBRgBFRERERKTe3ly5k5n/3chlE3syeViXcKcjR9GgAtDMfmJmq81slZk9Z2axZpZhZgvNbL2ZzTGzaK9tjPc+y1vfO2Q/t3nxdWZ2Zkh8shfLMrNbG5KriIiIiIg0rtc/38GPnltGZq/2/PKcIeFOR+qg3gWgmXUHbgQynXPDgAhgKnA3cJ9zrj+wD5jubTId2Oec6wfc57XDzIZ42w0FJgMPmVmEmUUADwJnAUOAS7y2IiIiIiISZq8u386Nzy1jbM/2PHlV3Sd9kfBq6CWgkUCcmUUC8cBO4BvAi976WcD53vIU7z3e+tOt6kmOU4DZzrly59wmIAsY772ynHMbnXMVwGyvrYiIiIiIhMne/eXc/dYX/GTOcsZndODJq8aRGKOpRVqKev9LOee2m9m9wFagFHgbWArkO+f8XrNsoLu33B3Y5m3rN7MCINWLLwjZdeg22w6JT6gpFzO7FrgWoGfPnvU9JBERERERqcXe/eX87b0sZi/eSrk/yHkju3HXt0cQF62Rv5ak3gWgmbWnakQuA8gHXqDqcs1DuepNallXW7ym0UlXQwzn3ExgJkBmZmaNbUREREREpH4q/EGufGIxa3cWcsHo7vzgtL70TUsMd1pSDw0Zqz0D2OScywEws38BXwPamVmkNwqYDuzw2mcDPYBs75LRFCAvJF4tdJva4iIiIiIi0kTue+dLVm6vesyDZvps2RpyD+BWYKKZxXv38p0OrAHeBy702kwDXvWW53rv8da/55xzXnyqN0toBtAfWAQsBvp7s4pGUzVRzNwG5CsiIiIiIsfo0w25/P0/G7hkfA8Vf61AQ+4BXGhmLwKfAX5gGVWXYb4BzDazO73YY94mjwFPm1kWVSN/U739rDaz56kqHv3ADc65AICZ/RCYR9UMo48751bXN18RERERkbZmX3EFT36ymbjoCLqmxNIrNYGR6SlUjd8cXUFJJT99fjkZqQn86lxNyN8aWNUgXOuRmZnplixZEu40RERERETCqqC0ku89soDVOwoPin9vQk9+f/6woxaBZZUBrnt6KR9n7eXlGScyPD3leKYrjcjMljrnMmtap/laRURERERamf3lfr7/xCK+3F3Ek1eOI7N3B3bmlzJ78TYe+2gTKXFR3DJ5UK3bF5RWcs2sJSzeksdd3x6u4q8VUQEoIiIiItKKlFYEuOrJxXyeXcBDl47htIGdAOjfOYlfnjOYssoAD3+wgaTYSGac1u+w7XOKypn2+CLW7yni/qmj+dbIbk19CHIcqQAUEREREWklnHP8/KXPWbw5j79OHc2ZQw+etMXM+N2UYewv9/PHt9bxSVYuEzI6kNm7A9n7Snh37R4+XJ9D0MGj08Zx6oC0MB2JHC8qAEVEREREWonHPtrEayt28LMzB3JeLSN3Pp9x73dH0r1dHO99sYc/zf/ywLouybFMGd2dSyf0ZGg3XfbZGqkAFBERERFpBT7ZsJf/+/cXTB7ahRmn9T1i26gIHz+fPIifTx5EfkkFy7bmk5YUw9BuyXWeIVRaJhWAIiIiIiItXPa+En747DJ6p8Zz70Ujj6mIaxcfzdcHdTqO2Ulz0pAHwYuIiIiISJit2l7Adx7+hEp/kH9cnklijMZ4pHYqAEVEREREWqi3V+/iu3//lAgznv/BCfTrlBjulKSZ058HRERERERaoJeWZnPziysY0T2FR6Zl0ikpNtwpSQugAlBEREREpIUpKKnkt6+vYVyvDsy6ajxx0RHhTklaCF0CKiIiIiLSwjz0QRaFZZXcft4QFX9yTFQAioiIiIi0INn7Snjik81cMLq7ntUnx0wFoIiIiIhIC/Knt7/EgJsnDQx3KtIC6R5AEREREZFmprCskpyichJjIomPjsBnhj/gWLe7iJeXbef60/rSrV1cuNOUFkgFoIiIiIhIM5K7v5xJ9/2X3OKKGte3j4/i+tP6NnFW0lqoABQRERERaUbufusLCkor+f0FwzCM4nI/QeeIivARFWGc0LcjybFR4U5TWigVgCIiIiIizcTSLft4fkk2153Sh0sn9Ap3OtIKaRIYEREREZFmIBB03D53FZ2TY/jR6f3DnY60UioARURERESagWcXbWXV9kJ+cc4QEmN0oZ4cHyoARURERETCbGdBKffOW8cJfVL51oiu4U5HWjEVgCIiIiIiYeQPBPnxc8upDASrJn4xC3dK0oppbFlEREREJIz+8s56Fm3O4y8Xj6JPWmK405FWrkEjgGbWzsxeNLMvzGytmZ1gZh3MbL6Zrfd+tvfampndb2ZZZva5mY0J2c80r/16M5sWEh9rZiu9be43/TlERERERFqRD9fn8OAHWVyUmc75o7uHOx1pAxp6Cehfgbecc4OAkcBa4FbgXedcf+Bd7z3AWUB/73Ut8DCAmXUAbgcmAOOB26uLRq/NtSHbTW5gviIiIiIizcKugjJ+Mmc5/dISueO8oeFOR9qIeheAZpYMnAI8BuCcq3DO5QNTgFles1nA+d7yFOApV2UB0M7MugJnAvOdc3nOuX3AfGCyty7ZOfepc84BT4XsS0RERESkxSqp8DN91mJKKwI8eOkY4qN1Z5Y0jYaMAPYBcoAnzGyZmT1qZglAZ+fcTgDvZyevfXdgW8j22V7sSPHsGuKHMbNrzWyJmS3JyclpwCGJiIiIiBxfwaDjptnLWbuzkAe+N5oBnZPCnZK0IQ0pACOBMcDDzrnRQDFfXe5Zk5ru33P1iB8edG6mcy7TOZeZlpZ25KxFRERERMLoj/PW8faa3fzinCF8Y1DncKcjbUxDCsBsINs5t9B7/yJVBeFu7/JNvJ97Qtr3CNk+HdhxlHh6DXERERERkRbpo/V7+ft/NvC9CT256sTe4U5H2qB6F4DOuV3ANjMb6IVOB9YAc4HqmTynAa96y3OBK7zZQCcCBd4lovOASWbW3pv8ZRIwz1tXZGYTvdk/rwjZl4iIiIhIi3P/e+vpkhzL7d8aouf9SVg09G7THwHPmFk0sBG4kqqi8nkzmw5sBb7rtX0TOBvIAkq8tjjn8szsd8Bir91vnXN53vL1wJNAHPBv7yUiIiIi0uIs3pzHok15/PrcIcRERoQ7HWmjGlQAOueWA5k1rDq9hrYOuKGW/TwOPF5DfAkwrCE5ioiIiIg0Bw+9n0WHhGimju9x9MYix0lDnwMoIiIiIiJHsXpHAe+vy+GqE3vrkQ8SVioARURERESOs4c+2EBSTCSXn9A73KlIG6cCUERERETkONqQs583V+7k8hN6kRIXFe50pI1TASgiIiIicpw45/j9G2uJj4rgqpMywp2OiApAEREREZHjZf6a3bz3xR5uOmMAHRNjwp2OiApAEREREZHjobQiwG9eW8OAzol8Xw99l2ZCUxCJiIiIiBwHD76fxfb8UuZcO5GoCI27SPOgM1FEREREpJFtzNnPzP9u5NujuzOhT2q40xE5QAWgiIiIiEgjKvcH+PHs5cRG+bjt7MHhTkfkILoEVERERESkEf3u9TWs3F7AzMvHkpakiV+kedEIoIiIiIhII3l1+Xb+uWAr153Sh0lDu4Q7HZHDqAAUEREREWkEX+4u4rZ/rWR87w7cfObAcKcjUiMVgCIiIiIiDfTmyp185+FPiKGHUtoAAB1GSURBVI+O4IHvjdasn9Js6R5AEREREZF6KqsM8LvX1/DMwq2M7NGOv10yms7JseFOS6RWKgBFREREROqhoKSSaU8sYvm2fK49pQ83TxpIdKRG/qR5UwEoIiIiInKMcveXc9lji9iwZz9/v2wMk4d1DXdKInWiAlBERERE5BjsLizj0kcXkr2vhEenZXLKgLRwpyRSZyoARURERETqKHtfCZc+upC9ReXMunI8E/qkhjslkWOiAlBEREREpA427y3m0kcXUlRWyT+vnsDonu3DnZLIMVMBKCIiIiJyFOt3F3HpowvxBx3PXjORYd1Twp2SSL2oABQREREROYKsPfuZOnMBPp8x59qJ9O+cFO6UROpNBaCIiIiISC225ZVw2aMLMasq/vqkJYY7JZEGafCDSswswsyWmdnr3vsMM1toZuvNbI6ZRXvxGO99lre+d8g+bvPi68zszJD4ZC+WZWa3NjRXEREREZG6qp7ts7QywD+vHq/iT1qFxnhS5Y+BtSHv7wbuc871B/YB0734dGCfc64fcJ/XDjMbAkwFhgKTgYe8ojICeBA4CxgCXOK1FRERERE5rvJLKrjs0YXk7i9n1lXjGdQlOdwpiTSKBhWAZpYOnAM86r034BvAi16TWcD53vIU7z3e+tO99lOA2c65cufcJiALGO+9spxzG51zFcBsr62IiIiIyHFT7g9w7dNL2ZJbwqPTxjGqR7twpyTSaBo6AvgX4OdA0HufCuQ75/ze+2ygu7fcHdgG4K0v8NofiB+yTW3xw5jZtWa2xMyW5OTkNPCQRERERKStCgYdP3/xcxZtyuOe747ghL56zp+0LvUuAM3sXGCPc25paLiGpu4o6441fnjQuZnOuUznXGZaWtoRshYRERERqd2f5q/j1eU7+NmZA5kyqsaxB5EWrSGzgJ4InGdmZwOxQDJVI4LtzCzSG+VLB3Z47bOBHkC2mUUCKUBeSLxa6Da1xUVEREREGk1ZZYDfvLaa5xZtY+q4Hsw4rW+4UxI5Luo9Auicu805l+6c603VJC7vOecuBd4HLvSaTQNe9Zbneu/x1r/nnHNefKo3S2gG0B9YBCwG+nuzikZ7fcytb74iIiIiIjXJ2rOf8x/8mOcWbeP60/py5/nDqJqqQqT1OR7PAbwFmG1mdwLLgMe8+GPA02aWRdXI31QA59xqM3seWAP4gRuccwEAM/shMA+IAB53zq0+DvmKiIiISBtS7g8wf81uVm4vYPX2QpZsySM+OpInrxzHaQM7hTs9kePKqgbhWo/MzEy3ZMmScKchIiIiIs1QWWWAa55awofr9xId4WNAl0RGprfjR9/oT5eU2HCnJ9IozGypcy6zpnXHYwRQRERERKTZKa0IMH3WYj7dmMsfLhjOhWPTiY5sjMdii7QcKgBFREREpNUrLvdz1ZOLWbw5jz99dyTfHpMe7pREwkIFoIiIiIi0aut3FzHjmc/YkLOf+y4epcc7SJumAlBEREREWq0XlmzjV6+uIjEmkllXjefk/npmtLRtKgBFREREpFXxB4K898Uenl6whQ/X72Vinw7cP3U0nZI1yYuICkARERERaRXKKgM8/ekWHv94EzsLyuicHMNtZw3i6pP7EOHTc/1EQAWgiIiIiLRwzjle+3wnf3zrC7L3lfK1vqnc/q2hnDG4E5ERmuVTJJQKQBERERFpsYrKKrnu6aV8siGXwV2T+ef0EZzUv2O40xJptlQAioiIiEiLlF9SwRWPL2LNjkLuPH8Yl4zvqUs9RY5CBaCIiIiItDg5ReVc/thCNu4t5h+Xj+X0wZ3DnZJIi6ACUERERERalILSSqbO/JSdBWU88f1xnNhPl3yK1JUKQBERERFpMYJBx0/mLGdLbglPT5/ACX1Tw52SSIuiaZFEREREpMX4y7vree+LPfz6W0NU/InUgwpAEREREWkR3l69i/vfXc+FY9O5fGKvcKcj0iLpElARERERabYCQccnG/bywpJs3lq1ixHpKdx5/jDMNNunSH2oABQRERGRZmfz3mJeXJrNvz7LZkdBGcmxkVw8rgc/Or0fsVER4U5PpMVSASgiIiIiYVdYVsnyrfl8tnUfH2ftZfHmffgMTu6fxv+eM5gzBndW4SfSCFQAioiIiEjY+ANB/jT/S/7xnw0EHZjBoC7J/OzMgXxnTDpdUmLDnaJIq6ICUERERETCIqeonBufW8anG3P5zph0zh/djVE92pEUGxXu1ERaLRWAIiIiItLkVm0vYPqsxeSXVHLPhSP4bmaPcKck0iaoABQRERGRJrWroIyrnlxMpM94ecaJDOmWHO6URNoMFYAiIiIi0mRKKwJc/dRiisv9/GvGiQzskhTulETalHo/CN7MepjZ+2a21sxWm9mPvXgHM5tvZuu9n+29uJnZ/WaWZWafm9mYkH1N89qvN7NpIfGxZrbS2+Z+0wNfRERERFqsYNDxPy8sZ/WOQu6/ZLSKP5EwaMgIoB/4H+fcZ2aWBCw1s/nA94F3nXN3mdmtwK3ALcBZQH/vNQF4GJhgZh2A24FMwHn7meuc2+e1uRZYALwJTAb+3YCcRURERKSJrMwu4K631rJqeyHRkT58BrsLy/nF2YM5fXDncKcn0ibVuwB0zu0EdnrLRWa2FugOTAFO85rNAj6gqgCcAjzlnHPAAjNrZ2ZdvbbznXN5AF4ROdnMPgCSnXOfevGngPNRASgiIiLSqIJBR2FZJc5B+4ToI7Z1znG0i7J2FZTxx3lf8K/PtpOaEM25I7oSdI5yf5AhXZOZflJGY6YvIsegUe4BNLPewGhgIdDZKw5xzu00s05es+7AtpDNsr3YkeLZNcRr6v9aqkYK6dmzZ8MORkRERKQNKKsM8Ic31/Laih3kl1YVfwCdk2MY1i2FHh3iyd5XypbcYrbnl1IZCOIPOiJ9xqPTxnHqgLQa97t+dxGXPLKAwlI/Pzi1LzO+3pdkPdZBpNlocAFoZonAS8BNzrnCI/xFqKYVrh7xw4POzQRmAmRmZtbYRkRERESqbMsr4fpnlrJqeyFTRnWjZ4d42sVHEww61uwsZPWOAhZszCW9fTwZHRM4uX8asVE+InzGvz7bzh/f+oJT+nc8bCRwQ85+LnlkIWbGmz8+iX6ddI+fSHPToALQzKKoKv6ecc79ywvvNrOu3uhfV2CPF88GQh/wkg7s8OKnHRL/wIun19BeRERERI7AOcdnW/NJiYs8qAirDAR54/Od3D53NUHnePSKTM4Ycmz34vVKTeDmF1bw9prdnDm0y4H4pr3FXDJzAQDPXTORfp0SG+dgRKRR1bsA9GbkfAxY65z7c8iqucA04C7v56sh8R+a2WyqJoEp8IrEecAfqmcLBSYBtznn8sysyMwmUnVp6RXAA/XNV0RERKQt2Jpbwu1zV/H+uhwARvdsx4Vj08kpKufZhVvZU1TOsO7JPPS9sfRMjT/m/Z8/qhsPvp/FffO/5JuDO+PzGVtyq4q/QNDx3LUq/kSas4aMAJ4IXA6sNLPlXux/qSr8njez6cBW4LveujeBs4EsoAS4EsAr9H4HLPba/bZ6QhjgeuBJII6qyV80AYyIiIi0aGWVAV5cmk1KXBTnjuh61AlV6qrCH+ThDzbw4AdZRPmM/z17EIbx/JJt/OLlVQCcOiCNu77Ti1MHdCLCV79+IyN83Hh6P34yZwXzVu9iWPcULpm5gHJ/gGevmciAzrrsU6Q5M+da1y1zmZmZbsmSJeFOQ0REROQgzjneWbuHO99Yw5bcEgDG9W7Pb6cMY3DX5Abte92uIn4yZzlrdhZy7oiu/PKcIXRJiT3Q75qdhSTFRNVrxK8mgaDjm/f9B6gqPIvK/Dx7zQSGdktplP2LSMOY2VLnXGZN6xplFlAREREROdjW3BJue/lzcvdXEBlhVPiDfLl7P/06JfLUVePZWVDKXf/+gnMf+IjpJ2Vw86SBREf6jqmPorJKnl6whb/MX09yXCQzLx/LpJD78gDMrNELswifcdMZA7jxuWUkxUby7NUTVfyJtBAqAEVERETqoaiskgp/kMqAw+eDTkmxB9Z9tnUf18xagj/omJDRAX/QEQg6po7ryeUn9CIqoqrQO3NoF+5+ax0z/7uRhZvy+Nslo+nR4cijdMGg4/11e3h52Xbmr9lNuT/IWcO6cOf5w0hNjDmuxxzqnOFd2ZpbzGkDOzGsu4o/kZZCl4CKiIhIi1BUVskjH24id385PztzIO3ij/zAcoCSCj8bc4rp0T6elPiGPYtuV0EZc1dsZ9nWfJZtzWdXYdlB6/umJTB5WBe6pMRx5+tr6JwcyxNXjqNv2tEnRPn3yp38/MXPMYM/XjiSycO61NhuZXYBv3p1Fcu35dM+PopvjezG+aO7M7pHu0a7l1BEWr4jXQKqAlBERESatQp/kGcWbuGB97LIK64gwmekJkRz13eG841Bhz/CYMW2fF5Yuo3PtuSzbncRgWDVd53eqfGM6tGOGV/vd9BEJf5AkD/N/5IO8dFMPykD3yGTo1T4gzz+8Sbuf3c9JRUBenaIZ3TPdgzumkx8dARRET6Ky/28u3YPizbnEQg6Rvdsx6NXZB7TiNyW3GJ++OwyVm4v4OzhXbj9W0PpnFw1qrghZz+Pf7SJZxdtJTUhhlvPGsSUUd0OjCSKiIRSASgiIiItRoU/SPa+EpZs3scHX+7hw/V7KSrz87W+qdx61iB8ZvzP8ytYt7uIs4Z1YUzP9vRJS6AyEOTxjzezaFMe8dERjOnZntE92zGwSxJbcktYsS2fhZvyCDrHI1dkMrFPKuX+ADfNXs6/V+0CqmbJvO/iUXRIiKasMsA7a3dz3/wv2ZBTzBmDO/OrcwfTKzWh1tz3FVewekchmb3bExsVUa9jf+TDjfz13fXERPg4Z0RXFm7KY9PeYiJ8xrQTenPTN/uTHNuw0UwRad1UAIqIiEizVFRWybKt+SzZnMeSLfvYtLeYXYVlVH896Zwcw6kD0vjWyG6c1K/jgcscy/0B/vrOep5btJV9JZUH9te9XRxXntibi8f1IKmGIml7finTHl/E1twS7vrOcF5dvoP/fJnDr84dQnSkj9+9tobUxGhO7t+Rf6/aRVGZn16p8fz63CGcPvjYHpjeEJv3FvPLV1axaFMeE/um8s3BnThjSGe6psQ1WQ4i0nKpABQREZGwqAwE+cd/NjDr0y10iI+mR4d4uqbEsj2/lHW7itieXwqAz2BIt2QGdk4mvX0c6e3jGNY9hUFdko56b9u+4go27i2muNzPCX1Tj3pZZH5JBdNnLWHpln2YwV3fHs7F43oCVffY3fDsZ+QUlXPWsC5cMKY7X+vbsd7PzGuoYNAddkmqiMjRqAAUERGRJrdqewE/e/Fz1u4s5NQBaURF+NiaV8zOgjK6t4ujf+ckBnRKZFTPdozu2Z7EmKabnLysMsA989YxPqMDZx7y2IRg0FEZDBITeeyXcIqINAd6DqCIiIgcdyUVfpZtzWfhxlwWbMpj6ZZ9pCZE84/Lxx5WZIVbbFQEvzp3SI3rfD4jxqfiT0RaJxWAIiIickz2FJWxMaeYgtJKCksr2bi3mIUbc/k8uwB/0OEzGNothWtP6cMPTunb4McviIhI41EBKCIiIrVyzlFY5ienqJyPs/byxsqdLN6cR+gdJJE+Y0R6Ctec0ofxGR3I7NW+xglYREQk/FQAioiItHHl/gBf7CxiRXY+K7ML2FVYRu7+CnKLy8krrqAy8FW1179TIjd+oz/jenegXXwUKXFRpCXF1OuRByIi0vRUAIqIiLRBe4rKeHftHuav2c3HWXsp9wcB6JgYTXr7qpk6h3VPJjUxhtSEaFIToxnWLYX+IQ9QFxGRlkcFoIiISCtVVhlga14JG3OK2bS3mM17q35u3FvM3v3lAKS3j+OS8T0Zn9GBkT3a0S0l9qiPXRARkZZLBaCIiEgLFgg6tu8rZePe/WzyCrzq1/b80oPu1UtLiiEjNYHTB3Wib6cEThmQxsDOR3/OnoiItB4qAEVERJoB5xy7C8tZub2ANTsK2bavhO37StlZUEqFP0h1HRcT6SM+OpL46Aj2lVSwNa/koHv0kmIi6ZOWQGav9lw4Np2Mjgn06ZhI747xmphFRERUAIqIiDSVcn+AzXtLWL5tH8u25vPl7iJKKgKU+4MUlFaSV1wBgBl0Toqle/s4hqe3IzbSd2AfFYEgxeUBisv99OuUyKShXcjomHDglZoQrRE9ERGplQpAERGROij3B9hVUMbOgjJ2FpSyI7+MXQVllFQECASD+IOOQNDhDzr8gYPfF5X52V1YdqDAA0iJi2JI16pJVmKjIkiMiWBg5ySGp6cwuGsy8dH6FS0iIo1Pv11ERESougQzp6icz7bms2zbPtbsKKSgtJKiMj/5JRXsK6k8bJuUuCgSYyKJjDAifEakz4jw+YgKeR/p89EtJZbRPdvRJTmW9PZxjOrRjoyOCRqpExGRJqcCUEREWgznHLnFFWzfV8re/eXkFleQX1JBUmwUnZNjSEuMpbCskm15JWzbV0JRmZ/KQNWIXGUgSGX16FzAHVgurgiwt6icnP3lVHiPQoiO8DGwSxKpidH0Sk0gOTaSzsmxdE2JpVu7OLqkVC1rlE5ERFoa/eYSEZEm4ZyjtDJASUWAkvIAJZV+issDlFYEKK7wU1Lh/2pdRYCSCj/7y/3sK6kgr7iCvfurCr/SykCd+ovwGUmxkUR6I3KREUZUhI8on4/ICCMywkeUz0iOjaRvxwTSkmLokhLLyB7tGNotmZhIPdhcRERaHxWAIiJymAp/kP3lfvaXVRVhJRV+iisClFZUFW0llQFKyv0HCrWqnwcvF5cfHC+tDBz0SIKjiYn0kRgTSfuEaDrER9MvLZFTB6TRo30c3dvHk5ZU9YDydvFRB+6x21NUTlJsJD28B5lHRviO3pGIiEgb0uwLQDObDPwViAAedc7dFeaUREQazDlH0EFlIHjQxCFfLTv8war3lYHqyUSCB9YFgo7KYJBAwGsfDFJeGSS3uJy9+yvI3V9xYN+hfVTv56D33v7K/AH2l/kpKvcfuBSyLuKiIkiIiSAuOoIE7/EE8dGRpCZEVy3HRBIf5f2MjiAhOoK46EjvZwQJMZHePr6KxUdHEuGr+/1xSbFRdGsXV59/ChERkTalWReAZhYBPAh8E8gGFpvZXOfcmvBmJnJkzjmc48Bzu5xzOPBi7qBRkNBYTe3x1n/V9pD1eOsPrPsqdlD7Y+kzJMdD8z50/6H7qylHDtnnQTke8rlQS58lFQFvNKoSf/CrA6meQMMOvK9adkDQQTDoCDpHwDv+gFfwOC92UJsgBF318lfrAu7gGR2rirEaCrGQoi20sKqxiPOKtuMlJtJHakI0MVERIROTVF3yWL0cFeEjNuqrSUsifUZMlI+k2EgSY6K8n1WvhJiq4qy6sAv9GRcVge8YCjUREREJr2ZdAALjgSzn3EYAM5sNTAFqLQC/3F3EGX/+z0ExV8M1RzV+9arl+1hN4TrvE6ihKa6G1jW2O4bviE2VU237rbltQ/fZwGM6hu2/KqAOL64OFEp1KMak+TMDnxkRZphV3SvmM8MXuuyreh/p83nFU+0zPMZERXrvvQIrwogKKaxq3TbCd9DyV8VZzdt+tVxVwIXmUH1/W2piNEkxkZpdUkRERGrU3AvA7sC2kPfZwIRDG5nZtcC1AMnd+jCwc9Lhe6rhu1BNX49q+9JUc9u6tattvzW2rXGfteRU52OqJacaWte4z1q/R9Zx++ORU20Z1fFL75H6rx5FMjtkhMkOXl+9n4NiIe1D1x0Uq25jtfTJIevNDqz7aj/H2GdV8iF5W0g+denz4BwJaW8h7Tl0n7X1eUiONX+2X72Pi44gKSaKxNhIoiLs4IK7hhFJ4EAB91Vx99V7FUciIiLSVjX3ArCmb2mHjbM452YCMwEyMzPdg5eOOd55iYiIiIiItDjNfXq0bKBHyPt0YEeYchEREREREWnRmnsBuBjob2YZZhYNTAXmhjknERERERGRFqlZXwLqnPOb2Q+BeVQ9BuJx59zqMKclIiIiIiLSIjXrAhDAOfcm8Ga48xAREREREWnpmvsloCIiIiIiItJIVACKiIiIiIi0ESoARURERERE2ggVgCIiIiIiIm2EOXfYc9VbNDMrANaHqfsUoCBMfXcE9oap73Aedzj7Dnf/Ot/Ud1vou62ea+Huv6323VbPN/Xd9MJ5rkHb/dzbUt+9nHNpNa5xzrWqFzCzjfa9pI0ed9j6Dnf/Ot/Udxvpu02ea+Huvw333SbPN/Udlr7Ddq41g2NX32F+tcZLQF9ro32HU1v+zNvysYdLW/3M22rf4RTu426r/+bh/tzDpa1+5m2173Brq597W+37IK3uEtC2ysyWOOcyw52HtA0636Sp6FyTpqTzTZqKzjUJp9Y4AthWzQx3AtKm6HyTpqJzTZqSzjdpKjrXJGw0AigiIiIiItJGaARQRERERESkjVABKCIiIiIi0kaoAGzGzOxxM9tjZqtCYnPMbLn32mxmy734pSHx5WYWNLNR3rqxZrbSzLLM7H4zs3AdkzRPtZxro8xsgXc+LTGz8V78UjP73Ht9YmYjQ7aZbGbrvHPt1nAcizR/x3i+/Szk/7VVZhYwsw7eOp1vckS1nGsjzexT7/fia2aW7MW/aWZLvfhSM/tGyDb6PSpHdYznm763SfiE+zkUetX+Ak4BxgCraln/J+DXNcSHAxtD3i8CTgAM+DdwVriPTa/m9arpXAPerj5XgLOBD7zlrwHtveWzgIXecgSwAegDRAMrgCHhPja9mt/rWM63Q7b7FvCet6zzTa+jvmo51xYDp3rLVwG/85ZHA9285WHA9pBt9HtUr6O+juV8O2Q7fW/Tq0lfGgFsxpxz/wXyalrn/TXoIuC5GlZfUh03s65AsnPuU+ecA54Czj8+GUtLVcu55oBkbzkF2OG1/cQ5t8+LLwDSveXxQJZzbqNzrgKYDUw5rolLi3Qs59shDvzfhs43qYNazrWBwH+95fnAd7y2y5xz1efdaiDWzGL0e1Tq6ljOt0Poe5s0qchwJyD1djKw2zm3voZ1F/PVF6HuQHbIumwvJnI0NwHzzOxeqi4X/1oNbaZT9ddJqDqvtoWsywYmHNcMpTU54vlmZvHAZOCHXkjnm9TXKuA84FXgu0CPGtp8B1jmnCs3M/0elYaoy/mm723SpDQC2HKF/iX8ADObAJQ456qvP6/punE9+0Pq4nrgJ865HsBPgMdCV5rZ16kqAG+pDtWwD51rUldHPN+ouvzzY+dc9V/Xdb5JfV0F3GBmS4EkoCJ0pZkNBe4GrqsO1bAPnWtSV0c73/S9TZqcRgBbIDOLBL4NjK1h9VQOLgyz+eoSPbzlmi6tEjnUNODH3vILwKPVK8xshPf+LOdcrhfO5uC/bOpck2NR6/nmqen/Np1vcsycc18AkwDMbABwTvU6M0sHXgaucM5t8ML6PSr1dqTzzaPvbdLkNALYMp0BfOGcC71EADPzUXV5wezqmHNuJ1BkZhO9+wavoOoyBJGj2QGc6i1/A1gPYGY9gX8Blzvnvgxpvxjob2YZZhZN1S+1uU2Yr7RsNZ5vAGaW4q0L/b9L55vUi5l18n76gF8Cf/fetwPeAG5zzn1c3V6/R6UhajvfQmL63iZNTiOA/9/OvaNEEAVRAL0VCma6BJdgLEbmLkJBdAujazAx85OZmYruw9TIyFwwGCiD6QHxA2Pir8+JmuIlDwq6b7/u+sWq6jLJZpLVqnpIctTdp3n/tmhuI8lDd9+/qe8luUiylNn/WteBVz7qtSQ7SY6HE+fnJLvD8sMkK0lOhsnU0+5e7+5pVR0kuclsQuNZd9997074C77Yb0myneS2u5/mBf3GIj7pteWq2h+WXCU5H64PkqwlmVTVZKhtdfdj3EdZwBf7LfHcxg+p2YAhAAAA/jufgAIAAIyEAAgAADASAiAAAMBICIAAAAAjIQACAACMhAAIAAAwEgIgAADASLwAA3lvHxoyl3wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# decompose time series in observed, seasonal, trend and residuals\n",
    "result = seasonal_decompose(ts.co2, model='multiplicative')\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "result.observed.plot(label='$CO^{2}$ emissions - observed')\n",
    "plt.legend()\n",
    "plt.savefig('img/ts_observed.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "perfect-negotiation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "result.seasonal.plot(label='$CO^{2}$ emissions - seasonal')\n",
    "plt.legend()\n",
    "plt.savefig('img/ts_seasonal.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dynamic-adapter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "result.trend.plot(label='$CO^{2}$ emissions - trend')\n",
    "plt.legend()\n",
    "plt.savefig('img/ts_trend.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bearing-intervention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "result.resid.plot(label='$CO^{2}$ emissions - residuals')\n",
    "plt.legend()\n",
    "plt.savefig('img/ts_residuals.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-machine",
   "metadata": {},
   "source": [
    "Running the plots of the observed, trend, seasonal, and residual time series, we can see that the results doesn't interesting. So let's try another approach to extract some insights about the time series. Next, the amount of carbon dioxide emission will be analyzed every 50 years, since 1850."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "departmental-calvin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>co2</th>\n",
       "      <th>period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1850-12-31</td>\n",
       "      <td>944.824</td>\n",
       "      <td>1850 to 1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1851-12-31</td>\n",
       "      <td>944.689</td>\n",
       "      <td>1850 to 1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1852-12-31</td>\n",
       "      <td>984.086</td>\n",
       "      <td>1850 to 1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1853-12-31</td>\n",
       "      <td>1025.620</td>\n",
       "      <td>1850 to 1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1854-12-31</td>\n",
       "      <td>1209.253</td>\n",
       "      <td>1850 to 1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>123813.289</td>\n",
       "      <td>&gt; 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>123890.716</td>\n",
       "      <td>&gt; 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>125438.734</td>\n",
       "      <td>&gt; 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>127746.944</td>\n",
       "      <td>&gt; 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>127568.915</td>\n",
       "      <td>&gt; 2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     timestamp         co2        period\n",
       "0   1850-12-31     944.824  1850 to 1900\n",
       "1   1851-12-31     944.689  1850 to 1900\n",
       "2   1852-12-31     984.086  1850 to 1900\n",
       "3   1853-12-31    1025.620  1850 to 1900\n",
       "4   1854-12-31    1209.253  1850 to 1900\n",
       "..         ...         ...           ...\n",
       "165 2015-12-31  123813.289        > 2000\n",
       "166 2016-12-31  123890.716        > 2000\n",
       "167 2017-12-31  125438.734        > 2000\n",
       "168 2018-12-31  127746.944        > 2000\n",
       "169 2019-12-31  127568.915        > 2000\n",
       "\n",
       "[170 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts50 = ts['1850':].reset_index().rename(columns={'index':'timestamp'})\n",
    "\n",
    "def classify_period(x):\n",
    "    if x.year >= 1850 and x.year <= 1900:\n",
    "        return '1850 to 1900'\n",
    "    if x.year > 1900 and x.year <= 1950:\n",
    "        return '1900 to 1950'\n",
    "    if x.year > 1950 and x.year <= 2000:\n",
    "        return '1950 to 2000'\n",
    "    if x.year > 2000:\n",
    "        return '> 2000'\n",
    "    \n",
    "ts50['period'] = ts50['timestamp'].apply(classify_period)\n",
    "ts50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "saved-pixel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning:\n",
      "\n",
      "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# source: https://stackoverflow.com/questions/52273543/creating-multiple-boxplots-on-the-same-graph-from-a-dictionary/52274064\n",
    "d = {\n",
    "    '1850 to 1900': list(ts50[ts50.period == '1850 to 1900'].co2.values),\n",
    "    '1900 to 1950': list(ts50[ts50.period == '1900 to 1950'].co2.values),\n",
    "    '1950 to 2000': list(ts50[ts50.period == '1950 to 2000'].co2.values),\n",
    "    '> 2000': list(ts50[ts50.period == '> 2000'].co2.values),\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.boxplot(d.values())\n",
    "ax.set_xticklabels(d.keys())\n",
    "plt.title('$CO^{2}$ emissions by period')\n",
    "plt.savefig('img/emissions_by_period.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "victorian-fourth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co2</th>\n",
       "      <th>percetual_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>period</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1850 to 1900</th>\n",
       "      <td>3511.905941</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900 to 1950</th>\n",
       "      <td>14672.126920</td>\n",
       "      <td>317.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950 to 2000</th>\n",
       "      <td>62801.521540</td>\n",
       "      <td>1688.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt; 2000</th>\n",
       "      <td>115070.215526</td>\n",
       "      <td>3176.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        co2  percetual_change\n",
       "period                                       \n",
       "1850 to 1900    3511.905941              0.00\n",
       "1900 to 1950   14672.126920            317.78\n",
       "1950 to 2000   62801.521540           1688.25\n",
       "> 2000        115070.215526           3176.57"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = ts50.groupby('period').mean()\n",
    "grouped['percetual_change'] = round((grouped.co2 - grouped.iloc[0].co2) / grouped.iloc[0].co2 * 100, 2)\n",
    "grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-transport",
   "metadata": {},
   "source": [
    "In the boxplot it is possible to observe the variation in the quartiles of carbon dioxide emission in the periods from 1850 to 1900, 1900 to 1950, 1950 to 2000, and 2000 to 2019. The annual averages of global carbon dioxide emissions in the period from 1950 to 2000 increased by 1,688% compared to the period from 1850 to 1900, and in the period from 2000 to 2019 emissions increased by 3,176%.\n",
    "\n",
    "Another interesting approach could be check the percentual variation year by year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "satisfactory-delivery",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co2</th>\n",
       "      <th>percetual_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1850-12-31</th>\n",
       "      <td>944.824</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851-12-31</th>\n",
       "      <td>944.689</td>\n",
       "      <td>-0.014288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852-12-31</th>\n",
       "      <td>984.086</td>\n",
       "      <td>4.170367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853-12-31</th>\n",
       "      <td>1025.620</td>\n",
       "      <td>4.220566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854-12-31</th>\n",
       "      <td>1209.253</td>\n",
       "      <td>17.904585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-31</th>\n",
       "      <td>123813.289</td>\n",
       "      <td>0.066294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31</th>\n",
       "      <td>123890.716</td>\n",
       "      <td>0.062535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>125438.734</td>\n",
       "      <td>1.249503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>127746.944</td>\n",
       "      <td>1.840109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>127568.915</td>\n",
       "      <td>-0.139361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   co2  percetual_change\n",
       "1850-12-31     944.824               NaN\n",
       "1851-12-31     944.689         -0.014288\n",
       "1852-12-31     984.086          4.170367\n",
       "1853-12-31    1025.620          4.220566\n",
       "1854-12-31    1209.253         17.904585\n",
       "...                ...               ...\n",
       "2015-12-31  123813.289          0.066294\n",
       "2016-12-31  123890.716          0.062535\n",
       "2017-12-31  125438.734          1.249503\n",
       "2018-12-31  127746.944          1.840109\n",
       "2019-12-31  127568.915         -0.139361\n",
       "\n",
       "[170 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsbar = ts['1850':]\n",
    "tsbar['percetual_change'] = tsbar.pct_change() * 100\n",
    "tsbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "stock-buying",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "plt.plot(tsbar.percetual_change, label='$CO^{2}$ emissions - percentual change')\n",
    "plt.hlines(tsbar.percetual_change.mean(), ls='--', color='red', xmin=tsbar.index.min(), xmax=tsbar.index.max())\n",
    "plt.ylabel('%')\n",
    "plt.legend()\n",
    "plt.savefig('img/emissions_percentual_change.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "attended-federation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    169.000000\n",
       "mean       3.066116\n",
       "std        4.923850\n",
       "min      -20.324288\n",
       "25%        0.835550\n",
       "50%        3.084643\n",
       "75%        5.701284\n",
       "max       17.904585\n",
       "Name: percetual_change, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsbar.percetual_change.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-ballet",
   "metadata": {},
   "source": [
    "We can conclude so far that, on average, the percentage change from year to year is approximately 3%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-taiwan",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "received-health",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1750-12-31       46.755\n",
       "1751-12-31       46.755\n",
       "1752-12-31       46.770\n",
       "1753-12-31       46.770\n",
       "1754-12-31       46.790\n",
       "                ...    \n",
       "1995-12-31    87252.937\n",
       "1996-12-31    89621.706\n",
       "1997-12-31    89708.397\n",
       "1998-12-31    89286.496\n",
       "1999-12-31    90256.260\n",
       "Freq: A-DEC, Name: co2, Length: 250, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series = make_time_series(ts.co2)\n",
    "time_series[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "seasonal-adolescent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1750-12-31       46.755\n",
       "1751-12-31       46.755\n",
       "1752-12-31       46.770\n",
       "1753-12-31       46.770\n",
       "1754-12-31       46.790\n",
       "                ...    \n",
       "1990-12-31    88010.112\n",
       "1991-12-31    88534.589\n",
       "1992-12-31    85683.429\n",
       "1993-12-31    85945.146\n",
       "1994-12-31    85845.104\n",
       "Freq: A-DEC, Name: co2, Length: 245, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series_training = create_training_series(time_series, 5)\n",
    "time_series_training[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "civil-namibia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display train/test time series\n",
    "time_series_idx = 0\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "time_series[time_series_idx].plot(label='Test', lw=3) # test data is the whole time series\n",
    "time_series_training[time_series_idx].plot(label='Train', ls=':', lw=3, color='yellow') # train data is all but the last prediction pts\n",
    "plt.legend()\n",
    "plt.savefig('img/example_train_test.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "quiet-appendix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data to a local directory\n",
    "data_dir = 'json_data'\n",
    "\n",
    "# make data dir, if it does not exist\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "searching-karma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json_data/train.json saved.\n",
      "json_data/test.json saved.\n"
     ]
    }
   ],
   "source": [
    "# directories to save train/test data\n",
    "train_key = os.path.join(data_dir, 'train.json')\n",
    "test_key = os.path.join(data_dir, 'test.json')\n",
    "\n",
    "# write train/test JSON files\n",
    "write_json_dataset(time_series_training, train_key)        \n",
    "write_json_dataset(time_series, test_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-rental",
   "metadata": {},
   "source": [
    "# Uploading data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "digital-clerk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data is stored in: s3://sagemaker-sa-east-1-072590943848/co2-emission/train/train.json\n",
      "Test data is stored in: s3://sagemaker-sa-east-1-072590943848/co2-emission/test/test.json\n"
     ]
    }
   ],
   "source": [
    "# session, role, bucket\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "# general prefix\n",
    "prefix = 'co2-emission'\n",
    "\n",
    "# *unique* train/test prefixes\n",
    "train_prefix = '{}/{}'.format(prefix, 'train')\n",
    "test_prefix = '{}/{}'.format(prefix, 'test')\n",
    "\n",
    "# uploading data to S3, and saving locations\n",
    "train_path = sagemaker_session.upload_data(train_key, bucket=bucket, key_prefix=train_prefix)\n",
    "test_path = sagemaker_session.upload_data(test_key,  bucket=bucket, key_prefix=test_prefix)\n",
    "\n",
    "# check locations\n",
    "print('Training data is stored in: '+ train_path)\n",
    "print('Test data is stored in: '+ test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-viking",
   "metadata": {},
   "source": [
    "# Training a DeepAR Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "mexican-briefs",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sa-east-1'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region = sagemaker_session.boto_region_name\n",
    "region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sharing-negotiation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: latest.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'855470959533.dkr.ecr.sa-east-1.amazonaws.com/forecasting-deepar:1'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_name = sagemaker.amazon.amazon_estimator.get_image_uri(region, 'forecasting-deepar', 'latest')\n",
    "image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "alpha-palmer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-sa-east-1-072590943848/co2-emission/output'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dir to save model artifacts\n",
    "s3_output_path = \"s3://{}/{}/output\".format(bucket, prefix)\n",
    "s3_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "final-graham",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=image_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c4.2xlarge',\n",
    "    base_job_name='deepar-co2-emission',\n",
    "    output_path=s3_output_path\n",
    ")\n",
    "\n",
    "freq = '12M'\n",
    "\n",
    "hyperparameters = {\n",
    "    'time_freq': freq,\n",
    "    'epochs': '400',\n",
    "    'early_stopping_patience': '40',\n",
    "    'mini_batch_size': '64',\n",
    "    'learning_rate': '5E-4',\n",
    "    'context_length': '5',\n",
    "    'prediction_length': '5'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "asian-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "conceptual-leader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-23 02:42:36 Starting - Starting the training job...\n",
      "2021-02-23 02:43:00 Starting - Launching requested ML instancesProfilerReport-1614048156: InProgress\n",
      ".........\n",
      "2021-02-23 02:44:22 Starting - Preparing the instances for training...\n",
      "2021-02-23 02:45:02 Downloading - Downloading input data...\n",
      "2021-02-23 02:45:37 Training - Training image download completed. Training in progress..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:39 INFO 140240734582592] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:39 INFO 140240734582592] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'5E-4', u'prediction_length': u'5', u'epochs': u'400', u'time_freq': u'12M', u'context_length': u'5', u'mini_batch_size': u'64', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:39 INFO 140240734582592] Final configuration: {u'dropout_rate': u'0.10', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'num_eval_samples': u'100', u'learning_rate': u'5E-4', u'num_layers': u'2', u'epochs': u'400', u'embedding_dimension': u'10', u'num_cells': u'40', u'_num_kv_servers': u'auto', u'mini_batch_size': u'64', u'likelihood': u'student-t', u'num_dynamic_feat': u'auto', u'cardinality': u'auto', u'_num_gpus': u'auto', u'prediction_length': u'5', u'time_freq': u'12M', u'context_length': u'5', u'_kvstore': u'auto', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:39 INFO 140240734582592] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:39 INFO 140240734582592] Using early stopping with patience 40\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:39 INFO 140240734582592] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:39 INFO 140240734582592] [num_dynamic_feat=auto] `dynamic_feat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:39 INFO 140240734582592] Training set statistics:\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:39 INFO 140240734582592] Real time series\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:39 INFO 140240734582592] number of time series: 4\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:39 INFO 140240734582592] number of observations: 1010\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:39 INFO 140240734582592] mean target length: 252\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:39 INFO 140240734582592] min/mean/max target: 46.7550010681/16842.5960396/114658.898438\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:39 INFO 140240734582592] mean abs(target): 16842.5960396\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:39 INFO 140240734582592] contains missing values: no\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:39 INFO 140240734582592] Small number of time series. Doing 160 passes over dataset with prob 1.0 per epoch.\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:39 INFO 140240734582592] Test set statistics:\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:39 INFO 140240734582592] Real time series\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:39 INFO 140240734582592] number of time series: 4\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:39 INFO 140240734582592] number of observations: 1030\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:39 INFO 140240734582592] mean target length: 257\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:39 INFO 140240734582592] min/mean/max target: 46.7550010681/18551.134466/123731.265625\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:39 INFO 140240734582592] mean abs(target): 18551.134466\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:39 INFO 140240734582592] contains missing values: no\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:39 INFO 140240734582592] nvidia-smi took: 0.0251700878143 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:39 INFO 140240734582592] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:39 INFO 140240734582592] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 27.35304832458496, \"sum\": 27.35304832458496, \"min\": 27.35304832458496}}, \"EndTime\": 1614048339.96504, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048339.936789}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:39 INFO 140240734582592] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 74.9669075012207, \"sum\": 74.9669075012207, \"min\": 74.9669075012207}}, \"EndTime\": 1614048340.011896, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048339.965121}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:40 INFO 140240734582592] Epoch[0] Batch[0] avg_epoch_loss=9.915379\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:40 INFO 140240734582592] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=9.91537857056\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:40 INFO 140240734582592] Epoch[0] Batch[5] avg_epoch_loss=9.323830\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:40 INFO 140240734582592] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=9.32382965088\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:40 INFO 140240734582592] Epoch[0] Batch [5]#011Speed: 4584.19 samples/sec#011loss=9.323830\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:40 INFO 140240734582592] Epoch[0] Batch[10] avg_epoch_loss=9.343267\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:40 INFO 140240734582592] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=9.36659088135\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:40 INFO 140240734582592] Epoch[0] Batch [10]#011Speed: 5060.56 samples/sec#011loss=9.366591\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:40 INFO 140240734582592] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 400, \"sum\": 400.0, \"min\": 400}, \"update.time\": {\"count\": 1, \"max\": 436.6600513458252, \"sum\": 436.6600513458252, \"min\": 436.6600513458252}}, \"EndTime\": 1614048340.448709, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048340.011959}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:40 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1547.65029271 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:40 INFO 140240734582592] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:40 INFO 140240734582592] #quality_metric: host=algo-1, epoch=0, train loss <loss>=9.34326657382\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:40 INFO 140240734582592] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:40 INFO 140240734582592] Saved checkpoint to \"/opt/ml/model/state_616fa367-1a70-4362-81bb-e99726c8136e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 12.563943862915039, \"sum\": 12.563943862915039, \"min\": 12.563943862915039}}, \"EndTime\": 1614048340.461955, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048340.448803}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:40 INFO 140240734582592] Epoch[1] Batch[0] avg_epoch_loss=8.777746\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:40 INFO 140240734582592] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=8.77774620056\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:40 INFO 140240734582592] Epoch[1] Batch[5] avg_epoch_loss=8.506681\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:40 INFO 140240734582592] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=8.50668080648\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:40 INFO 140240734582592] Epoch[1] Batch [5]#011Speed: 4665.00 samples/sec#011loss=8.506681\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:40 INFO 140240734582592] Epoch[1] Batch[10] avg_epoch_loss=8.446882\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:40 INFO 140240734582592] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=8.37512254715\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:40 INFO 140240734582592] Epoch[1] Batch [10]#011Speed: 4987.54 samples/sec#011loss=8.375123\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:40 INFO 140240734582592] processed a total of 696 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 341.25709533691406, \"sum\": 341.25709533691406, \"min\": 341.25709533691406}}, \"EndTime\": 1614048340.803355, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048340.462034}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:40 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2038.84285205 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:40 INFO 140240734582592] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:40 INFO 140240734582592] #quality_metric: host=algo-1, epoch=1, train loss <loss>=8.44688159769\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:40 INFO 140240734582592] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:40 INFO 140240734582592] Saved checkpoint to \"/opt/ml/model/state_7dceaa60-263d-4105-9b0d-3b6956c1dbec-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 11.091947555541992, \"sum\": 11.091947555541992, \"min\": 11.091947555541992}}, \"EndTime\": 1614048340.814999, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048340.803432}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] Epoch[2] Batch[0] avg_epoch_loss=8.235662\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=8.23566246033\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] Epoch[2] Batch[5] avg_epoch_loss=8.227176\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=8.22717603048\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] Epoch[2] Batch [5]#011Speed: 4148.31 samples/sec#011loss=8.227176\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 347.4130630493164, \"sum\": 347.4130630493164, \"min\": 347.4130630493164}}, \"EndTime\": 1614048341.162547, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048340.815068}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1809.90013165 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] #quality_metric: host=algo-1, epoch=2, train loss <loss>=8.0866669178\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] Saved checkpoint to \"/opt/ml/model/state_6c2537cf-a5d1-46b3-81e3-d901dd4cd2f4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.690927505493164, \"sum\": 10.690927505493164, \"min\": 10.690927505493164}}, \"EndTime\": 1614048341.173811, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048341.162626}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] Epoch[3] Batch[0] avg_epoch_loss=7.987882\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=7.9878821373\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] Epoch[3] Batch[5] avg_epoch_loss=8.111765\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=8.11176522573\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] Epoch[3] Batch [5]#011Speed: 4358.84 samples/sec#011loss=8.111765\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] Epoch[3] Batch[10] avg_epoch_loss=8.183237\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=8.26900291443\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] Epoch[3] Batch [10]#011Speed: 5017.95 samples/sec#011loss=8.269003\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 359.88688468933105, \"sum\": 359.88688468933105, \"min\": 359.88688468933105}}, \"EndTime\": 1614048341.533802, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048341.173863}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1786.12582644 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] #quality_metric: host=algo-1, epoch=3, train loss <loss>=8.18323690241\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] Epoch[4] Batch[0] avg_epoch_loss=7.181030\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=7.18103027344\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] Epoch[4] Batch[5] avg_epoch_loss=7.469413\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=7.46941312154\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] Epoch[4] Batch [5]#011Speed: 4209.58 samples/sec#011loss=7.469413\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 317.13104248046875, \"sum\": 317.13104248046875, \"min\": 317.13104248046875}}, \"EndTime\": 1614048341.851453, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048341.533877}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1998.39233345 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] #quality_metric: host=algo-1, epoch=4, train loss <loss>=7.57788500786\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:41 INFO 140240734582592] Saved checkpoint to \"/opt/ml/model/state_e4ab9bb9-fa4b-47fe-a179-ef574d7cda70-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 11.148929595947266, \"sum\": 11.148929595947266, \"min\": 11.148929595947266}}, \"EndTime\": 1614048341.863215, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048341.851539}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:42 INFO 140240734582592] Epoch[5] Batch[0] avg_epoch_loss=7.399925\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:42 INFO 140240734582592] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=7.3999247551\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:42 INFO 140240734582592] Epoch[5] Batch[5] avg_epoch_loss=7.350773\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:42 INFO 140240734582592] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=7.3507733345\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:42 INFO 140240734582592] Epoch[5] Batch [5]#011Speed: 3809.39 samples/sec#011loss=7.350773\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:42 INFO 140240734582592] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 377.6979446411133, \"sum\": 377.6979446411133, \"min\": 377.6979446411133}}, \"EndTime\": 1614048342.241039, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048341.863283}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:42 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1688.66243865 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:42 INFO 140240734582592] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:42 INFO 140240734582592] #quality_metric: host=algo-1, epoch=5, train loss <loss>=7.31885523796\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:42 INFO 140240734582592] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:42 INFO 140240734582592] Saved checkpoint to \"/opt/ml/model/state_495237f4-2c53-4b47-8538-5de297446122-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 9.497880935668945, \"sum\": 9.497880935668945, \"min\": 9.497880935668945}}, \"EndTime\": 1614048342.251277, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048342.241117}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:42 INFO 140240734582592] Epoch[6] Batch[0] avg_epoch_loss=7.193563\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:42 INFO 140240734582592] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=7.19356298447\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:42 INFO 140240734582592] Epoch[6] Batch[5] avg_epoch_loss=7.138893\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:42 INFO 140240734582592] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=7.13889312744\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:42 INFO 140240734582592] Epoch[6] Batch [5]#011Speed: 3594.25 samples/sec#011loss=7.138893\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:42 INFO 140240734582592] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 409.4858169555664, \"sum\": 409.4858169555664, \"min\": 409.4858169555664}}, \"EndTime\": 1614048342.660877, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048342.251329}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:42 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1540.50844001 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:42 INFO 140240734582592] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:42 INFO 140240734582592] #quality_metric: host=algo-1, epoch=6, train loss <loss>=7.08048658371\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:42 INFO 140240734582592] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:42 INFO 140240734582592] Saved checkpoint to \"/opt/ml/model/state_f8951d34-1be7-45c0-86f0-ddfa31bd6954-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.868072509765625, \"sum\": 10.868072509765625, \"min\": 10.868072509765625}}, \"EndTime\": 1614048342.672358, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048342.660962}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:42 INFO 140240734582592] Epoch[7] Batch[0] avg_epoch_loss=6.667745\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:42 INFO 140240734582592] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=6.66774511337\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] Epoch[7] Batch[5] avg_epoch_loss=6.902464\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=6.90246423086\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] Epoch[7] Batch [5]#011Speed: 3844.26 samples/sec#011loss=6.902464\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 404.13904190063477, \"sum\": 404.13904190063477, \"min\": 404.13904190063477}}, \"EndTime\": 1614048343.076809, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048342.672608}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1503.97135177 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] #quality_metric: host=algo-1, epoch=7, train loss <loss>=7.19743671417\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] Epoch[8] Batch[0] avg_epoch_loss=7.074642\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=7.0746421814\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] Epoch[8] Batch[5] avg_epoch_loss=6.948465\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=6.94846471151\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] Epoch[8] Batch [5]#011Speed: 4925.44 samples/sec#011loss=6.948465\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 330.9969902038574, \"sum\": 330.9969902038574, \"min\": 330.9969902038574}}, \"EndTime\": 1614048343.408375, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048343.076894}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1866.47071632 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] #quality_metric: host=algo-1, epoch=8, train loss <loss>=6.90841464996\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] Saved checkpoint to \"/opt/ml/model/state_2b9396c7-10f2-43a4-ac8b-0521ef40a02c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 8.07499885559082, \"sum\": 8.07499885559082, \"min\": 8.07499885559082}}, \"EndTime\": 1614048343.417026, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048343.408439}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] Epoch[9] Batch[0] avg_epoch_loss=6.540998\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=6.54099798203\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] Epoch[9] Batch[5] avg_epoch_loss=6.956749\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=6.95674935977\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] Epoch[9] Batch [5]#011Speed: 4620.34 samples/sec#011loss=6.956749\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] Epoch[9] Batch[10] avg_epoch_loss=7.064498\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=7.19379644394\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] Epoch[9] Batch [10]#011Speed: 4626.01 samples/sec#011loss=7.193796\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 322.6490020751953, \"sum\": 322.6490020751953, \"min\": 322.6490020751953}}, \"EndTime\": 1614048343.739809, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048343.417099}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2066.52590026 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] #quality_metric: host=algo-1, epoch=9, train loss <loss>=7.06449803439\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] Epoch[10] Batch[0] avg_epoch_loss=7.046232\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:43 INFO 140240734582592] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=7.04623222351\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] Epoch[10] Batch[5] avg_epoch_loss=6.762562\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=6.7625617981\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] Epoch[10] Batch [5]#011Speed: 4229.39 samples/sec#011loss=6.762562\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] processed a total of 604 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 346.3931083679199, \"sum\": 346.3931083679199, \"min\": 346.3931083679199}}, \"EndTime\": 1614048344.086673, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048343.739884}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1743.13655085 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] #quality_metric: host=algo-1, epoch=10, train loss <loss>=6.68625617027\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] Saved checkpoint to \"/opt/ml/model/state_637b55fa-c5de-4dd6-90cd-d0915ba1b74c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 7.056951522827148, \"sum\": 7.056951522827148, \"min\": 7.056951522827148}}, \"EndTime\": 1614048344.094403, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048344.086752}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] Epoch[11] Batch[0] avg_epoch_loss=6.589060\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=6.58906030655\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] Epoch[11] Batch[5] avg_epoch_loss=6.812474\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=6.81247385343\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] Epoch[11] Batch [5]#011Speed: 3916.09 samples/sec#011loss=6.812474\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] Epoch[11] Batch[10] avg_epoch_loss=6.691775\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=6.54693727493\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] Epoch[11] Batch [10]#011Speed: 4059.47 samples/sec#011loss=6.546937\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 341.839075088501, \"sum\": 341.839075088501, \"min\": 341.839075088501}}, \"EndTime\": 1614048344.436356, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048344.09446}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1959.32790382 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] #quality_metric: host=algo-1, epoch=11, train loss <loss>=6.69177540866\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] Epoch[12] Batch[0] avg_epoch_loss=6.851186\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=6.85118579865\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] Epoch[12] Batch[5] avg_epoch_loss=6.856371\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=6.85637076696\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] Epoch[12] Batch [5]#011Speed: 4577.05 samples/sec#011loss=6.856371\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] Epoch[12] Batch[10] avg_epoch_loss=6.725956\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=6.56945819855\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] Epoch[12] Batch [10]#011Speed: 4420.87 samples/sec#011loss=6.569458\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 330.20496368408203, \"sum\": 330.20496368408203, \"min\": 330.20496368408203}}, \"EndTime\": 1614048344.767074, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048344.436434}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1943.61125222 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] #quality_metric: host=algo-1, epoch=12, train loss <loss>=6.72595596313\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] Epoch[13] Batch[0] avg_epoch_loss=6.465653\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:44 INFO 140240734582592] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=6.46565341949\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] Epoch[13] Batch[5] avg_epoch_loss=6.694684\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=6.69468363126\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] Epoch[13] Batch [5]#011Speed: 4186.90 samples/sec#011loss=6.694684\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 338.3219242095947, \"sum\": 338.3219242095947, \"min\": 338.3219242095947}}, \"EndTime\": 1614048345.105923, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048344.767154}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1802.32806201 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] #quality_metric: host=algo-1, epoch=13, train loss <loss>=6.48921298981\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] Saved checkpoint to \"/opt/ml/model/state_8f4a3971-9b5e-41de-a2c7-3e964236aa67-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 7.498025894165039, \"sum\": 7.498025894165039, \"min\": 7.498025894165039}}, \"EndTime\": 1614048345.114065, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048345.106}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] Epoch[14] Batch[0] avg_epoch_loss=7.242145\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=7.24214458466\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] Epoch[14] Batch[5] avg_epoch_loss=6.622628\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=6.62262773514\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] Epoch[14] Batch [5]#011Speed: 4462.23 samples/sec#011loss=6.622628\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 297.5630760192871, \"sum\": 297.5630760192871, \"min\": 297.5630760192871}}, \"EndTime\": 1614048345.411772, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048345.114142}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2129.76870223 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] #quality_metric: host=algo-1, epoch=14, train loss <loss>=6.55847406387\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] Epoch[15] Batch[0] avg_epoch_loss=6.498967\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=6.49896669388\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] Epoch[15] Batch[5] avg_epoch_loss=6.425517\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=6.4255165259\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] Epoch[15] Batch [5]#011Speed: 5355.73 samples/sec#011loss=6.425517\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] Epoch[15] Batch[10] avg_epoch_loss=6.359235\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=6.27969799042\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] Epoch[15] Batch [10]#011Speed: 4562.82 samples/sec#011loss=6.279698\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 368.08109283447266, \"sum\": 368.08109283447266, \"min\": 368.08109283447266}}, \"EndTime\": 1614048345.780424, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048345.411857}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1803.41179754 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] #quality_metric: host=algo-1, epoch=15, train loss <loss>=6.35923537341\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] Saved checkpoint to \"/opt/ml/model/state_eaabdc23-ffd9-432d-8e5f-07f10a9af621-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 11.607885360717773, \"sum\": 11.607885360717773, \"min\": 11.607885360717773}}, \"EndTime\": 1614048345.792625, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048345.780504}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] Epoch[16] Batch[0] avg_epoch_loss=6.939609\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:45 INFO 140240734582592] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=6.93960857391\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] Epoch[16] Batch[5] avg_epoch_loss=6.666399\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=6.66639947891\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] Epoch[16] Batch [5]#011Speed: 4396.33 samples/sec#011loss=6.666399\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 320.19591331481934, \"sum\": 320.19591331481934, \"min\": 320.19591331481934}}, \"EndTime\": 1614048346.112936, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048345.792684}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1960.63790295 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] #quality_metric: host=algo-1, epoch=16, train loss <loss>=6.51587696075\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] Epoch[17] Batch[0] avg_epoch_loss=6.399012\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=6.39901208878\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] Epoch[17] Batch[5] avg_epoch_loss=6.619005\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=6.61900496483\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] Epoch[17] Batch [5]#011Speed: 4242.23 samples/sec#011loss=6.619005\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] Epoch[17] Batch[10] avg_epoch_loss=6.465571\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=6.28144979477\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] Epoch[17] Batch [10]#011Speed: 4011.68 samples/sec#011loss=6.281450\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] processed a total of 694 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 336.5921974182129, \"sum\": 336.5921974182129, \"min\": 336.5921974182129}}, \"EndTime\": 1614048346.450186, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048346.11301}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2061.09034366 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] #quality_metric: host=algo-1, epoch=17, train loss <loss>=6.46557079662\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] Epoch[18] Batch[0] avg_epoch_loss=6.764704\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=6.76470375061\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] Epoch[18] Batch[5] avg_epoch_loss=6.507367\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=6.50736697515\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] Epoch[18] Batch [5]#011Speed: 4204.05 samples/sec#011loss=6.507367\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 349.5349884033203, \"sum\": 349.5349884033203, \"min\": 349.5349884033203}}, \"EndTime\": 1614048346.800266, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048346.450268}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1793.1709201 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] #quality_metric: host=algo-1, epoch=18, train loss <loss>=6.581980896\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:46 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] Epoch[19] Batch[0] avg_epoch_loss=6.406812\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=6.40681219101\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] Epoch[19] Batch[5] avg_epoch_loss=6.386613\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=6.38661297162\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] Epoch[19] Batch [5]#011Speed: 4723.88 samples/sec#011loss=6.386613\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] Epoch[19] Batch[10] avg_epoch_loss=6.508393\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=6.65452919006\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] Epoch[19] Batch [10]#011Speed: 4337.80 samples/sec#011loss=6.654529\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 354.1722297668457, \"sum\": 354.1722297668457, \"min\": 354.1722297668457}}, \"EndTime\": 1614048347.15499, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048346.800345}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1829.00516553 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] #quality_metric: host=algo-1, epoch=19, train loss <loss>=6.50839307091\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] Epoch[20] Batch[0] avg_epoch_loss=6.706833\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=6.70683288574\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] Epoch[20] Batch[5] avg_epoch_loss=6.713458\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=6.71345814069\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] Epoch[20] Batch [5]#011Speed: 4628.36 samples/sec#011loss=6.713458\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] Epoch[20] Batch[10] avg_epoch_loss=6.482473\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] #quality_metric: host=algo-1, epoch=20, batch=10 train loss <loss>=6.2052898407\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] Epoch[20] Batch [10]#011Speed: 4981.23 samples/sec#011loss=6.205290\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 328.9330005645752, \"sum\": 328.9330005645752, \"min\": 328.9330005645752}}, \"EndTime\": 1614048347.484449, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048347.155071}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2024.00224905 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] #quality_metric: host=algo-1, epoch=20, train loss <loss>=6.48247254979\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] Epoch[21] Batch[0] avg_epoch_loss=6.703036\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=6.70303630829\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] Epoch[21] Batch[5] avg_epoch_loss=6.551314\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=6.55131403605\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] Epoch[21] Batch [5]#011Speed: 5063.14 samples/sec#011loss=6.551314\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 352.20980644226074, \"sum\": 352.20980644226074, \"min\": 352.20980644226074}}, \"EndTime\": 1614048347.837195, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048347.48453}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1796.74867798 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] #quality_metric: host=algo-1, epoch=21, train loss <loss>=6.49219527245\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:47 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] Epoch[22] Batch[0] avg_epoch_loss=6.459006\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=6.45900583267\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] Epoch[22] Batch[5] avg_epoch_loss=6.693645\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=6.69364500046\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] Epoch[22] Batch [5]#011Speed: 4992.05 samples/sec#011loss=6.693645\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 297.3790168762207, \"sum\": 297.3790168762207, \"min\": 297.3790168762207}}, \"EndTime\": 1614048348.135167, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048347.837255}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2114.48472375 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] #quality_metric: host=algo-1, epoch=22, train loss <loss>=6.69869756699\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] Epoch[23] Batch[0] avg_epoch_loss=6.624711\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=6.62471103668\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] Epoch[23] Batch[5] avg_epoch_loss=6.590507\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=6.59050679207\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] Epoch[23] Batch [5]#011Speed: 4080.27 samples/sec#011loss=6.590507\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] Epoch[23] Batch[10] avg_epoch_loss=6.782570\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=7.01304540634\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] Epoch[23] Batch [10]#011Speed: 4310.28 samples/sec#011loss=7.013045\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 336.6358280181885, \"sum\": 336.6358280181885, \"min\": 336.6358280181885}}, \"EndTime\": 1614048348.472372, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048348.135228}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1918.38848367 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] #quality_metric: host=algo-1, epoch=23, train loss <loss>=6.78256979856\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] Epoch[24] Batch[0] avg_epoch_loss=6.862781\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=6.86278057098\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] Epoch[24] Batch[5] avg_epoch_loss=6.522103\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=6.52210275332\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] Epoch[24] Batch [5]#011Speed: 4678.42 samples/sec#011loss=6.522103\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] Epoch[24] Batch[10] avg_epoch_loss=6.557498\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=6.59997272491\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] Epoch[24] Batch [10]#011Speed: 3938.56 samples/sec#011loss=6.599973\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 325.8380889892578, \"sum\": 325.8380889892578, \"min\": 325.8380889892578}}, \"EndTime\": 1614048348.79876, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048348.472443}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1988.03554007 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] #quality_metric: host=algo-1, epoch=24, train loss <loss>=6.55749819495\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:48 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] Epoch[25] Batch[0] avg_epoch_loss=6.682514\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=6.68251371384\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] Epoch[25] Batch[5] avg_epoch_loss=6.561016\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=6.56101576487\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] Epoch[25] Batch [5]#011Speed: 5238.77 samples/sec#011loss=6.561016\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] Epoch[25] Batch[10] avg_epoch_loss=6.757628\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] #quality_metric: host=algo-1, epoch=25, batch=10 train loss <loss>=6.99356184006\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] Epoch[25] Batch [10]#011Speed: 4629.49 samples/sec#011loss=6.993562\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 354.31385040283203, \"sum\": 354.31385040283203, \"min\": 354.31385040283203}}, \"EndTime\": 1614048349.153615, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048348.798839}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1845.16930362 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] #quality_metric: host=algo-1, epoch=25, train loss <loss>=6.75762761723\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] Epoch[26] Batch[0] avg_epoch_loss=6.629905\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=6.62990522385\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] Epoch[26] Batch[5] avg_epoch_loss=6.739621\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=6.7396206061\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] Epoch[26] Batch [5]#011Speed: 4102.62 samples/sec#011loss=6.739621\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] Epoch[26] Batch[10] avg_epoch_loss=6.435755\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=6.07111616135\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] Epoch[26] Batch [10]#011Speed: 4072.08 samples/sec#011loss=6.071116\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 341.98498725891113, \"sum\": 341.98498725891113, \"min\": 341.98498725891113}}, \"EndTime\": 1614048349.496146, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048349.1537}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1949.77312219 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] #quality_metric: host=algo-1, epoch=26, train loss <loss>=6.4357549494\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] Epoch[27] Batch[0] avg_epoch_loss=6.374655\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=6.3746547699\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] Epoch[27] Batch[5] avg_epoch_loss=6.290705\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=6.29070512454\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] Epoch[27] Batch [5]#011Speed: 4347.19 samples/sec#011loss=6.290705\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] Epoch[27] Batch[10] avg_epoch_loss=6.376991\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=6.48053312302\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] Epoch[27] Batch [10]#011Speed: 5094.73 samples/sec#011loss=6.480533\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 316.38312339782715, \"sum\": 316.38312339782715, \"min\": 316.38312339782715}}, \"EndTime\": 1614048349.813084, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048349.496212}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2120.05075988 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] #quality_metric: host=algo-1, epoch=27, train loss <loss>=6.37699057839\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] Epoch[28] Batch[0] avg_epoch_loss=5.780742\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:49 INFO 140240734582592] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=5.78074216843\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] Epoch[28] Batch[5] avg_epoch_loss=6.455395\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=6.45539458593\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] Epoch[28] Batch [5]#011Speed: 4870.99 samples/sec#011loss=6.455395\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] Epoch[28] Batch[10] avg_epoch_loss=6.438741\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=6.41875696182\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] Epoch[28] Batch [10]#011Speed: 5131.33 samples/sec#011loss=6.418757\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 313.26889991760254, \"sum\": 313.26889991760254, \"min\": 313.26889991760254}}, \"EndTime\": 1614048350.126929, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048349.813165}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2058.17745818 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] #quality_metric: host=algo-1, epoch=28, train loss <loss>=6.43874112043\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] Epoch[29] Batch[0] avg_epoch_loss=6.479230\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=6.47922992706\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] Epoch[29] Batch[5] avg_epoch_loss=6.395993\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=6.39599299431\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] Epoch[29] Batch [5]#011Speed: 4903.54 samples/sec#011loss=6.395993\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] Epoch[29] Batch[10] avg_epoch_loss=6.172328\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=5.90393071175\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] Epoch[29] Batch [10]#011Speed: 4012.63 samples/sec#011loss=5.903931\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 377.4600028991699, \"sum\": 377.4600028991699, \"min\": 377.4600028991699}}, \"EndTime\": 1614048350.504925, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048350.127007}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1726.83686623 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] #quality_metric: host=algo-1, epoch=29, train loss <loss>=6.17232832042\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] Saved checkpoint to \"/opt/ml/model/state_4982b588-2e48-4025-9242-5003735cfccb-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 7.393121719360352, \"sum\": 7.393121719360352, \"min\": 7.393121719360352}}, \"EndTime\": 1614048350.512962, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048350.504996}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] Epoch[30] Batch[0] avg_epoch_loss=6.494107\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=6.49410676956\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] Epoch[30] Batch[5] avg_epoch_loss=6.514804\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=6.51480356852\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] Epoch[30] Batch [5]#011Speed: 4320.70 samples/sec#011loss=6.514804\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] Epoch[30] Batch[10] avg_epoch_loss=6.607100\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] #quality_metric: host=algo-1, epoch=30, batch=10 train loss <loss>=6.7178560257\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] Epoch[30] Batch [10]#011Speed: 4254.48 samples/sec#011loss=6.717856\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 333.5099220275879, \"sum\": 333.5099220275879, \"min\": 333.5099220275879}}, \"EndTime\": 1614048350.846627, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048350.513045}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2008.27245545 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] #quality_metric: host=algo-1, epoch=30, train loss <loss>=6.60710013996\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:50 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] Epoch[31] Batch[0] avg_epoch_loss=6.721478\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=6.72147798538\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] Epoch[31] Batch[5] avg_epoch_loss=6.454878\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=6.45487761497\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] Epoch[31] Batch [5]#011Speed: 4070.62 samples/sec#011loss=6.454878\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 317.75689125061035, \"sum\": 317.75689125061035, \"min\": 317.75689125061035}}, \"EndTime\": 1614048351.164975, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048350.846695}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1994.4758186 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] #quality_metric: host=algo-1, epoch=31, train loss <loss>=6.32771487236\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] Epoch[32] Batch[0] avg_epoch_loss=6.494490\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=6.4944896698\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] Epoch[32] Batch[5] avg_epoch_loss=6.466007\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=6.46600707372\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] Epoch[32] Batch [5]#011Speed: 4604.26 samples/sec#011loss=6.466007\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] processed a total of 598 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 318.68481636047363, \"sum\": 318.68481636047363, \"min\": 318.68481636047363}}, \"EndTime\": 1614048351.484228, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048351.165056}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1875.71842168 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] #quality_metric: host=algo-1, epoch=32, train loss <loss>=6.57093667984\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] Epoch[33] Batch[0] avg_epoch_loss=6.552098\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=6.55209779739\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] Epoch[33] Batch[5] avg_epoch_loss=6.397437\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=6.39743717511\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] Epoch[33] Batch [5]#011Speed: 4812.81 samples/sec#011loss=6.397437\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] Epoch[33] Batch[10] avg_epoch_loss=6.132465\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] #quality_metric: host=algo-1, epoch=33, batch=10 train loss <loss>=5.81449913979\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] Epoch[33] Batch [10]#011Speed: 5047.22 samples/sec#011loss=5.814499\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 325.4070281982422, \"sum\": 325.4070281982422, \"min\": 325.4070281982422}}, \"EndTime\": 1614048351.810189, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048351.484316}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2039.71288644 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] #quality_metric: host=algo-1, epoch=33, train loss <loss>=6.13246534087\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:51 INFO 140240734582592] Saved checkpoint to \"/opt/ml/model/state_7ed45c01-c576-472b-aa8c-9cf666c2b6b8-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 11.97504997253418, \"sum\": 11.97504997253418, \"min\": 11.97504997253418}}, \"EndTime\": 1614048351.822773, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048351.81028}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] Epoch[34] Batch[0] avg_epoch_loss=6.018589\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=6.01858901978\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] Epoch[34] Batch[5] avg_epoch_loss=6.341879\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=6.34187936783\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] Epoch[34] Batch [5]#011Speed: 4562.03 samples/sec#011loss=6.341879\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 312.59989738464355, \"sum\": 312.59989738464355, \"min\": 312.59989738464355}}, \"EndTime\": 1614048352.135521, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048351.822854}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1998.52251563 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] #quality_metric: host=algo-1, epoch=34, train loss <loss>=6.46024794579\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] Epoch[35] Batch[0] avg_epoch_loss=6.278671\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=6.27867126465\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] Epoch[35] Batch[5] avg_epoch_loss=6.195883\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=6.19588319461\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] Epoch[35] Batch [5]#011Speed: 4343.93 samples/sec#011loss=6.195883\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] Epoch[35] Batch[10] avg_epoch_loss=6.574632\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] #quality_metric: host=algo-1, epoch=35, batch=10 train loss <loss>=7.02912960052\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] Epoch[35] Batch [10]#011Speed: 4805.74 samples/sec#011loss=7.029130\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 351.0701656341553, \"sum\": 351.0701656341553, \"min\": 351.0701656341553}}, \"EndTime\": 1614048352.487155, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048352.135612}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1830.94336979 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] #quality_metric: host=algo-1, epoch=35, train loss <loss>=6.57463156093\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] Epoch[36] Batch[0] avg_epoch_loss=6.610605\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=6.61060476303\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] Epoch[36] Batch[5] avg_epoch_loss=6.496679\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=6.4966793855\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] Epoch[36] Batch [5]#011Speed: 4275.73 samples/sec#011loss=6.496679\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 323.0400085449219, \"sum\": 323.0400085449219, \"min\": 323.0400085449219}}, \"EndTime\": 1614048352.810722, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048352.487234}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1937.08989098 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] #quality_metric: host=algo-1, epoch=36, train loss <loss>=6.37888245583\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] Epoch[37] Batch[0] avg_epoch_loss=6.601943\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:52 INFO 140240734582592] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=6.60194301605\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] Epoch[37] Batch[5] avg_epoch_loss=6.218639\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=6.21863937378\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] Epoch[37] Batch [5]#011Speed: 4684.74 samples/sec#011loss=6.218639\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 307.29198455810547, \"sum\": 307.29198455810547, \"min\": 307.29198455810547}}, \"EndTime\": 1614048353.118624, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048352.810803}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2081.89560874 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] #quality_metric: host=algo-1, epoch=37, train loss <loss>=6.199995327\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] Epoch[38] Batch[0] avg_epoch_loss=5.994706\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=5.99470615387\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] Epoch[38] Batch[5] avg_epoch_loss=6.420939\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=6.42093880971\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] Epoch[38] Batch [5]#011Speed: 5218.87 samples/sec#011loss=6.420939\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 301.44619941711426, \"sum\": 301.44619941711426, \"min\": 301.44619941711426}}, \"EndTime\": 1614048353.420716, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048353.118702}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2069.06052442 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] #quality_metric: host=algo-1, epoch=38, train loss <loss>=6.42180538177\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] Epoch[39] Batch[0] avg_epoch_loss=6.250169\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=6.25016880035\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] Epoch[39] Batch[5] avg_epoch_loss=6.490970\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=6.49096957843\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] Epoch[39] Batch [5]#011Speed: 4449.20 samples/sec#011loss=6.490970\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 309.69715118408203, \"sum\": 309.69715118408203, \"min\": 309.69715118408203}}, \"EndTime\": 1614048353.731096, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048353.420808}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2010.9104112 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] #quality_metric: host=algo-1, epoch=39, train loss <loss>=6.41671910286\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] Epoch[40] Batch[0] avg_epoch_loss=6.165433\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=6.16543340683\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] Epoch[40] Batch[5] avg_epoch_loss=6.362938\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=6.36293808619\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:53 INFO 140240734582592] Epoch[40] Batch [5]#011Speed: 3899.30 samples/sec#011loss=6.362938\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 322.2181797027588, \"sum\": 322.2181797027588, \"min\": 322.2181797027588}}, \"EndTime\": 1614048354.053899, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048353.731174}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1942.13919814 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] #quality_metric: host=algo-1, epoch=40, train loss <loss>=6.3209405899\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] Epoch[41] Batch[0] avg_epoch_loss=6.633167\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=6.63316726685\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] Epoch[41] Batch[5] avg_epoch_loss=6.375408\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=6.37540769577\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] Epoch[41] Batch [5]#011Speed: 5317.55 samples/sec#011loss=6.375408\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] processed a total of 601 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 283.174991607666, \"sum\": 283.174991607666, \"min\": 283.174991607666}}, \"EndTime\": 1614048354.337629, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048354.053969}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2121.5694642 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] #quality_metric: host=algo-1, epoch=41, train loss <loss>=6.4558763504\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] Epoch[42] Batch[0] avg_epoch_loss=6.664205\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=6.66420507431\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] Epoch[42] Batch[5] avg_epoch_loss=6.535075\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=6.53507479032\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] Epoch[42] Batch [5]#011Speed: 4850.48 samples/sec#011loss=6.535075\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 304.85987663269043, \"sum\": 304.85987663269043, \"min\": 304.85987663269043}}, \"EndTime\": 1614048354.643102, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048354.337701}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2075.56027111 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] #quality_metric: host=algo-1, epoch=42, train loss <loss>=6.56443729401\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] Epoch[43] Batch[0] avg_epoch_loss=6.691050\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=6.69104957581\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] Epoch[43] Batch[5] avg_epoch_loss=6.373650\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=6.37365031242\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] Epoch[43] Batch [5]#011Speed: 5011.73 samples/sec#011loss=6.373650\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] Epoch[43] Batch[10] avg_epoch_loss=6.256945\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] #quality_metric: host=algo-1, epoch=43, batch=10 train loss <loss>=6.11689853668\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] Epoch[43] Batch [10]#011Speed: 4555.54 samples/sec#011loss=6.116899\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 347.7141857147217, \"sum\": 347.7141857147217, \"min\": 347.7141857147217}}, \"EndTime\": 1614048354.991368, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048354.643183}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1886.01596297 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] #quality_metric: host=algo-1, epoch=43, train loss <loss>=6.25694495981\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:54 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] Epoch[44] Batch[0] avg_epoch_loss=6.367733\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=6.36773300171\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] Epoch[44] Batch[5] avg_epoch_loss=6.288546\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=6.28854552905\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] Epoch[44] Batch [5]#011Speed: 5248.42 samples/sec#011loss=6.288546\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] Epoch[44] Batch[10] avg_epoch_loss=6.321242\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] #quality_metric: host=algo-1, epoch=44, batch=10 train loss <loss>=6.36047801971\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] Epoch[44] Batch [10]#011Speed: 4985.97 samples/sec#011loss=6.360478\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 305.15599250793457, \"sum\": 305.15599250793457, \"min\": 305.15599250793457}}, \"EndTime\": 1614048355.297077, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048354.991437}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2204.51826317 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] #quality_metric: host=algo-1, epoch=44, train loss <loss>=6.32124211571\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] Epoch[45] Batch[0] avg_epoch_loss=6.316422\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=6.31642150879\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] Epoch[45] Batch[5] avg_epoch_loss=6.111060\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=6.1110599041\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] Epoch[45] Batch [5]#011Speed: 4244.70 samples/sec#011loss=6.111060\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 308.14099311828613, \"sum\": 308.14099311828613, \"min\": 308.14099311828613}}, \"EndTime\": 1614048355.605866, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048355.297162}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2069.69448569 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] #quality_metric: host=algo-1, epoch=45, train loss <loss>=6.13696026802\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] Epoch[46] Batch[0] avg_epoch_loss=6.847400\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=6.84740018845\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] Epoch[46] Batch[5] avg_epoch_loss=6.495512\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=6.49551177025\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] Epoch[46] Batch [5]#011Speed: 4711.34 samples/sec#011loss=6.495512\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] Epoch[46] Batch[10] avg_epoch_loss=6.606857\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=6.74047212601\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] Epoch[46] Batch [10]#011Speed: 5044.87 samples/sec#011loss=6.740472\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 305.88698387145996, \"sum\": 305.88698387145996, \"min\": 305.88698387145996}}, \"EndTime\": 1614048355.912315, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048355.605946}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2101.27939639 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] #quality_metric: host=algo-1, epoch=46, train loss <loss>=6.6068573865\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:55 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] Epoch[47] Batch[0] avg_epoch_loss=6.764716\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=6.76471614838\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] Epoch[47] Batch[5] avg_epoch_loss=6.208321\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=6.20832109451\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] Epoch[47] Batch [5]#011Speed: 4621.27 samples/sec#011loss=6.208321\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] processed a total of 596 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 301.1820316314697, \"sum\": 301.1820316314697, \"min\": 301.1820316314697}}, \"EndTime\": 1614048356.21403, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048355.912397}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1978.05547058 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] #quality_metric: host=algo-1, epoch=47, train loss <loss>=6.47986364365\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] Epoch[48] Batch[0] avg_epoch_loss=5.784299\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=5.78429889679\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] Epoch[48] Batch[5] avg_epoch_loss=6.436976\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=6.43697619438\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] Epoch[48] Batch [5]#011Speed: 4292.36 samples/sec#011loss=6.436976\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] Epoch[48] Batch[10] avg_epoch_loss=6.195044\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] #quality_metric: host=algo-1, epoch=48, batch=10 train loss <loss>=5.9047249794\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] Epoch[48] Batch [10]#011Speed: 4083.56 samples/sec#011loss=5.904725\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 331.50410652160645, \"sum\": 331.50410652160645, \"min\": 331.50410652160645}}, \"EndTime\": 1614048356.546159, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048356.214117}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1990.16409518 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] #quality_metric: host=algo-1, epoch=48, train loss <loss>=6.19504382394\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] Epoch[49] Batch[0] avg_epoch_loss=6.429893\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=6.42989253998\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] Epoch[49] Batch[5] avg_epoch_loss=6.216790\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=6.21679011981\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] Epoch[49] Batch [5]#011Speed: 4184.16 samples/sec#011loss=6.216790\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] Epoch[49] Batch[10] avg_epoch_loss=6.148904\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] #quality_metric: host=algo-1, epoch=49, batch=10 train loss <loss>=6.06743974686\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] Epoch[49] Batch [10]#011Speed: 4057.92 samples/sec#011loss=6.067440\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 329.5459747314453, \"sum\": 329.5459747314453, \"min\": 329.5459747314453}}, \"EndTime\": 1614048356.876359, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048356.546246}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1953.58192927 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] #quality_metric: host=algo-1, epoch=49, train loss <loss>=6.14890358665\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:56 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] Epoch[50] Batch[0] avg_epoch_loss=5.784420\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=5.78442001343\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] Epoch[50] Batch[5] avg_epoch_loss=6.068257\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=6.06825749079\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] Epoch[50] Batch [5]#011Speed: 4113.39 samples/sec#011loss=6.068257\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 317.49796867370605, \"sum\": 317.49796867370605, \"min\": 317.49796867370605}}, \"EndTime\": 1614048357.194392, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048356.87643}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1986.662401 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] #quality_metric: host=algo-1, epoch=50, train loss <loss>=6.16579346657\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] Epoch[51] Batch[0] avg_epoch_loss=6.174335\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=6.1743350029\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] Epoch[51] Batch[5] avg_epoch_loss=6.233040\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=6.23304009438\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] Epoch[51] Batch [5]#011Speed: 5269.91 samples/sec#011loss=6.233040\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] Epoch[51] Batch[10] avg_epoch_loss=6.287325\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=6.35246734619\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] Epoch[51] Batch [10]#011Speed: 4756.04 samples/sec#011loss=6.352467\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 304.6689033508301, \"sum\": 304.6689033508301, \"min\": 304.6689033508301}}, \"EndTime\": 1614048357.499671, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048357.194475}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2132.71418882 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] #quality_metric: host=algo-1, epoch=51, train loss <loss>=6.28732520884\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] Epoch[52] Batch[0] avg_epoch_loss=5.774334\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=5.77433443069\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] Epoch[52] Batch[5] avg_epoch_loss=6.058304\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=6.05830383301\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] Epoch[52] Batch [5]#011Speed: 3270.79 samples/sec#011loss=6.058304\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 395.45202255249023, \"sum\": 395.45202255249023, \"min\": 395.45202255249023}}, \"EndTime\": 1614048357.895692, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048357.499743}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1600.14996962 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] #quality_metric: host=algo-1, epoch=52, train loss <loss>=6.29531598091\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:57 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] Epoch[53] Batch[0] avg_epoch_loss=5.650482\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=5.65048217773\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] Epoch[53] Batch[5] avg_epoch_loss=6.002391\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=6.00239054362\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] Epoch[53] Batch [5]#011Speed: 4841.30 samples/sec#011loss=6.002391\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 299.37100410461426, \"sum\": 299.37100410461426, \"min\": 299.37100410461426}}, \"EndTime\": 1614048358.195638, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048357.895785}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2070.1993402 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] #quality_metric: host=algo-1, epoch=53, train loss <loss>=6.0108080864\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] Saved checkpoint to \"/opt/ml/model/state_ddaf1526-0cf5-4eb2-905c-172b4afb5b32-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 11.276960372924805, \"sum\": 11.276960372924805, \"min\": 11.276960372924805}}, \"EndTime\": 1614048358.207475, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048358.195716}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] Epoch[54] Batch[0] avg_epoch_loss=6.093429\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=6.09342908859\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] Epoch[54] Batch[5] avg_epoch_loss=6.021188\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=6.02118825912\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] Epoch[54] Batch [5]#011Speed: 4941.85 samples/sec#011loss=6.021188\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 338.99807929992676, \"sum\": 338.99807929992676, \"min\": 338.99807929992676}}, \"EndTime\": 1614048358.546592, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048358.207535}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1845.9209757 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] #quality_metric: host=algo-1, epoch=54, train loss <loss>=6.16179695129\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] Epoch[55] Batch[0] avg_epoch_loss=6.747346\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=6.74734640121\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] Epoch[55] Batch[5] avg_epoch_loss=6.496927\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=6.49692702293\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] Epoch[55] Batch [5]#011Speed: 4408.75 samples/sec#011loss=6.496927\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] Epoch[55] Batch[10] avg_epoch_loss=6.630703\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=6.79123487473\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] Epoch[55] Batch [10]#011Speed: 4499.38 samples/sec#011loss=6.791235\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 359.9259853363037, \"sum\": 359.9259853363037, \"min\": 359.9259853363037}}, \"EndTime\": 1614048358.907111, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048358.546681}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1877.50601522 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] #quality_metric: host=algo-1, epoch=55, train loss <loss>=6.6307033192\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:58 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] Epoch[56] Batch[0] avg_epoch_loss=6.011857\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=6.01185655594\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] Epoch[56] Batch[5] avg_epoch_loss=6.257047\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=6.25704693794\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] Epoch[56] Batch [5]#011Speed: 5044.93 samples/sec#011loss=6.257047\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 293.9341068267822, \"sum\": 293.9341068267822, \"min\": 293.9341068267822}}, \"EndTime\": 1614048359.20159, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048358.907203}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2118.60156561 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] #quality_metric: host=algo-1, epoch=56, train loss <loss>=6.36856279373\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] Epoch[57] Batch[0] avg_epoch_loss=6.146202\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=6.1462020874\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] Epoch[57] Batch[5] avg_epoch_loss=6.329507\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=6.32950727145\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] Epoch[57] Batch [5]#011Speed: 5157.54 samples/sec#011loss=6.329507\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] Epoch[57] Batch[10] avg_epoch_loss=6.606197\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] #quality_metric: host=algo-1, epoch=57, batch=10 train loss <loss>=6.93822517395\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] Epoch[57] Batch [10]#011Speed: 4863.51 samples/sec#011loss=6.938225\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 303.5409450531006, \"sum\": 303.5409450531006, \"min\": 303.5409450531006}}, \"EndTime\": 1614048359.505722, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048359.201673}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2117.54863683 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] #quality_metric: host=algo-1, epoch=57, train loss <loss>=6.60619722713\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] Epoch[58] Batch[0] avg_epoch_loss=5.883155\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=5.88315534592\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] Epoch[58] Batch[5] avg_epoch_loss=6.160688\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=6.1606880029\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] Epoch[58] Batch [5]#011Speed: 4047.46 samples/sec#011loss=6.160688\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 330.8830261230469, \"sum\": 330.8830261230469, \"min\": 330.8830261230469}}, \"EndTime\": 1614048359.837117, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048359.505798}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1882.17471683 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] #quality_metric: host=algo-1, epoch=58, train loss <loss>=6.17014732361\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:45:59 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] Epoch[59] Batch[0] avg_epoch_loss=5.878707\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=5.87870693207\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] Epoch[59] Batch[5] avg_epoch_loss=6.102969\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=6.10296932856\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] Epoch[59] Batch [5]#011Speed: 4899.78 samples/sec#011loss=6.102969\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] Epoch[59] Batch[10] avg_epoch_loss=5.880690\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] #quality_metric: host=algo-1, epoch=59, batch=10 train loss <loss>=5.61395516396\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] Epoch[59] Batch [10]#011Speed: 4615.47 samples/sec#011loss=5.613955\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 360.5961799621582, \"sum\": 360.5961799621582, \"min\": 360.5961799621582}}, \"EndTime\": 1614048360.198317, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048359.837197}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1807.50608112 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] #quality_metric: host=algo-1, epoch=59, train loss <loss>=5.88069016283\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] Saved checkpoint to \"/opt/ml/model/state_952c326e-ceda-490d-b64e-a9aaf541a1fc-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 7.1010589599609375, \"sum\": 7.1010589599609375, \"min\": 7.1010589599609375}}, \"EndTime\": 1614048360.206026, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048360.198399}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] Epoch[60] Batch[0] avg_epoch_loss=6.073630\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=6.07362985611\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] Epoch[60] Batch[5] avg_epoch_loss=6.270949\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=6.27094896634\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] Epoch[60] Batch [5]#011Speed: 4689.19 samples/sec#011loss=6.270949\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 303.9529323577881, \"sum\": 303.9529323577881, \"min\": 303.9529323577881}}, \"EndTime\": 1614048360.510091, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048360.206069}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2071.83776007 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] #quality_metric: host=algo-1, epoch=60, train loss <loss>=6.29835214615\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] Epoch[61] Batch[0] avg_epoch_loss=6.325345\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=6.32534503937\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] Epoch[61] Batch[5] avg_epoch_loss=6.093629\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=6.09362904231\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] Epoch[61] Batch [5]#011Speed: 4198.27 samples/sec#011loss=6.093629\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] Epoch[61] Batch[10] avg_epoch_loss=6.372882\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] #quality_metric: host=algo-1, epoch=61, batch=10 train loss <loss>=6.70798578262\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] Epoch[61] Batch [10]#011Speed: 4554.51 samples/sec#011loss=6.707986\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 328.3689022064209, \"sum\": 328.3689022064209, \"min\": 328.3689022064209}}, \"EndTime\": 1614048360.839049, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048360.510164}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2000.16964939 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] #quality_metric: host=algo-1, epoch=61, train loss <loss>=6.37288210609\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:00 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:01 INFO 140240734582592] Epoch[62] Batch[0] avg_epoch_loss=6.210907\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:01 INFO 140240734582592] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=6.21090745926\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:01 INFO 140240734582592] Epoch[62] Batch[5] avg_epoch_loss=6.221605\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:01 INFO 140240734582592] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=6.22160482407\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:01 INFO 140240734582592] Epoch[62] Batch [5]#011Speed: 4145.99 samples/sec#011loss=6.221605\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:01 INFO 140240734582592] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 312.95299530029297, \"sum\": 312.95299530029297, \"min\": 312.95299530029297}}, \"EndTime\": 1614048361.152565, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048360.839115}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:01 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2034.72863371 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:01 INFO 140240734582592] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:01 INFO 140240734582592] #quality_metric: host=algo-1, epoch=62, train loss <loss>=6.31218113899\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:01 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:01 INFO 140240734582592] Epoch[63] Batch[0] avg_epoch_loss=6.518461\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:01 INFO 140240734582592] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=6.51846075058\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:01 INFO 140240734582592] Epoch[63] Batch[5] avg_epoch_loss=6.350855\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:01 INFO 140240734582592] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=6.35085471471\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:01 INFO 140240734582592] Epoch[63] Batch [5]#011Speed: 4453.23 samples/sec#011loss=6.350855\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:01 INFO 140240734582592] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 296.43702507019043, \"sum\": 296.43702507019043, \"min\": 296.43702507019043}}, \"EndTime\": 1614048361.44961, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048361.152642}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:01 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2067.04330559 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:01 INFO 140240734582592] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:01 INFO 140240734582592] #quality_metric: host=algo-1, epoch=63, train loss <loss>=6.17464923859\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:01 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:01 INFO 140240734582592] Epoch[64] Batch[0] avg_epoch_loss=6.350102\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:01 INFO 140240734582592] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=6.35010194778\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:01 INFO 140240734582592] Epoch[64] Batch[5] avg_epoch_loss=6.188215\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:01 INFO 140240734582592] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=6.18821549416\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:01 INFO 140240734582592] Epoch[64] Batch [5]#011Speed: 3463.43 samples/sec#011loss=6.188215\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:01 INFO 140240734582592] processed a total of 605 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 384.7827911376953, \"sum\": 384.7827911376953, \"min\": 384.7827911376953}}, \"EndTime\": 1614048361.834969, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048361.449692}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:01 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1571.84522346 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:01 INFO 140240734582592] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:01 INFO 140240734582592] #quality_metric: host=algo-1, epoch=64, train loss <loss>=6.11540050507\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:01 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] Epoch[65] Batch[0] avg_epoch_loss=6.113784\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=6.1137843132\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] Epoch[65] Batch[5] avg_epoch_loss=6.196945\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=6.19694487254\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] Epoch[65] Batch [5]#011Speed: 3906.87 samples/sec#011loss=6.196945\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] Epoch[65] Batch[10] avg_epoch_loss=5.827380\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=5.38390183449\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] Epoch[65] Batch [10]#011Speed: 3858.35 samples/sec#011loss=5.383902\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 347.83411026000977, \"sum\": 347.83411026000977, \"min\": 347.83411026000977}}, \"EndTime\": 1614048362.183392, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048361.835042}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1882.52929044 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] #quality_metric: host=algo-1, epoch=65, train loss <loss>=5.82737985524\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] Saved checkpoint to \"/opt/ml/model/state_42223a8a-da24-4832-96f7-bb781b12f14f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 7.994174957275391, \"sum\": 7.994174957275391, \"min\": 7.994174957275391}}, \"EndTime\": 1614048362.191986, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048362.183452}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] Epoch[66] Batch[0] avg_epoch_loss=6.229971\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=6.22997093201\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] Epoch[66] Batch[5] avg_epoch_loss=6.424119\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=6.42411875725\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] Epoch[66] Batch [5]#011Speed: 4136.29 samples/sec#011loss=6.424119\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] Epoch[66] Batch[10] avg_epoch_loss=6.384708\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=6.33741474152\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] Epoch[66] Batch [10]#011Speed: 3921.33 samples/sec#011loss=6.337415\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 334.3930244445801, \"sum\": 334.3930244445801, \"min\": 334.3930244445801}}, \"EndTime\": 1614048362.526494, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048362.192052}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1940.24479229 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] #quality_metric: host=algo-1, epoch=66, train loss <loss>=6.38470784101\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] Epoch[67] Batch[0] avg_epoch_loss=6.439249\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=6.43924856186\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] Epoch[67] Batch[5] avg_epoch_loss=6.194948\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=6.19494827588\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] Epoch[67] Batch [5]#011Speed: 3842.60 samples/sec#011loss=6.194948\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 371.2759017944336, \"sum\": 371.2759017944336, \"min\": 371.2759017944336}}, \"EndTime\": 1614048362.898381, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048362.52656}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1715.18644168 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] #quality_metric: host=algo-1, epoch=67, train loss <loss>=6.14695706367\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:02 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] Epoch[68] Batch[0] avg_epoch_loss=5.489424\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=5.48942422867\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] Epoch[68] Batch[5] avg_epoch_loss=6.221082\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=6.22108213107\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] Epoch[68] Batch [5]#011Speed: 4222.91 samples/sec#011loss=6.221082\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] Epoch[68] Batch[10] avg_epoch_loss=5.922541\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=5.56429233551\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] Epoch[68] Batch [10]#011Speed: 4353.21 samples/sec#011loss=5.564292\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 364.6960258483887, \"sum\": 364.6960258483887, \"min\": 364.6960258483887}}, \"EndTime\": 1614048363.263578, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048362.898453}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1806.48948639 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] #quality_metric: host=algo-1, epoch=68, train loss <loss>=5.92254131491\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] Epoch[69] Batch[0] avg_epoch_loss=6.016457\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=6.01645708084\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] Epoch[69] Batch[5] avg_epoch_loss=6.358993\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=6.35899337133\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] Epoch[69] Batch [5]#011Speed: 4130.95 samples/sec#011loss=6.358993\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 345.53003311157227, \"sum\": 345.53003311157227, \"min\": 345.53003311157227}}, \"EndTime\": 1614048363.609567, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048363.263644}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1805.27840615 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] #quality_metric: host=algo-1, epoch=69, train loss <loss>=6.23249759674\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] Epoch[70] Batch[0] avg_epoch_loss=6.325086\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=6.32508611679\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] Epoch[70] Batch[5] avg_epoch_loss=6.262904\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=6.2629040877\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] Epoch[70] Batch [5]#011Speed: 3964.32 samples/sec#011loss=6.262904\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] Epoch[70] Batch[10] avg_epoch_loss=6.219816\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=6.16810970306\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] Epoch[70] Batch [10]#011Speed: 3931.89 samples/sec#011loss=6.168110\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] processed a total of 680 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 366.2240505218506, \"sum\": 366.2240505218506, \"min\": 366.2240505218506}}, \"EndTime\": 1614048363.976371, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048363.609651}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1856.18989046 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] #quality_metric: host=algo-1, epoch=70, train loss <loss>=6.21981573105\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:03 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:04 INFO 140240734582592] Epoch[71] Batch[0] avg_epoch_loss=5.856780\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:04 INFO 140240734582592] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=5.85677957535\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:04 INFO 140240734582592] Epoch[71] Batch[5] avg_epoch_loss=5.957893\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:04 INFO 140240734582592] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=5.95789265633\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:04 INFO 140240734582592] Epoch[71] Batch [5]#011Speed: 3973.97 samples/sec#011loss=5.957893\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:04 INFO 140240734582592] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 353.302001953125, \"sum\": 353.302001953125, \"min\": 353.302001953125}}, \"EndTime\": 1614048364.330287, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048363.976445}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:04 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1765.24493324 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:04 INFO 140240734582592] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:04 INFO 140240734582592] #quality_metric: host=algo-1, epoch=71, train loss <loss>=6.07750887871\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:04 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:04 INFO 140240734582592] Epoch[72] Batch[0] avg_epoch_loss=5.873233\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:04 INFO 140240734582592] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=5.87323284149\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:04 INFO 140240734582592] Epoch[72] Batch[5] avg_epoch_loss=6.026405\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:04 INFO 140240734582592] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=6.02640469869\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:04 INFO 140240734582592] Epoch[72] Batch [5]#011Speed: 4236.28 samples/sec#011loss=6.026405\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:04 INFO 140240734582592] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 376.2669563293457, \"sum\": 376.2669563293457, \"min\": 376.2669563293457}}, \"EndTime\": 1614048364.707157, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048364.330435}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:04 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1670.7125756 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:04 INFO 140240734582592] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:04 INFO 140240734582592] #quality_metric: host=algo-1, epoch=72, train loss <loss>=6.12099657059\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:04 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:04 INFO 140240734582592] Epoch[73] Batch[0] avg_epoch_loss=6.824204\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:04 INFO 140240734582592] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=6.82420396805\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] Epoch[73] Batch[5] avg_epoch_loss=6.333896\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=6.3338962396\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] Epoch[73] Batch [5]#011Speed: 3998.65 samples/sec#011loss=6.333896\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] Epoch[73] Batch[10] avg_epoch_loss=6.176781\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] #quality_metric: host=algo-1, epoch=73, batch=10 train loss <loss>=5.98824167252\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] Epoch[73] Batch [10]#011Speed: 4004.71 samples/sec#011loss=5.988242\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 393.4769630432129, \"sum\": 393.4769630432129, \"min\": 393.4769630432129}}, \"EndTime\": 1614048365.101375, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048364.707326}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1699.643701 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] #quality_metric: host=algo-1, epoch=73, train loss <loss>=6.17678052729\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] Epoch[74] Batch[0] avg_epoch_loss=6.182264\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=6.18226385117\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] Epoch[74] Batch[5] avg_epoch_loss=6.274326\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=6.2743259271\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] Epoch[74] Batch [5]#011Speed: 3861.24 samples/sec#011loss=6.274326\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 394.665002822876, \"sum\": 394.665002822876, \"min\": 394.665002822876}}, \"EndTime\": 1614048365.496535, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048365.101455}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1573.07203308 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] #quality_metric: host=algo-1, epoch=74, train loss <loss>=6.29718413353\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] Epoch[75] Batch[0] avg_epoch_loss=6.004354\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=6.00435447693\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] Epoch[75] Batch[5] avg_epoch_loss=6.079281\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=6.07928101222\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] Epoch[75] Batch [5]#011Speed: 4299.80 samples/sec#011loss=6.079281\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] processed a total of 614 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 309.85307693481445, \"sum\": 309.85307693481445, \"min\": 309.85307693481445}}, \"EndTime\": 1614048365.80681, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048365.496602}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1980.81158042 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] #quality_metric: host=algo-1, epoch=75, train loss <loss>=6.13625683784\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] Epoch[76] Batch[0] avg_epoch_loss=6.415399\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:05 INFO 140240734582592] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=6.41539859772\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] Epoch[76] Batch[5] avg_epoch_loss=6.174076\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=6.17407592138\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] Epoch[76] Batch [5]#011Speed: 5020.47 samples/sec#011loss=6.174076\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] Epoch[76] Batch[10] avg_epoch_loss=6.262184\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] #quality_metric: host=algo-1, epoch=76, batch=10 train loss <loss>=6.36791315079\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] Epoch[76] Batch [10]#011Speed: 4058.03 samples/sec#011loss=6.367913\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 319.4608688354492, \"sum\": 319.4608688354492, \"min\": 319.4608688354492}}, \"EndTime\": 1614048366.126852, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048365.806891}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2052.69978484 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] #quality_metric: host=algo-1, epoch=76, train loss <loss>=6.26218375293\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] Epoch[77] Batch[0] avg_epoch_loss=6.265078\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=6.26507806778\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] Epoch[77] Batch[5] avg_epoch_loss=6.238085\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=6.23808542887\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] Epoch[77] Batch [5]#011Speed: 4592.82 samples/sec#011loss=6.238085\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] Epoch[77] Batch[10] avg_epoch_loss=6.465300\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] #quality_metric: host=algo-1, epoch=77, batch=10 train loss <loss>=6.73795833588\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] Epoch[77] Batch [10]#011Speed: 4839.26 samples/sec#011loss=6.737958\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 335.44015884399414, \"sum\": 335.44015884399414, \"min\": 335.44015884399414}}, \"EndTime\": 1614048366.462803, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048366.126934}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1910.26219817 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] #quality_metric: host=algo-1, epoch=77, train loss <loss>=6.4653003866\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] Epoch[78] Batch[0] avg_epoch_loss=6.115257\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=6.11525726318\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] Epoch[78] Batch[5] avg_epoch_loss=6.169002\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=6.16900237401\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] Epoch[78] Batch [5]#011Speed: 5045.42 samples/sec#011loss=6.169002\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] Epoch[78] Batch[10] avg_epoch_loss=6.029695\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] #quality_metric: host=algo-1, epoch=78, batch=10 train loss <loss>=5.86252613068\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] Epoch[78] Batch [10]#011Speed: 4224.19 samples/sec#011loss=5.862526\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 331.03203773498535, \"sum\": 331.03203773498535, \"min\": 331.03203773498535}}, \"EndTime\": 1614048366.794354, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048366.462882}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2020.2205519 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] #quality_metric: host=algo-1, epoch=78, train loss <loss>=6.02969499068\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] Epoch[79] Batch[0] avg_epoch_loss=6.431878\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:06 INFO 140240734582592] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=6.43187761307\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] Epoch[79] Batch[5] avg_epoch_loss=6.218043\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=6.21804285049\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] Epoch[79] Batch [5]#011Speed: 4219.36 samples/sec#011loss=6.218043\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] Epoch[79] Batch[10] avg_epoch_loss=6.106072\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] #quality_metric: host=algo-1, epoch=79, batch=10 train loss <loss>=5.97170772552\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] Epoch[79] Batch [10]#011Speed: 4389.03 samples/sec#011loss=5.971708\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] processed a total of 699 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 338.1330966949463, \"sum\": 338.1330966949463, \"min\": 338.1330966949463}}, \"EndTime\": 1614048367.133066, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048366.794434}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2066.61692193 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] #quality_metric: host=algo-1, epoch=79, train loss <loss>=6.10607233914\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] Epoch[80] Batch[0] avg_epoch_loss=6.608741\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=6.60874080658\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] Epoch[80] Batch[5] avg_epoch_loss=6.362570\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=6.36257020632\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] Epoch[80] Batch [5]#011Speed: 5100.83 samples/sec#011loss=6.362570\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] Epoch[80] Batch[10] avg_epoch_loss=6.278766\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] #quality_metric: host=algo-1, epoch=80, batch=10 train loss <loss>=6.17820186615\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] Epoch[80] Batch [10]#011Speed: 4199.80 samples/sec#011loss=6.178202\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 315.96899032592773, \"sum\": 315.96899032592773, \"min\": 315.96899032592773}}, \"EndTime\": 1614048367.449649, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048367.13313}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2034.20398478 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] #quality_metric: host=algo-1, epoch=80, train loss <loss>=6.27876641534\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] Epoch[81] Batch[0] avg_epoch_loss=6.361143\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=6.36114311218\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] Epoch[81] Batch[5] avg_epoch_loss=6.488210\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=6.48820972443\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] Epoch[81] Batch [5]#011Speed: 4106.61 samples/sec#011loss=6.488210\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] Epoch[81] Batch[10] avg_epoch_loss=6.246990\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] #quality_metric: host=algo-1, epoch=81, batch=10 train loss <loss>=5.95752658844\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] Epoch[81] Batch [10]#011Speed: 4506.78 samples/sec#011loss=5.957527\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 336.8830680847168, \"sum\": 336.8830680847168, \"min\": 336.8830680847168}}, \"EndTime\": 1614048367.787078, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048367.44973}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1916.89149959 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] #quality_metric: host=algo-1, epoch=81, train loss <loss>=6.24699011716\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:07 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] Epoch[82] Batch[0] avg_epoch_loss=6.534986\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=6.53498601913\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] Epoch[82] Batch[5] avg_epoch_loss=6.127195\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=6.12719488144\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] Epoch[82] Batch [5]#011Speed: 3935.99 samples/sec#011loss=6.127195\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] Epoch[82] Batch[10] avg_epoch_loss=6.296328\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] #quality_metric: host=algo-1, epoch=82, batch=10 train loss <loss>=6.49928722382\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] Epoch[82] Batch [10]#011Speed: 4210.03 samples/sec#011loss=6.499287\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 379.61387634277344, \"sum\": 379.61387634277344, \"min\": 379.61387634277344}}, \"EndTime\": 1614048368.167213, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048367.787159}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1732.75146931 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] #quality_metric: host=algo-1, epoch=82, train loss <loss>=6.29632776434\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] Epoch[83] Batch[0] avg_epoch_loss=6.025394\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=6.0253944397\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] Epoch[83] Batch[5] avg_epoch_loss=6.253945\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=6.25394495328\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] Epoch[83] Batch [5]#011Speed: 4069.07 samples/sec#011loss=6.253945\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] Epoch[83] Batch[10] avg_epoch_loss=5.957712\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] #quality_metric: host=algo-1, epoch=83, batch=10 train loss <loss>=5.60223240852\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] Epoch[83] Batch [10]#011Speed: 4936.60 samples/sec#011loss=5.602232\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 326.5080451965332, \"sum\": 326.5080451965332, \"min\": 326.5080451965332}}, \"EndTime\": 1614048368.49426, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048368.167295}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1971.6448643 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] #quality_metric: host=algo-1, epoch=83, train loss <loss>=5.95771197839\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] Epoch[84] Batch[0] avg_epoch_loss=5.978973\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=5.97897338867\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] Epoch[84] Batch[5] avg_epoch_loss=6.212891\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=6.21289118131\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] Epoch[84] Batch [5]#011Speed: 4388.97 samples/sec#011loss=6.212891\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] Epoch[84] Batch[10] avg_epoch_loss=6.458263\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=6.75270814896\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] Epoch[84] Batch [10]#011Speed: 4374.58 samples/sec#011loss=6.752708\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 322.89886474609375, \"sum\": 322.89886474609375, \"min\": 322.89886474609375}}, \"EndTime\": 1614048368.81769, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048368.494344}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2037.06929138 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] #quality_metric: host=algo-1, epoch=84, train loss <loss>=6.45826253024\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:08 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] Epoch[85] Batch[0] avg_epoch_loss=6.060057\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=6.06005716324\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] Epoch[85] Batch[5] avg_epoch_loss=6.252735\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=6.25273545583\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] Epoch[85] Batch [5]#011Speed: 4147.07 samples/sec#011loss=6.252735\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] Epoch[85] Batch[10] avg_epoch_loss=6.029944\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] #quality_metric: host=algo-1, epoch=85, batch=10 train loss <loss>=5.7625934124\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] Epoch[85] Batch [10]#011Speed: 4096.21 samples/sec#011loss=5.762593\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 339.45202827453613, \"sum\": 339.45202827453613, \"min\": 339.45202827453613}}, \"EndTime\": 1614048369.157714, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048368.817765}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1908.34510607 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] #quality_metric: host=algo-1, epoch=85, train loss <loss>=6.02994361791\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] Epoch[86] Batch[0] avg_epoch_loss=6.480369\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=6.48036909103\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] Epoch[86] Batch[5] avg_epoch_loss=6.363939\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=6.36393944422\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] Epoch[86] Batch [5]#011Speed: 4149.91 samples/sec#011loss=6.363939\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] Epoch[86] Batch[10] avg_epoch_loss=6.389670\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] #quality_metric: host=algo-1, epoch=86, batch=10 train loss <loss>=6.42054719925\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] Epoch[86] Batch [10]#011Speed: 4129.03 samples/sec#011loss=6.420547\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] processed a total of 679 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 336.1830711364746, \"sum\": 336.1830711364746, \"min\": 336.1830711364746}}, \"EndTime\": 1614048369.494485, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048369.157799}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2019.18728336 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] #quality_metric: host=algo-1, epoch=86, train loss <loss>=6.38967024196\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] Epoch[87] Batch[0] avg_epoch_loss=6.279201\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=6.27920103073\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] Epoch[87] Batch[5] avg_epoch_loss=6.292260\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=6.29225969315\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] Epoch[87] Batch [5]#011Speed: 4812.83 samples/sec#011loss=6.292260\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] Epoch[87] Batch[10] avg_epoch_loss=6.268736\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=6.24050836563\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] Epoch[87] Batch [10]#011Speed: 4310.82 samples/sec#011loss=6.240508\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 319.6520805358887, \"sum\": 319.6520805358887, \"min\": 319.6520805358887}}, \"EndTime\": 1614048369.814704, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048369.49455}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2032.73009245 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] #quality_metric: host=algo-1, epoch=87, train loss <loss>=6.26873636246\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:09 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] Epoch[88] Batch[0] avg_epoch_loss=6.805721\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=6.80572080612\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] Epoch[88] Batch[5] avg_epoch_loss=6.433824\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=6.43382358551\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] Epoch[88] Batch [5]#011Speed: 4991.96 samples/sec#011loss=6.433824\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 352.83517837524414, \"sum\": 352.83517837524414, \"min\": 352.83517837524414}}, \"EndTime\": 1614048370.168056, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048369.814782}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1801.93985377 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] #quality_metric: host=algo-1, epoch=88, train loss <loss>=6.38308663368\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] Epoch[89] Batch[0] avg_epoch_loss=6.321043\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=6.32104301453\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] Epoch[89] Batch[5] avg_epoch_loss=6.237322\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=6.23732185364\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] Epoch[89] Batch [5]#011Speed: 4739.63 samples/sec#011loss=6.237322\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] Epoch[89] Batch[10] avg_epoch_loss=6.332181\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] #quality_metric: host=algo-1, epoch=89, batch=10 train loss <loss>=6.44601211548\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] Epoch[89] Batch [10]#011Speed: 4626.08 samples/sec#011loss=6.446012\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 335.6361389160156, \"sum\": 335.6361389160156, \"min\": 335.6361389160156}}, \"EndTime\": 1614048370.50428, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048370.168137}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1983.60125262 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] #quality_metric: host=algo-1, epoch=89, train loss <loss>=6.33218106357\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] Epoch[90] Batch[0] avg_epoch_loss=6.037979\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=6.03797912598\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] Epoch[90] Batch[5] avg_epoch_loss=6.238228\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=6.2382282416\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] Epoch[90] Batch [5]#011Speed: 4051.46 samples/sec#011loss=6.238228\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] Epoch[90] Batch[10] avg_epoch_loss=5.901601\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] #quality_metric: host=algo-1, epoch=90, batch=10 train loss <loss>=5.49764881134\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] Epoch[90] Batch [10]#011Speed: 4184.05 samples/sec#011loss=5.497649\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 390.61498641967773, \"sum\": 390.61498641967773, \"min\": 390.61498641967773}}, \"EndTime\": 1614048370.89542, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048370.504358}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1684.03596708 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] #quality_metric: host=algo-1, epoch=90, train loss <loss>=5.90160122785\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:10 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] Epoch[91] Batch[0] avg_epoch_loss=6.122869\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=6.1228685379\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] Epoch[91] Batch[5] avg_epoch_loss=6.200961\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=6.2009610335\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] Epoch[91] Batch [5]#011Speed: 4433.24 samples/sec#011loss=6.200961\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] Epoch[91] Batch[10] avg_epoch_loss=6.123899\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] #quality_metric: host=algo-1, epoch=91, batch=10 train loss <loss>=6.0314248085\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] Epoch[91] Batch [10]#011Speed: 4133.68 samples/sec#011loss=6.031425\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] processed a total of 682 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 326.30395889282227, \"sum\": 326.30395889282227, \"min\": 326.30395889282227}}, \"EndTime\": 1614048371.222339, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048370.895494}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2089.30637883 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] #quality_metric: host=algo-1, epoch=91, train loss <loss>=6.12389911305\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] Epoch[92] Batch[0] avg_epoch_loss=6.256884\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=6.25688409805\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] Epoch[92] Batch[5] avg_epoch_loss=6.253227\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=6.2532265981\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] Epoch[92] Batch [5]#011Speed: 5276.77 samples/sec#011loss=6.253227\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] Epoch[92] Batch[10] avg_epoch_loss=6.495716\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] #quality_metric: host=algo-1, epoch=92, batch=10 train loss <loss>=6.78670396805\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] Epoch[92] Batch [10]#011Speed: 5022.91 samples/sec#011loss=6.786704\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 338.9320373535156, \"sum\": 338.9320373535156, \"min\": 338.9320373535156}}, \"EndTime\": 1614048371.561842, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048371.222422}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1899.32305269 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] #quality_metric: host=algo-1, epoch=92, train loss <loss>=6.49571631171\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] Epoch[93] Batch[0] avg_epoch_loss=6.602785\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=6.60278511047\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] Epoch[93] Batch[5] avg_epoch_loss=6.360822\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=6.36082196236\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] Epoch[93] Batch [5]#011Speed: 5218.01 samples/sec#011loss=6.360822\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] Epoch[93] Batch[10] avg_epoch_loss=5.915147\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] #quality_metric: host=algo-1, epoch=93, batch=10 train loss <loss>=5.38033795357\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] Epoch[93] Batch [10]#011Speed: 4894.31 samples/sec#011loss=5.380338\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 307.5261116027832, \"sum\": 307.5261116027832, \"min\": 307.5261116027832}}, \"EndTime\": 1614048371.869904, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048371.561932}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2155.15091431 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] #quality_metric: host=algo-1, epoch=93, train loss <loss>=5.91514741291\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:11 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:12 INFO 140240734582592] Epoch[94] Batch[0] avg_epoch_loss=6.204537\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:12 INFO 140240734582592] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=6.20453691483\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:12 INFO 140240734582592] Epoch[94] Batch[5] avg_epoch_loss=6.068274\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:12 INFO 140240734582592] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=6.06827449799\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:12 INFO 140240734582592] Epoch[94] Batch [5]#011Speed: 4117.77 samples/sec#011loss=6.068274\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:12 INFO 140240734582592] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 304.19087409973145, \"sum\": 304.19087409973145, \"min\": 304.19087409973145}}, \"EndTime\": 1614048372.174641, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048371.869974}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:12 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2027.5180906 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:12 INFO 140240734582592] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:12 INFO 140240734582592] #quality_metric: host=algo-1, epoch=94, train loss <loss>=6.26160173416\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:12 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:12 INFO 140240734582592] Epoch[95] Batch[0] avg_epoch_loss=6.048906\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:12 INFO 140240734582592] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=6.04890632629\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:12 INFO 140240734582592] Epoch[95] Batch[5] avg_epoch_loss=5.996341\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:12 INFO 140240734582592] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=5.9963414669\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:12 INFO 140240734582592] Epoch[95] Batch [5]#011Speed: 4795.31 samples/sec#011loss=5.996341\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:12 INFO 140240734582592] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 323.84705543518066, \"sum\": 323.84705543518066, \"min\": 323.84705543518066}}, \"EndTime\": 1614048372.499062, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048372.174723}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:12 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1904.52209174 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:12 INFO 140240734582592] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:12 INFO 140240734582592] #quality_metric: host=algo-1, epoch=95, train loss <loss>=6.08288049698\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:12 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:12 INFO 140240734582592] Epoch[96] Batch[0] avg_epoch_loss=6.146984\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:12 INFO 140240734582592] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=6.1469836235\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:12 INFO 140240734582592] Epoch[96] Batch[5] avg_epoch_loss=6.019383\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:12 INFO 140240734582592] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=6.01938271523\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:12 INFO 140240734582592] Epoch[96] Batch [5]#011Speed: 4647.32 samples/sec#011loss=6.019383\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:12 INFO 140240734582592] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 328.82094383239746, \"sum\": 328.82094383239746, \"min\": 328.82094383239746}}, \"EndTime\": 1614048372.828428, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048372.499142}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:12 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1878.75576275 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:12 INFO 140240734582592] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:12 INFO 140240734582592] #quality_metric: host=algo-1, epoch=96, train loss <loss>=5.93677978516\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:12 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] Epoch[97] Batch[0] avg_epoch_loss=6.268568\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=6.26856803894\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] Epoch[97] Batch[5] avg_epoch_loss=6.022690\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=6.02268950144\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] Epoch[97] Batch [5]#011Speed: 4046.08 samples/sec#011loss=6.022690\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] Epoch[97] Batch[10] avg_epoch_loss=5.836623\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] #quality_metric: host=algo-1, epoch=97, batch=10 train loss <loss>=5.61334266663\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] Epoch[97] Batch [10]#011Speed: 4762.48 samples/sec#011loss=5.613343\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 397.46999740600586, \"sum\": 397.46999740600586, \"min\": 397.46999740600586}}, \"EndTime\": 1614048373.226449, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048372.828509}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1695.24347559 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] #quality_metric: host=algo-1, epoch=97, train loss <loss>=5.83662275835\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] Epoch[98] Batch[0] avg_epoch_loss=5.887521\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=5.88752126694\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] Epoch[98] Batch[5] avg_epoch_loss=6.140058\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=6.14005812009\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] Epoch[98] Batch [5]#011Speed: 4774.83 samples/sec#011loss=6.140058\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] Epoch[98] Batch[10] avg_epoch_loss=6.284911\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] #quality_metric: host=algo-1, epoch=98, batch=10 train loss <loss>=6.45873413086\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] Epoch[98] Batch [10]#011Speed: 4695.93 samples/sec#011loss=6.458734\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 311.14697456359863, \"sum\": 311.14697456359863, \"min\": 311.14697456359863}}, \"EndTime\": 1614048373.538163, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048373.226526}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2142.87523898 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] #quality_metric: host=algo-1, epoch=98, train loss <loss>=6.28491085226\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] Epoch[99] Batch[0] avg_epoch_loss=6.319580\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=6.31957960129\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] Epoch[99] Batch[5] avg_epoch_loss=5.955878\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=5.95587825775\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] Epoch[99] Batch [5]#011Speed: 4768.35 samples/sec#011loss=5.955878\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] Epoch[99] Batch[10] avg_epoch_loss=6.085180\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] #quality_metric: host=algo-1, epoch=99, batch=10 train loss <loss>=6.24034290314\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] Epoch[99] Batch [10]#011Speed: 4800.69 samples/sec#011loss=6.240343\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 313.9190673828125, \"sum\": 313.9190673828125, \"min\": 313.9190673828125}}, \"EndTime\": 1614048373.85266, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048373.538242}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2085.72192542 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] #quality_metric: host=algo-1, epoch=99, train loss <loss>=6.08518036929\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:13 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] Epoch[100] Batch[0] avg_epoch_loss=6.671628\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=6.67162799835\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] Epoch[100] Batch[5] avg_epoch_loss=6.077166\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=6.07716560364\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] Epoch[100] Batch [5]#011Speed: 5068.51 samples/sec#011loss=6.077166\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] Epoch[100] Batch[10] avg_epoch_loss=5.990309\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] #quality_metric: host=algo-1, epoch=100, batch=10 train loss <loss>=5.88608121872\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] Epoch[100] Batch [10]#011Speed: 4959.47 samples/sec#011loss=5.886081\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 327.79884338378906, \"sum\": 327.79884338378906, \"min\": 327.79884338378906}}, \"EndTime\": 1614048374.180982, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048373.852739}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1982.22705001 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] #quality_metric: host=algo-1, epoch=100, train loss <loss>=5.99030906504\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] Epoch[101] Batch[0] avg_epoch_loss=5.605669\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=5.60566902161\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] Epoch[101] Batch[5] avg_epoch_loss=6.084270\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=6.08427047729\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] Epoch[101] Batch [5]#011Speed: 5086.64 samples/sec#011loss=6.084270\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 283.01501274108887, \"sum\": 283.01501274108887, \"min\": 283.01501274108887}}, \"EndTime\": 1614048374.464637, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048374.181058}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2225.16428873 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] #quality_metric: host=algo-1, epoch=101, train loss <loss>=5.99237484932\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] Epoch[102] Batch[0] avg_epoch_loss=5.839628\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=5.8396282196\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] Epoch[102] Batch[5] avg_epoch_loss=5.957482\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=5.95748225848\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] Epoch[102] Batch [5]#011Speed: 4203.78 samples/sec#011loss=5.957482\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] Epoch[102] Batch[10] avg_epoch_loss=5.815942\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] #quality_metric: host=algo-1, epoch=102, batch=10 train loss <loss>=5.64609422684\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] Epoch[102] Batch [10]#011Speed: 4787.34 samples/sec#011loss=5.646094\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 339.6940231323242, \"sum\": 339.6940231323242, \"min\": 339.6940231323242}}, \"EndTime\": 1614048374.804834, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048374.464708}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1930.49658519 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] #quality_metric: host=algo-1, epoch=102, train loss <loss>=5.8159422441\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] Saved checkpoint to \"/opt/ml/model/state_8441861a-62e7-4312-9cd0-dd15d448cd6a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 11.452913284301758, \"sum\": 11.452913284301758, \"min\": 11.452913284301758}}, \"EndTime\": 1614048374.816901, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048374.804913}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] Epoch[103] Batch[0] avg_epoch_loss=6.262589\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:14 INFO 140240734582592] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=6.26258945465\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] Epoch[103] Batch[5] avg_epoch_loss=6.089377\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=6.08937676748\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] Epoch[103] Batch [5]#011Speed: 4115.11 samples/sec#011loss=6.089377\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] processed a total of 603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 320.1639652252197, \"sum\": 320.1639652252197, \"min\": 320.1639652252197}}, \"EndTime\": 1614048375.137214, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048374.816983}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1882.53378291 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] #quality_metric: host=algo-1, epoch=103, train loss <loss>=6.03062372208\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] Epoch[104] Batch[0] avg_epoch_loss=6.215240\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=6.21524000168\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] Epoch[104] Batch[5] avg_epoch_loss=6.207872\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=6.20787215233\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] Epoch[104] Batch [5]#011Speed: 4463.73 samples/sec#011loss=6.207872\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] processed a total of 612 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 337.07189559936523, \"sum\": 337.07189559936523, \"min\": 337.07189559936523}}, \"EndTime\": 1614048375.474884, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048375.137323}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1815.02786483 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] #quality_metric: host=algo-1, epoch=104, train loss <loss>=6.28508024216\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] Epoch[105] Batch[0] avg_epoch_loss=6.077528\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=6.07752752304\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] Epoch[105] Batch[5] avg_epoch_loss=6.257877\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=6.25787742933\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] Epoch[105] Batch [5]#011Speed: 4535.85 samples/sec#011loss=6.257877\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] Epoch[105] Batch[10] avg_epoch_loss=6.268264\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] #quality_metric: host=algo-1, epoch=105, batch=10 train loss <loss>=6.28072881699\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] Epoch[105] Batch [10]#011Speed: 3819.12 samples/sec#011loss=6.280729\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 335.4949951171875, \"sum\": 335.4949951171875, \"min\": 335.4949951171875}}, \"EndTime\": 1614048375.811006, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048375.474963}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2008.27110543 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] #quality_metric: host=algo-1, epoch=105, train loss <loss>=6.26826442372\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:15 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] Epoch[106] Batch[0] avg_epoch_loss=6.134570\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=6.13456964493\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] Epoch[106] Batch[5] avg_epoch_loss=6.176528\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=6.17652773857\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] Epoch[106] Batch [5]#011Speed: 4251.65 samples/sec#011loss=6.176528\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] Epoch[106] Batch[10] avg_epoch_loss=5.983328\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] #quality_metric: host=algo-1, epoch=106, batch=10 train loss <loss>=5.75148887634\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] Epoch[106] Batch [10]#011Speed: 4068.76 samples/sec#011loss=5.751489\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] processed a total of 704 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 354.48718070983887, \"sum\": 354.48718070983887, \"min\": 354.48718070983887}}, \"EndTime\": 1614048376.166035, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048375.811084}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1985.36922627 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] #quality_metric: host=algo-1, epoch=106, train loss <loss>=5.98332825574\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] Epoch[107] Batch[0] avg_epoch_loss=6.105014\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=6.10501432419\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] Epoch[107] Batch[5] avg_epoch_loss=6.288185\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=6.28818488121\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] Epoch[107] Batch [5]#011Speed: 4156.38 samples/sec#011loss=6.288185\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] Epoch[107] Batch[10] avg_epoch_loss=6.233492\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] #quality_metric: host=algo-1, epoch=107, batch=10 train loss <loss>=6.1678612709\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] Epoch[107] Batch [10]#011Speed: 4909.78 samples/sec#011loss=6.167861\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 322.7190971374512, \"sum\": 322.7190971374512, \"min\": 322.7190971374512}}, \"EndTime\": 1614048376.489324, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048376.166103}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2025.73403421 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] #quality_metric: host=algo-1, epoch=107, train loss <loss>=6.23349233107\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] Epoch[108] Batch[0] avg_epoch_loss=6.147325\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=6.14732456207\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] Epoch[108] Batch[5] avg_epoch_loss=6.172953\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=6.17295320829\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] Epoch[108] Batch [5]#011Speed: 5101.14 samples/sec#011loss=6.172953\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] Epoch[108] Batch[10] avg_epoch_loss=6.417299\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] #quality_metric: host=algo-1, epoch=108, batch=10 train loss <loss>=6.71051387787\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] Epoch[108] Batch [10]#011Speed: 4058.13 samples/sec#011loss=6.710514\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 314.2809867858887, \"sum\": 314.2809867858887, \"min\": 314.2809867858887}}, \"EndTime\": 1614048376.804202, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048376.489387}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2054.80582364 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] #quality_metric: host=algo-1, epoch=108, train loss <loss>=6.41729896719\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] Epoch[109] Batch[0] avg_epoch_loss=6.030612\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:16 INFO 140240734582592] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=6.03061199188\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] Epoch[109] Batch[5] avg_epoch_loss=6.114527\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=6.11452658971\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] Epoch[109] Batch [5]#011Speed: 4176.63 samples/sec#011loss=6.114527\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] Epoch[109] Batch[10] avg_epoch_loss=6.232146\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] #quality_metric: host=algo-1, epoch=109, batch=10 train loss <loss>=6.37328891754\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] Epoch[109] Batch [10]#011Speed: 4328.95 samples/sec#011loss=6.373289\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 333.3101272583008, \"sum\": 333.3101272583008, \"min\": 333.3101272583008}}, \"EndTime\": 1614048377.138065, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048376.804272}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1973.48666717 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] #quality_metric: host=algo-1, epoch=109, train loss <loss>=6.23214582963\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] Epoch[110] Batch[0] avg_epoch_loss=5.733978\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=5.73397827148\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] Epoch[110] Batch[5] avg_epoch_loss=5.987894\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=5.9878941377\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] Epoch[110] Batch [5]#011Speed: 5157.30 samples/sec#011loss=5.987894\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] Epoch[110] Batch[10] avg_epoch_loss=6.004975\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] #quality_metric: host=algo-1, epoch=110, batch=10 train loss <loss>=6.02547235489\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] Epoch[110] Batch [10]#011Speed: 4920.28 samples/sec#011loss=6.025472\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] processed a total of 689 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 308.14504623413086, \"sum\": 308.14504623413086, \"min\": 308.14504623413086}}, \"EndTime\": 1614048377.446783, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048377.138136}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2235.07632148 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] #quality_metric: host=algo-1, epoch=110, train loss <loss>=6.00497514551\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] Epoch[111] Batch[0] avg_epoch_loss=5.841059\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=5.84105873108\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] Epoch[111] Batch[5] avg_epoch_loss=5.904669\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=5.90466888746\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] Epoch[111] Batch [5]#011Speed: 5035.33 samples/sec#011loss=5.904669\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 283.80322456359863, \"sum\": 283.80322456359863, \"min\": 283.80322456359863}}, \"EndTime\": 1614048377.731154, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048377.446863}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2148.49937397 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] #quality_metric: host=algo-1, epoch=111, train loss <loss>=6.07088670731\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] Epoch[112] Batch[0] avg_epoch_loss=6.318711\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=6.31871128082\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] Epoch[112] Batch[5] avg_epoch_loss=6.294005\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=6.29400515556\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:17 INFO 140240734582592] Epoch[112] Batch [5]#011Speed: 4674.61 samples/sec#011loss=6.294005\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 309.4460964202881, \"sum\": 309.4460964202881, \"min\": 309.4460964202881}}, \"EndTime\": 1614048378.041188, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048377.731228}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1996.38772167 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] #quality_metric: host=algo-1, epoch=112, train loss <loss>=6.16606945992\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] Epoch[113] Batch[0] avg_epoch_loss=6.570288\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=6.57028770447\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] Epoch[113] Batch[5] avg_epoch_loss=6.094518\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=6.09451818466\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] Epoch[113] Batch [5]#011Speed: 4987.13 samples/sec#011loss=6.094518\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 314.68701362609863, \"sum\": 314.68701362609863, \"min\": 314.68701362609863}}, \"EndTime\": 1614048378.356502, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048378.041263}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1985.41295869 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] #quality_metric: host=algo-1, epoch=113, train loss <loss>=6.20085506439\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] Epoch[114] Batch[0] avg_epoch_loss=5.880847\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=5.88084697723\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] Epoch[114] Batch[5] avg_epoch_loss=6.028444\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=6.02844429016\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] Epoch[114] Batch [5]#011Speed: 4378.87 samples/sec#011loss=6.028444\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 310.40501594543457, \"sum\": 310.40501594543457, \"min\": 310.40501594543457}}, \"EndTime\": 1614048378.667486, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048378.356579}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2057.76464572 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] #quality_metric: host=algo-1, epoch=114, train loss <loss>=5.99801087379\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] Epoch[115] Batch[0] avg_epoch_loss=5.609603\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=5.60960292816\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] Epoch[115] Batch[5] avg_epoch_loss=6.080157\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=6.08015735944\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] Epoch[115] Batch [5]#011Speed: 4292.03 samples/sec#011loss=6.080157\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] processed a total of 601 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 311.95807456970215, \"sum\": 311.95807456970215, \"min\": 311.95807456970215}}, \"EndTime\": 1614048378.980019, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048378.667576}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1925.83150347 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] #quality_metric: host=algo-1, epoch=115, train loss <loss>=6.17196731567\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:18 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] Epoch[116] Batch[0] avg_epoch_loss=6.088346\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=6.08834648132\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] Epoch[116] Batch[5] avg_epoch_loss=6.275115\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=6.27511461576\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] Epoch[116] Batch [5]#011Speed: 4088.04 samples/sec#011loss=6.275115\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 348.67286682128906, \"sum\": 348.67286682128906, \"min\": 348.67286682128906}}, \"EndTime\": 1614048379.329258, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048378.980096}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1808.93503951 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] #quality_metric: host=algo-1, epoch=116, train loss <loss>=6.21033000946\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] Epoch[117] Batch[0] avg_epoch_loss=5.611428\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=5.6114282608\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] Epoch[117] Batch[5] avg_epoch_loss=6.173890\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=6.17388987541\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] Epoch[117] Batch [5]#011Speed: 5195.23 samples/sec#011loss=6.173890\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] Epoch[117] Batch[10] avg_epoch_loss=5.875582\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] #quality_metric: host=algo-1, epoch=117, batch=10 train loss <loss>=5.51761293411\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] Epoch[117] Batch [10]#011Speed: 4640.31 samples/sec#011loss=5.517613\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 327.6028633117676, \"sum\": 327.6028633117676, \"min\": 327.6028633117676}}, \"EndTime\": 1614048379.657439, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048379.32937}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2004.81457381 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] #quality_metric: host=algo-1, epoch=117, train loss <loss>=5.87558217482\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] Epoch[118] Batch[0] avg_epoch_loss=6.016637\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=6.01663684845\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] Epoch[118] Batch[5] avg_epoch_loss=5.956074\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=5.95607384046\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] Epoch[118] Batch [5]#011Speed: 3974.67 samples/sec#011loss=5.956074\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 318.4020519256592, \"sum\": 318.4020519256592, \"min\": 318.4020519256592}}, \"EndTime\": 1614048379.976441, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048379.657506}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1987.28466883 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] #quality_metric: host=algo-1, epoch=118, train loss <loss>=6.02214679718\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:19 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] Epoch[119] Batch[0] avg_epoch_loss=5.797340\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=5.79734039307\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] Epoch[119] Batch[5] avg_epoch_loss=6.111468\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=6.1114683946\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] Epoch[119] Batch [5]#011Speed: 4514.30 samples/sec#011loss=6.111468\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 331.24804496765137, \"sum\": 331.24804496765137, \"min\": 331.24804496765137}}, \"EndTime\": 1614048380.308257, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048379.976525}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1889.05290588 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] #quality_metric: host=algo-1, epoch=119, train loss <loss>=6.25099415779\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] Epoch[120] Batch[0] avg_epoch_loss=5.642499\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=5.64249944687\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] Epoch[120] Batch[5] avg_epoch_loss=6.003065\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=6.00306479136\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] Epoch[120] Batch [5]#011Speed: 4126.80 samples/sec#011loss=6.003065\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 319.5669651031494, \"sum\": 319.5669651031494, \"min\": 319.5669651031494}}, \"EndTime\": 1614048380.628484, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048380.30835}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1998.74284802 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] #quality_metric: host=algo-1, epoch=120, train loss <loss>=6.08815789223\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] Epoch[121] Batch[0] avg_epoch_loss=5.894875\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=5.89487457275\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] Epoch[121] Batch[5] avg_epoch_loss=6.023018\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=6.02301820119\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] Epoch[121] Batch [5]#011Speed: 3943.61 samples/sec#011loss=6.023018\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] Epoch[121] Batch[10] avg_epoch_loss=6.198478\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] #quality_metric: host=algo-1, epoch=121, batch=10 train loss <loss>=6.40902900696\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] Epoch[121] Batch [10]#011Speed: 4333.98 samples/sec#011loss=6.409029\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 342.0298099517822, \"sum\": 342.0298099517822, \"min\": 342.0298099517822}}, \"EndTime\": 1614048380.971177, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048380.628573}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1990.42461382 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] #quality_metric: host=algo-1, epoch=121, train loss <loss>=6.19847765836\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:20 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] Epoch[122] Batch[0] avg_epoch_loss=5.503584\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=5.50358390808\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] Epoch[122] Batch[5] avg_epoch_loss=6.187259\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=6.18725887934\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] Epoch[122] Batch [5]#011Speed: 4436.50 samples/sec#011loss=6.187259\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 303.48777770996094, \"sum\": 303.48777770996094, \"min\": 303.48777770996094}}, \"EndTime\": 1614048381.275256, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048380.971242}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2084.9519023 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] #quality_metric: host=algo-1, epoch=122, train loss <loss>=6.17371611595\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] Epoch[123] Batch[0] avg_epoch_loss=6.173495\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=6.17349481583\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] Epoch[123] Batch[5] avg_epoch_loss=6.260916\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=6.26091639201\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] Epoch[123] Batch [5]#011Speed: 4137.15 samples/sec#011loss=6.260916\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] Epoch[123] Batch[10] avg_epoch_loss=5.999491\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] #quality_metric: host=algo-1, epoch=123, batch=10 train loss <loss>=5.6857796669\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] Epoch[123] Batch [10]#011Speed: 4325.08 samples/sec#011loss=5.685780\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 353.53612899780273, \"sum\": 353.53612899780273, \"min\": 353.53612899780273}}, \"EndTime\": 1614048381.629349, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048381.275333}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1843.68739879 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] #quality_metric: host=algo-1, epoch=123, train loss <loss>=5.99949060787\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] Epoch[124] Batch[0] avg_epoch_loss=6.129338\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=6.12933778763\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] Epoch[124] Batch[5] avg_epoch_loss=6.227985\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=6.22798506419\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] Epoch[124] Batch [5]#011Speed: 4327.43 samples/sec#011loss=6.227985\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] processed a total of 612 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 304.218053817749, \"sum\": 304.218053817749, \"min\": 304.218053817749}}, \"EndTime\": 1614048381.934152, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048381.629413}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2010.90173044 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] #quality_metric: host=algo-1, epoch=124, train loss <loss>=6.22096242905\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:21 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] Epoch[125] Batch[0] avg_epoch_loss=5.826961\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=5.8269610405\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] Epoch[125] Batch[5] avg_epoch_loss=5.956164\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=5.95616404215\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] Epoch[125] Batch [5]#011Speed: 4652.12 samples/sec#011loss=5.956164\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] Epoch[125] Batch[10] avg_epoch_loss=5.859813\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] #quality_metric: host=algo-1, epoch=125, batch=10 train loss <loss>=5.74419221878\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] Epoch[125] Batch [10]#011Speed: 4100.57 samples/sec#011loss=5.744192\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] processed a total of 691 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 340.67511558532715, \"sum\": 340.67511558532715, \"min\": 340.67511558532715}}, \"EndTime\": 1614048382.275378, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048381.934234}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2027.6357836 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] #quality_metric: host=algo-1, epoch=125, train loss <loss>=5.85981321335\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] Epoch[126] Batch[0] avg_epoch_loss=6.045055\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=6.0450553894\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] Epoch[126] Batch[5] avg_epoch_loss=5.966638\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=5.96663753192\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] Epoch[126] Batch [5]#011Speed: 4650.91 samples/sec#011loss=5.966638\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] Epoch[126] Batch[10] avg_epoch_loss=6.128348\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] #quality_metric: host=algo-1, epoch=126, batch=10 train loss <loss>=6.32240066528\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] Epoch[126] Batch [10]#011Speed: 4162.16 samples/sec#011loss=6.322401\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 326.6417980194092, \"sum\": 326.6417980194092, \"min\": 326.6417980194092}}, \"EndTime\": 1614048382.602619, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048382.275453}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1986.21616538 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] #quality_metric: host=algo-1, epoch=126, train loss <loss>=6.12834804708\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] Epoch[127] Batch[0] avg_epoch_loss=5.957359\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=5.95735931396\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] Epoch[127] Batch[5] avg_epoch_loss=6.029256\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=6.0292561849\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] Epoch[127] Batch [5]#011Speed: 4179.25 samples/sec#011loss=6.029256\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 321.30980491638184, \"sum\": 321.30980491638184, \"min\": 321.30980491638184}}, \"EndTime\": 1614048382.92451, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048382.602689}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1966.2443074 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] #quality_metric: host=algo-1, epoch=127, train loss <loss>=5.96776742935\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:22 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] Epoch[128] Batch[0] avg_epoch_loss=6.393808\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=6.39380836487\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] Epoch[128] Batch[5] avg_epoch_loss=6.162865\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=6.16286468506\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] Epoch[128] Batch [5]#011Speed: 4860.64 samples/sec#011loss=6.162865\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] Epoch[128] Batch[10] avg_epoch_loss=6.201747\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] #quality_metric: host=algo-1, epoch=128, batch=10 train loss <loss>=6.24840660095\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] Epoch[128] Batch [10]#011Speed: 4376.43 samples/sec#011loss=6.248407\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] processed a total of 677 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 335.6921672821045, \"sum\": 335.6921672821045, \"min\": 335.6921672821045}}, \"EndTime\": 1614048383.260718, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048382.924583}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2015.97978017 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] #quality_metric: host=algo-1, epoch=128, train loss <loss>=6.2017473741\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] Epoch[129] Batch[0] avg_epoch_loss=6.337330\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=6.3373298645\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] Epoch[129] Batch[5] avg_epoch_loss=6.326978\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=6.32697844505\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] Epoch[129] Batch [5]#011Speed: 4137.15 samples/sec#011loss=6.326978\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 330.6398391723633, \"sum\": 330.6398391723633, \"min\": 330.6398391723633}}, \"EndTime\": 1614048383.592039, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048383.260798}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1910.76751321 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] #quality_metric: host=algo-1, epoch=129, train loss <loss>=6.22483382225\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] Epoch[130] Batch[0] avg_epoch_loss=5.952746\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=5.95274591446\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] Epoch[130] Batch[5] avg_epoch_loss=6.035788\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=6.03578790029\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] Epoch[130] Batch [5]#011Speed: 4186.52 samples/sec#011loss=6.035788\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 311.2978935241699, \"sum\": 311.2978935241699, \"min\": 311.2978935241699}}, \"EndTime\": 1614048383.903935, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048383.592122}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1990.38242901 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] #quality_metric: host=algo-1, epoch=130, train loss <loss>=6.20109472275\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:23 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] Epoch[131] Batch[0] avg_epoch_loss=5.376225\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=5.3762254715\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] Epoch[131] Batch[5] avg_epoch_loss=6.029511\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=6.0295112133\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] Epoch[131] Batch [5]#011Speed: 4103.36 samples/sec#011loss=6.029511\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] Epoch[131] Batch[10] avg_epoch_loss=6.015108\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] #quality_metric: host=algo-1, epoch=131, batch=10 train loss <loss>=5.99782381058\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] Epoch[131] Batch [10]#011Speed: 4509.84 samples/sec#011loss=5.997824\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 331.0868740081787, \"sum\": 331.0868740081787, \"min\": 331.0868740081787}}, \"EndTime\": 1614048384.235933, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048383.904068}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1944.4437233 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] #quality_metric: host=algo-1, epoch=131, train loss <loss>=6.01510784843\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] Epoch[132] Batch[0] avg_epoch_loss=5.907606\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=5.90760564804\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] Epoch[132] Batch[5] avg_epoch_loss=5.992847\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=5.99284656843\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] Epoch[132] Batch [5]#011Speed: 4889.30 samples/sec#011loss=5.992847\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 290.8179759979248, \"sum\": 290.8179759979248, \"min\": 290.8179759979248}}, \"EndTime\": 1614048384.527366, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048384.236008}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2168.85482161 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] #quality_metric: host=algo-1, epoch=132, train loss <loss>=5.88418636322\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] Epoch[133] Batch[0] avg_epoch_loss=6.506043\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=6.50604343414\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] Epoch[133] Batch[5] avg_epoch_loss=6.154952\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=6.15495173136\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] Epoch[133] Batch [5]#011Speed: 4444.44 samples/sec#011loss=6.154952\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 318.0279731750488, \"sum\": 318.0279731750488, \"min\": 318.0279731750488}}, \"EndTime\": 1614048384.845942, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048384.527447}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1942.46222882 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] #quality_metric: host=algo-1, epoch=133, train loss <loss>=6.27582035065\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:24 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] Epoch[134] Batch[0] avg_epoch_loss=5.807425\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=5.80742454529\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] Epoch[134] Batch[5] avg_epoch_loss=6.054265\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=6.05426502228\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] Epoch[134] Batch [5]#011Speed: 4251.31 samples/sec#011loss=6.054265\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 321.882963180542, \"sum\": 321.882963180542, \"min\": 321.882963180542}}, \"EndTime\": 1614048385.168394, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048384.846029}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1922.30030919 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] #quality_metric: host=algo-1, epoch=134, train loss <loss>=6.14524965286\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] Epoch[135] Batch[0] avg_epoch_loss=6.142642\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=6.14264202118\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] Epoch[135] Batch[5] avg_epoch_loss=6.121168\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=6.12116781871\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] Epoch[135] Batch [5]#011Speed: 5017.49 samples/sec#011loss=6.121168\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] Epoch[135] Batch[10] avg_epoch_loss=6.010645\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] #quality_metric: host=algo-1, epoch=135, batch=10 train loss <loss>=5.87801761627\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] Epoch[135] Batch [10]#011Speed: 4427.41 samples/sec#011loss=5.878018\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 319.9419975280762, \"sum\": 319.9419975280762, \"min\": 319.9419975280762}}, \"EndTime\": 1614048385.488975, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048385.168478}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2065.2638266 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] #quality_metric: host=algo-1, epoch=135, train loss <loss>=6.01064499942\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] Epoch[136] Batch[0] avg_epoch_loss=6.369024\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] #quality_metric: host=algo-1, epoch=136, batch=0 train loss <loss>=6.3690237999\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] Epoch[136] Batch[5] avg_epoch_loss=6.038303\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] #quality_metric: host=algo-1, epoch=136, batch=5 train loss <loss>=6.03830337524\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] Epoch[136] Batch [5]#011Speed: 4176.67 samples/sec#011loss=6.038303\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] Epoch[136] Batch[10] avg_epoch_loss=6.178041\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] #quality_metric: host=algo-1, epoch=136, batch=10 train loss <loss>=6.34572658539\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] Epoch[136] Batch [10]#011Speed: 4057.36 samples/sec#011loss=6.345727\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 344.54798698425293, \"sum\": 344.54798698425293, \"min\": 344.54798698425293}}, \"EndTime\": 1614048385.834074, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048385.489053}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1914.91981624 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] #quality_metric: host=algo-1, epoch=136, train loss <loss>=6.17804119804\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:25 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] Epoch[137] Batch[0] avg_epoch_loss=6.591037\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] #quality_metric: host=algo-1, epoch=137, batch=0 train loss <loss>=6.59103679657\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] Epoch[137] Batch[5] avg_epoch_loss=6.116011\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] #quality_metric: host=algo-1, epoch=137, batch=5 train loss <loss>=6.11601130168\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] Epoch[137] Batch [5]#011Speed: 4159.62 samples/sec#011loss=6.116011\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 319.95201110839844, \"sum\": 319.95201110839844, \"min\": 319.95201110839844}}, \"EndTime\": 1614048386.15462, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048385.834146}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1955.7622606 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] #quality_metric: host=algo-1, epoch=137, train loss <loss>=6.17983541489\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] Epoch[138] Batch[0] avg_epoch_loss=5.552143\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] #quality_metric: host=algo-1, epoch=138, batch=0 train loss <loss>=5.55214262009\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] Epoch[138] Batch[5] avg_epoch_loss=5.743054\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] #quality_metric: host=algo-1, epoch=138, batch=5 train loss <loss>=5.74305415154\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] Epoch[138] Batch [5]#011Speed: 5262.97 samples/sec#011loss=5.743054\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 285.9377861022949, \"sum\": 285.9377861022949, \"min\": 285.9377861022949}}, \"EndTime\": 1614048386.441185, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048386.154706}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2202.25001229 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] #quality_metric: host=algo-1, epoch=138, train loss <loss>=5.80795283318\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] Saved checkpoint to \"/opt/ml/model/state_697e55ae-dc4c-4a09-bdf8-845e96ac9490-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 11.34490966796875, \"sum\": 11.34490966796875, \"min\": 11.34490966796875}}, \"EndTime\": 1614048386.453188, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048386.441273}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] Epoch[139] Batch[0] avg_epoch_loss=6.380333\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] #quality_metric: host=algo-1, epoch=139, batch=0 train loss <loss>=6.38033294678\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] Epoch[139] Batch[5] avg_epoch_loss=6.216866\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] #quality_metric: host=algo-1, epoch=139, batch=5 train loss <loss>=6.21686553955\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] Epoch[139] Batch [5]#011Speed: 4646.85 samples/sec#011loss=6.216866\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] Epoch[139] Batch[10] avg_epoch_loss=6.156940\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] #quality_metric: host=algo-1, epoch=139, batch=10 train loss <loss>=6.08502893448\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] Epoch[139] Batch [10]#011Speed: 4858.42 samples/sec#011loss=6.085029\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] processed a total of 691 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 325.3040313720703, \"sum\": 325.3040313720703, \"min\": 325.3040313720703}}, \"EndTime\": 1614048386.778881, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048386.453516}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2123.31237614 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] #quality_metric: host=algo-1, epoch=139, train loss <loss>=6.15693980997\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] Epoch[140] Batch[0] avg_epoch_loss=5.741308\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:26 INFO 140240734582592] #quality_metric: host=algo-1, epoch=140, batch=0 train loss <loss>=5.74130821228\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] Epoch[140] Batch[5] avg_epoch_loss=5.999584\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] #quality_metric: host=algo-1, epoch=140, batch=5 train loss <loss>=5.99958372116\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] Epoch[140] Batch [5]#011Speed: 4092.23 samples/sec#011loss=5.999584\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] Epoch[140] Batch[10] avg_epoch_loss=6.287473\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] #quality_metric: host=algo-1, epoch=140, batch=10 train loss <loss>=6.63293972015\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] Epoch[140] Batch [10]#011Speed: 3988.14 samples/sec#011loss=6.632940\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 362.26701736450195, \"sum\": 362.26701736450195, \"min\": 362.26701736450195}}, \"EndTime\": 1614048387.141759, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048386.778971}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1824.05796068 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] #quality_metric: host=algo-1, epoch=140, train loss <loss>=6.28747281161\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] Epoch[141] Batch[0] avg_epoch_loss=5.993249\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] #quality_metric: host=algo-1, epoch=141, batch=0 train loss <loss>=5.99324893951\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] Epoch[141] Batch[5] avg_epoch_loss=6.330734\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] #quality_metric: host=algo-1, epoch=141, batch=5 train loss <loss>=6.33073401451\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] Epoch[141] Batch [5]#011Speed: 5014.58 samples/sec#011loss=6.330734\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 335.7839584350586, \"sum\": 335.7839584350586, \"min\": 335.7839584350586}}, \"EndTime\": 1614048387.47803, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048387.141827}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1872.63125333 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] #quality_metric: host=algo-1, epoch=141, train loss <loss>=6.10502653122\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] Epoch[142] Batch[0] avg_epoch_loss=6.093232\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] #quality_metric: host=algo-1, epoch=142, batch=0 train loss <loss>=6.09323167801\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] Epoch[142] Batch[5] avg_epoch_loss=6.254194\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] #quality_metric: host=algo-1, epoch=142, batch=5 train loss <loss>=6.25419370333\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] Epoch[142] Batch [5]#011Speed: 4682.89 samples/sec#011loss=6.254194\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 291.01109504699707, \"sum\": 291.01109504699707, \"min\": 291.01109504699707}}, \"EndTime\": 1614048387.769642, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048387.478107}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2191.48369429 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] #quality_metric: host=algo-1, epoch=142, train loss <loss>=6.19177379608\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] Epoch[143] Batch[0] avg_epoch_loss=6.548117\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:27 INFO 140240734582592] #quality_metric: host=algo-1, epoch=143, batch=0 train loss <loss>=6.54811668396\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] Epoch[143] Batch[5] avg_epoch_loss=6.298207\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] #quality_metric: host=algo-1, epoch=143, batch=5 train loss <loss>=6.29820664724\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] Epoch[143] Batch [5]#011Speed: 4368.24 samples/sec#011loss=6.298207\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 314.7430419921875, \"sum\": 314.7430419921875, \"min\": 314.7430419921875}}, \"EndTime\": 1614048388.084992, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048387.76972}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2000.83861608 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] #quality_metric: host=algo-1, epoch=143, train loss <loss>=6.168714571\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] Epoch[144] Batch[0] avg_epoch_loss=5.909945\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] #quality_metric: host=algo-1, epoch=144, batch=0 train loss <loss>=5.90994501114\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] Epoch[144] Batch[5] avg_epoch_loss=6.031478\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] #quality_metric: host=algo-1, epoch=144, batch=5 train loss <loss>=6.0314775308\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] Epoch[144] Batch [5]#011Speed: 3816.89 samples/sec#011loss=6.031478\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] Epoch[144] Batch[10] avg_epoch_loss=6.290420\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] #quality_metric: host=algo-1, epoch=144, batch=10 train loss <loss>=6.60115032196\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] Epoch[144] Batch [10]#011Speed: 4406.45 samples/sec#011loss=6.601150\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 328.7968635559082, \"sum\": 328.7968635559082, \"min\": 328.7968635559082}}, \"EndTime\": 1614048388.414459, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048388.085073}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2003.5564241 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] #quality_metric: host=algo-1, epoch=144, train loss <loss>=6.2904197086\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] Epoch[145] Batch[0] avg_epoch_loss=5.913549\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] #quality_metric: host=algo-1, epoch=145, batch=0 train loss <loss>=5.91354942322\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] Epoch[145] Batch[5] avg_epoch_loss=6.028481\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] #quality_metric: host=algo-1, epoch=145, batch=5 train loss <loss>=6.02848052979\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] Epoch[145] Batch [5]#011Speed: 4444.44 samples/sec#011loss=6.028481\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 300.3358840942383, \"sum\": 300.3358840942383, \"min\": 300.3358840942383}}, \"EndTime\": 1614048388.715373, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048388.414532}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2123.48083248 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] #quality_metric: host=algo-1, epoch=145, train loss <loss>=6.09445943832\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] Epoch[146] Batch[0] avg_epoch_loss=7.014088\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] #quality_metric: host=algo-1, epoch=146, batch=0 train loss <loss>=7.014087677\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] Epoch[146] Batch[5] avg_epoch_loss=6.328668\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] #quality_metric: host=algo-1, epoch=146, batch=5 train loss <loss>=6.32866827647\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:28 INFO 140240734582592] Epoch[146] Batch [5]#011Speed: 4136.98 samples/sec#011loss=6.328668\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:29 INFO 140240734582592] processed a total of 612 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 312.6711845397949, \"sum\": 312.6711845397949, \"min\": 312.6711845397949}}, \"EndTime\": 1614048389.028649, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048388.715438}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:29 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1956.58331764 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:29 INFO 140240734582592] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:29 INFO 140240734582592] #quality_metric: host=algo-1, epoch=146, train loss <loss>=6.11056728363\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:29 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:29 INFO 140240734582592] Epoch[147] Batch[0] avg_epoch_loss=6.171100\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:29 INFO 140240734582592] #quality_metric: host=algo-1, epoch=147, batch=0 train loss <loss>=6.17110013962\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:29 INFO 140240734582592] Epoch[147] Batch[5] avg_epoch_loss=6.123136\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:29 INFO 140240734582592] #quality_metric: host=algo-1, epoch=147, batch=5 train loss <loss>=6.12313644091\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:29 INFO 140240734582592] Epoch[147] Batch [5]#011Speed: 4139.88 samples/sec#011loss=6.123136\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:29 INFO 140240734582592] Epoch[147] Batch[10] avg_epoch_loss=5.999532\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:29 INFO 140240734582592] #quality_metric: host=algo-1, epoch=147, batch=10 train loss <loss>=5.85120573044\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:29 INFO 140240734582592] Epoch[147] Batch [10]#011Speed: 4594.47 samples/sec#011loss=5.851206\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:29 INFO 140240734582592] processed a total of 679 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 390.81501960754395, \"sum\": 390.81501960754395, \"min\": 390.81501960754395}}, \"EndTime\": 1614048389.420022, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048389.02873}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:29 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1736.88411939 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:29 INFO 140240734582592] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:29 INFO 140240734582592] #quality_metric: host=algo-1, epoch=147, train loss <loss>=5.99953157252\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:29 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:29 INFO 140240734582592] Epoch[148] Batch[0] avg_epoch_loss=6.103523\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:29 INFO 140240734582592] #quality_metric: host=algo-1, epoch=148, batch=0 train loss <loss>=6.10352325439\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:29 INFO 140240734582592] Epoch[148] Batch[5] avg_epoch_loss=6.128597\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:29 INFO 140240734582592] #quality_metric: host=algo-1, epoch=148, batch=5 train loss <loss>=6.1285970211\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:29 INFO 140240734582592] Epoch[148] Batch [5]#011Speed: 5021.65 samples/sec#011loss=6.128597\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:29 INFO 140240734582592] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 327.9581069946289, \"sum\": 327.9581069946289, \"min\": 327.9581069946289}}, \"EndTime\": 1614048389.748509, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048389.420101}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:29 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1911.09043026 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:29 INFO 140240734582592] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:29 INFO 140240734582592] #quality_metric: host=algo-1, epoch=148, train loss <loss>=6.22436056137\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:29 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:29 INFO 140240734582592] Epoch[149] Batch[0] avg_epoch_loss=5.674575\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:29 INFO 140240734582592] #quality_metric: host=algo-1, epoch=149, batch=0 train loss <loss>=5.67457532883\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] Epoch[149] Batch[5] avg_epoch_loss=5.871626\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] #quality_metric: host=algo-1, epoch=149, batch=5 train loss <loss>=5.87162613869\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] Epoch[149] Batch [5]#011Speed: 4777.11 samples/sec#011loss=5.871626\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] Epoch[149] Batch[10] avg_epoch_loss=5.741136\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] #quality_metric: host=algo-1, epoch=149, batch=10 train loss <loss>=5.58454790115\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] Epoch[149] Batch [10]#011Speed: 4248.32 samples/sec#011loss=5.584548\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 329.53619956970215, \"sum\": 329.53619956970215, \"min\": 329.53619956970215}}, \"EndTime\": 1614048390.07865, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048389.748595}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1992.59965899 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] #quality_metric: host=algo-1, epoch=149, train loss <loss>=5.74113603072\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] Saved checkpoint to \"/opt/ml/model/state_64ee8578-84b2-4dcf-93c2-a6c76d4a70fd-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 8.922815322875977, \"sum\": 8.922815322875977, \"min\": 8.922815322875977}}, \"EndTime\": 1614048390.088225, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048390.078765}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] Epoch[150] Batch[0] avg_epoch_loss=5.448974\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] #quality_metric: host=algo-1, epoch=150, batch=0 train loss <loss>=5.44897413254\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] Epoch[150] Batch[5] avg_epoch_loss=5.870567\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] #quality_metric: host=algo-1, epoch=150, batch=5 train loss <loss>=5.87056748072\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] Epoch[150] Batch [5]#011Speed: 4140.09 samples/sec#011loss=5.870567\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 312.53600120544434, \"sum\": 312.53600120544434, \"min\": 312.53600120544434}}, \"EndTime\": 1614048390.400896, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048390.088305}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1989.39977535 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] #quality_metric: host=algo-1, epoch=150, train loss <loss>=5.95252900124\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] Epoch[151] Batch[0] avg_epoch_loss=6.085308\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] #quality_metric: host=algo-1, epoch=151, batch=0 train loss <loss>=6.08530759811\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] Epoch[151] Batch[5] avg_epoch_loss=6.319741\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] #quality_metric: host=algo-1, epoch=151, batch=5 train loss <loss>=6.31974124908\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] Epoch[151] Batch [5]#011Speed: 4096.78 samples/sec#011loss=6.319741\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] Epoch[151] Batch[10] avg_epoch_loss=6.160423\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] #quality_metric: host=algo-1, epoch=151, batch=10 train loss <loss>=5.96924104691\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] Epoch[151] Batch [10]#011Speed: 4662.77 samples/sec#011loss=5.969241\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 324.1310119628906, \"sum\": 324.1310119628906, \"min\": 324.1310119628906}}, \"EndTime\": 1614048390.725671, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048390.400982}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2066.30089404 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] #quality_metric: host=algo-1, epoch=151, train loss <loss>=6.16042297537\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] Epoch[152] Batch[0] avg_epoch_loss=5.524381\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] #quality_metric: host=algo-1, epoch=152, batch=0 train loss <loss>=5.52438116074\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] Epoch[152] Batch[5] avg_epoch_loss=6.041838\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] #quality_metric: host=algo-1, epoch=152, batch=5 train loss <loss>=6.04183785121\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:30 INFO 140240734582592] Epoch[152] Batch [5]#011Speed: 4801.26 samples/sec#011loss=6.041838\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] Epoch[152] Batch[10] avg_epoch_loss=5.806179\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] #quality_metric: host=algo-1, epoch=152, batch=10 train loss <loss>=5.52338895798\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] Epoch[152] Batch [10]#011Speed: 4158.98 samples/sec#011loss=5.523389\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 323.46391677856445, \"sum\": 323.46391677856445, \"min\": 323.46391677856445}}, \"EndTime\": 1614048391.049701, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048390.725752}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2070.57142562 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] #quality_metric: host=algo-1, epoch=152, train loss <loss>=5.80617926338\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] Epoch[153] Batch[0] avg_epoch_loss=6.020752\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] #quality_metric: host=algo-1, epoch=153, batch=0 train loss <loss>=6.02075195312\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] Epoch[153] Batch[5] avg_epoch_loss=6.108999\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] #quality_metric: host=algo-1, epoch=153, batch=5 train loss <loss>=6.10899933179\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] Epoch[153] Batch [5]#011Speed: 4141.10 samples/sec#011loss=6.108999\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 334.3501091003418, \"sum\": 334.3501091003418, \"min\": 334.3501091003418}}, \"EndTime\": 1614048391.384597, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048391.049779}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1850.64543069 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] #quality_metric: host=algo-1, epoch=153, train loss <loss>=5.91968708038\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] Epoch[154] Batch[0] avg_epoch_loss=6.267860\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] #quality_metric: host=algo-1, epoch=154, batch=0 train loss <loss>=6.26785993576\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] Epoch[154] Batch[5] avg_epoch_loss=6.096278\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] #quality_metric: host=algo-1, epoch=154, batch=5 train loss <loss>=6.09627771378\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] Epoch[154] Batch [5]#011Speed: 4822.70 samples/sec#011loss=6.096278\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] Epoch[154] Batch[10] avg_epoch_loss=5.958131\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] #quality_metric: host=algo-1, epoch=154, batch=10 train loss <loss>=5.79235525131\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] Epoch[154] Batch [10]#011Speed: 4534.38 samples/sec#011loss=5.792355\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 321.7661380767822, \"sum\": 321.7661380767822, \"min\": 321.7661380767822}}, \"EndTime\": 1614048391.706931, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048391.384682}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2000.74498449 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] #quality_metric: host=algo-1, epoch=154, train loss <loss>=5.95813113993\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] Epoch[155] Batch[0] avg_epoch_loss=5.693056\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] #quality_metric: host=algo-1, epoch=155, batch=0 train loss <loss>=5.69305610657\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] Epoch[155] Batch[5] avg_epoch_loss=6.054507\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] #quality_metric: host=algo-1, epoch=155, batch=5 train loss <loss>=6.05450661977\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:31 INFO 140240734582592] Epoch[155] Batch [5]#011Speed: 4331.41 samples/sec#011loss=6.054507\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 305.97400665283203, \"sum\": 305.97400665283203, \"min\": 305.97400665283203}}, \"EndTime\": 1614048392.01345, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048391.70701}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2081.05242956 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] #quality_metric: host=algo-1, epoch=155, train loss <loss>=5.97546081543\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] Epoch[156] Batch[0] avg_epoch_loss=6.223336\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] #quality_metric: host=algo-1, epoch=156, batch=0 train loss <loss>=6.22333574295\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] Epoch[156] Batch[5] avg_epoch_loss=5.950421\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] #quality_metric: host=algo-1, epoch=156, batch=5 train loss <loss>=5.95042109489\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] Epoch[156] Batch [5]#011Speed: 4542.04 samples/sec#011loss=5.950421\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] Epoch[156] Batch[10] avg_epoch_loss=5.849828\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] #quality_metric: host=algo-1, epoch=156, batch=10 train loss <loss>=5.72911586761\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] Epoch[156] Batch [10]#011Speed: 5041.69 samples/sec#011loss=5.729116\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] processed a total of 688 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 321.00796699523926, \"sum\": 321.00796699523926, \"min\": 321.00796699523926}}, \"EndTime\": 1614048392.335085, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048392.013535}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2142.44223231 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] #quality_metric: host=algo-1, epoch=156, train loss <loss>=5.84982780977\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] Epoch[157] Batch[0] avg_epoch_loss=5.873036\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] #quality_metric: host=algo-1, epoch=157, batch=0 train loss <loss>=5.87303638458\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] Epoch[157] Batch[5] avg_epoch_loss=6.074142\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] #quality_metric: host=algo-1, epoch=157, batch=5 train loss <loss>=6.07414189974\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] Epoch[157] Batch [5]#011Speed: 5009.64 samples/sec#011loss=6.074142\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] Epoch[157] Batch[10] avg_epoch_loss=6.326069\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] #quality_metric: host=algo-1, epoch=157, batch=10 train loss <loss>=6.62838106155\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] Epoch[157] Batch [10]#011Speed: 4177.11 samples/sec#011loss=6.628381\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 320.6620216369629, \"sum\": 320.6620216369629, \"min\": 320.6620216369629}}, \"EndTime\": 1614048392.656242, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048392.335161}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2026.29254954 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] #quality_metric: host=algo-1, epoch=157, train loss <loss>=6.32606879148\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] Epoch[158] Batch[0] avg_epoch_loss=5.893975\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] #quality_metric: host=algo-1, epoch=158, batch=0 train loss <loss>=5.89397478104\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] Epoch[158] Batch[5] avg_epoch_loss=5.981519\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] #quality_metric: host=algo-1, epoch=158, batch=5 train loss <loss>=5.98151946068\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] Epoch[158] Batch [5]#011Speed: 4682.61 samples/sec#011loss=5.981519\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 312.8488063812256, \"sum\": 312.8488063812256, \"min\": 312.8488063812256}}, \"EndTime\": 1614048392.969631, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048392.656325}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1997.0152642 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] #quality_metric: host=algo-1, epoch=158, train loss <loss>=6.20643768311\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:32 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] Epoch[159] Batch[0] avg_epoch_loss=6.445601\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] #quality_metric: host=algo-1, epoch=159, batch=0 train loss <loss>=6.44560098648\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] Epoch[159] Batch[5] avg_epoch_loss=6.122848\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] #quality_metric: host=algo-1, epoch=159, batch=5 train loss <loss>=6.12284779549\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] Epoch[159] Batch [5]#011Speed: 4725.76 samples/sec#011loss=6.122848\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] Epoch[159] Batch[10] avg_epoch_loss=6.261089\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] #quality_metric: host=algo-1, epoch=159, batch=10 train loss <loss>=6.42697935104\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] Epoch[159] Batch [10]#011Speed: 4182.19 samples/sec#011loss=6.426979\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 357.4550151824951, \"sum\": 357.4550151824951, \"min\": 357.4550151824951}}, \"EndTime\": 1614048393.327651, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048392.969711}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1831.79362169 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] #quality_metric: host=algo-1, epoch=159, train loss <loss>=6.26108941165\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] Epoch[160] Batch[0] avg_epoch_loss=6.638859\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] #quality_metric: host=algo-1, epoch=160, batch=0 train loss <loss>=6.638859272\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] Epoch[160] Batch[5] avg_epoch_loss=6.158796\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] #quality_metric: host=algo-1, epoch=160, batch=5 train loss <loss>=6.15879599253\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] Epoch[160] Batch [5]#011Speed: 4182.85 samples/sec#011loss=6.158796\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 325.86097717285156, \"sum\": 325.86097717285156, \"min\": 325.86097717285156}}, \"EndTime\": 1614048393.65405, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048393.32773}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1926.46786725 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] #quality_metric: host=algo-1, epoch=160, train loss <loss>=6.16389188766\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] Epoch[161] Batch[0] avg_epoch_loss=5.973722\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] #quality_metric: host=algo-1, epoch=161, batch=0 train loss <loss>=5.97372150421\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] Epoch[161] Batch[5] avg_epoch_loss=6.036618\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] #quality_metric: host=algo-1, epoch=161, batch=5 train loss <loss>=6.03661775589\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] Epoch[161] Batch [5]#011Speed: 4143.89 samples/sec#011loss=6.036618\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] Epoch[161] Batch[10] avg_epoch_loss=5.948166\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] #quality_metric: host=algo-1, epoch=161, batch=10 train loss <loss>=5.84202432632\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] Epoch[161] Batch [10]#011Speed: 5062.57 samples/sec#011loss=5.842024\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 324.47195053100586, \"sum\": 324.47195053100586, \"min\": 324.47195053100586}}, \"EndTime\": 1614048393.97906, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048393.654139}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2073.41707409 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] #quality_metric: host=algo-1, epoch=161, train loss <loss>=5.948166197\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:33 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] Epoch[162] Batch[0] avg_epoch_loss=5.728589\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] #quality_metric: host=algo-1, epoch=162, batch=0 train loss <loss>=5.72858858109\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] Epoch[162] Batch[5] avg_epoch_loss=6.062639\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] #quality_metric: host=algo-1, epoch=162, batch=5 train loss <loss>=6.06263931592\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] Epoch[162] Batch [5]#011Speed: 4858.79 samples/sec#011loss=6.062639\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] Epoch[162] Batch[10] avg_epoch_loss=5.954768\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] #quality_metric: host=algo-1, epoch=162, batch=10 train loss <loss>=5.82532176971\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] Epoch[162] Batch [10]#011Speed: 4530.85 samples/sec#011loss=5.825322\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 337.4941349029541, \"sum\": 337.4941349029541, \"min\": 337.4941349029541}}, \"EndTime\": 1614048394.317103, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048393.979142}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1919.34592602 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] #quality_metric: host=algo-1, epoch=162, train loss <loss>=5.95476770401\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] Epoch[163] Batch[0] avg_epoch_loss=6.011154\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] #quality_metric: host=algo-1, epoch=163, batch=0 train loss <loss>=6.01115369797\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] Epoch[163] Batch[5] avg_epoch_loss=5.978978\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] #quality_metric: host=algo-1, epoch=163, batch=5 train loss <loss>=5.97897839546\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] Epoch[163] Batch [5]#011Speed: 5086.55 samples/sec#011loss=5.978978\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] Epoch[163] Batch[10] avg_epoch_loss=5.766916\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] #quality_metric: host=algo-1, epoch=163, batch=10 train loss <loss>=5.51244153976\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] Epoch[163] Batch [10]#011Speed: 4280.65 samples/sec#011loss=5.512442\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 341.8128490447998, \"sum\": 341.8128490447998, \"min\": 341.8128490447998}}, \"EndTime\": 1614048394.659544, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048394.317185}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1950.65679718 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] #quality_metric: host=algo-1, epoch=163, train loss <loss>=5.76691618833\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] Epoch[164] Batch[0] avg_epoch_loss=6.135104\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] #quality_metric: host=algo-1, epoch=164, batch=0 train loss <loss>=6.13510370255\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] Epoch[164] Batch[5] avg_epoch_loss=5.822718\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] #quality_metric: host=algo-1, epoch=164, batch=5 train loss <loss>=5.82271790504\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:34 INFO 140240734582592] Epoch[164] Batch [5]#011Speed: 4661.58 samples/sec#011loss=5.822718\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] Epoch[164] Batch[10] avg_epoch_loss=6.004650\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] #quality_metric: host=algo-1, epoch=164, batch=10 train loss <loss>=6.22296905518\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] Epoch[164] Batch [10]#011Speed: 3886.90 samples/sec#011loss=6.222969\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 342.71788597106934, \"sum\": 342.71788597106934, \"min\": 342.71788597106934}}, \"EndTime\": 1614048395.002805, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048394.659624}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1869.7043605 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] #quality_metric: host=algo-1, epoch=164, train loss <loss>=6.00465024601\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] Epoch[165] Batch[0] avg_epoch_loss=6.282765\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] #quality_metric: host=algo-1, epoch=165, batch=0 train loss <loss>=6.28276538849\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] Epoch[165] Batch[5] avg_epoch_loss=6.095165\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] #quality_metric: host=algo-1, epoch=165, batch=5 train loss <loss>=6.09516477585\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] Epoch[165] Batch [5]#011Speed: 4162.38 samples/sec#011loss=6.095165\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] processed a total of 589 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 350.16703605651855, \"sum\": 350.16703605651855, \"min\": 350.16703605651855}}, \"EndTime\": 1614048395.353509, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048395.002885}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1681.45906385 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] #quality_metric: host=algo-1, epoch=165, train loss <loss>=6.30786552429\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] Epoch[166] Batch[0] avg_epoch_loss=5.669945\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] #quality_metric: host=algo-1, epoch=166, batch=0 train loss <loss>=5.66994476318\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] Epoch[166] Batch[5] avg_epoch_loss=5.830366\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] #quality_metric: host=algo-1, epoch=166, batch=5 train loss <loss>=5.83036645253\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] Epoch[166] Batch [5]#011Speed: 4782.25 samples/sec#011loss=5.830366\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 327.146053314209, \"sum\": 327.146053314209, \"min\": 327.146053314209}}, \"EndTime\": 1614048395.681238, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048395.353594}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1903.45761922 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] #quality_metric: host=algo-1, epoch=166, train loss <loss>=5.83645801544\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] Epoch[167] Batch[0] avg_epoch_loss=6.622020\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] #quality_metric: host=algo-1, epoch=167, batch=0 train loss <loss>=6.62201976776\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] Epoch[167] Batch[5] avg_epoch_loss=6.041860\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] #quality_metric: host=algo-1, epoch=167, batch=5 train loss <loss>=6.04186010361\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:35 INFO 140240734582592] Epoch[167] Batch [5]#011Speed: 4997.51 samples/sec#011loss=6.041860\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] Epoch[167] Batch[10] avg_epoch_loss=6.290531\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] #quality_metric: host=algo-1, epoch=167, batch=10 train loss <loss>=6.58893594742\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] Epoch[167] Batch [10]#011Speed: 4313.24 samples/sec#011loss=6.588936\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 341.4309024810791, \"sum\": 341.4309024810791, \"min\": 341.4309024810791}}, \"EndTime\": 1614048396.023283, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048395.681352}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1882.60526779 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] #quality_metric: host=algo-1, epoch=167, train loss <loss>=6.2905309417\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] Epoch[168] Batch[0] avg_epoch_loss=5.869891\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] #quality_metric: host=algo-1, epoch=168, batch=0 train loss <loss>=5.86989116669\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] Epoch[168] Batch[5] avg_epoch_loss=5.915118\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] #quality_metric: host=algo-1, epoch=168, batch=5 train loss <loss>=5.91511829694\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] Epoch[168] Batch [5]#011Speed: 4406.37 samples/sec#011loss=5.915118\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] Epoch[168] Batch[10] avg_epoch_loss=5.861265\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] #quality_metric: host=algo-1, epoch=168, batch=10 train loss <loss>=5.79664020538\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] Epoch[168] Batch [10]#011Speed: 4413.26 samples/sec#011loss=5.796640\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 337.1739387512207, \"sum\": 337.1739387512207, \"min\": 337.1739387512207}}, \"EndTime\": 1614048396.360974, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048396.023363}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1927.08524478 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] #quality_metric: host=algo-1, epoch=168, train loss <loss>=5.86126461896\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] Epoch[169] Batch[0] avg_epoch_loss=5.699463\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] #quality_metric: host=algo-1, epoch=169, batch=0 train loss <loss>=5.69946336746\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] Epoch[169] Batch[5] avg_epoch_loss=5.904011\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] #quality_metric: host=algo-1, epoch=169, batch=5 train loss <loss>=5.90401077271\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] Epoch[169] Batch [5]#011Speed: 4281.79 samples/sec#011loss=5.904011\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 320.42598724365234, \"sum\": 320.42598724365234, \"min\": 320.42598724365234}}, \"EndTime\": 1614048396.68196, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048396.361062}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1968.49187049 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] #quality_metric: host=algo-1, epoch=169, train loss <loss>=5.86135644913\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] Epoch[170] Batch[0] avg_epoch_loss=5.592533\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=5.59253311157\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] Epoch[170] Batch[5] avg_epoch_loss=5.845933\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=5.84593288104\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:36 INFO 140240734582592] Epoch[170] Batch [5]#011Speed: 4966.02 samples/sec#011loss=5.845933\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] Epoch[170] Batch[10] avg_epoch_loss=5.683619\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] #quality_metric: host=algo-1, epoch=170, batch=10 train loss <loss>=5.4888422966\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] Epoch[170] Batch [10]#011Speed: 4554.90 samples/sec#011loss=5.488842\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 322.1778869628906, \"sum\": 322.1778869628906, \"min\": 322.1778869628906}}, \"EndTime\": 1614048397.004708, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048396.682047}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2085.06513803 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] #quality_metric: host=algo-1, epoch=170, train loss <loss>=5.68361897902\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] Saved checkpoint to \"/opt/ml/model/state_8a5de885-ccae-4d7f-bd24-dcbc523cf081-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 12.738943099975586, \"sum\": 12.738943099975586, \"min\": 12.738943099975586}}, \"EndTime\": 1614048397.018021, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048397.004785}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] Epoch[171] Batch[0] avg_epoch_loss=5.498738\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=5.49873781204\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] Epoch[171] Batch[5] avg_epoch_loss=5.884395\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=5.88439504306\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] Epoch[171] Batch [5]#011Speed: 5152.23 samples/sec#011loss=5.884395\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] Epoch[171] Batch[10] avg_epoch_loss=5.847386\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] #quality_metric: host=algo-1, epoch=171, batch=10 train loss <loss>=5.80297517776\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] Epoch[171] Batch [10]#011Speed: 4966.32 samples/sec#011loss=5.802975\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 323.4531879425049, \"sum\": 323.4531879425049, \"min\": 323.4531879425049}}, \"EndTime\": 1614048397.341628, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048397.018102}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2021.10111714 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] #quality_metric: host=algo-1, epoch=171, train loss <loss>=5.84738601338\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] Epoch[172] Batch[0] avg_epoch_loss=5.607906\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=5.60790634155\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] Epoch[172] Batch[5] avg_epoch_loss=5.959871\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=5.95987089475\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] Epoch[172] Batch [5]#011Speed: 5161.03 samples/sec#011loss=5.959871\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 284.0461730957031, \"sum\": 284.0461730957031, \"min\": 284.0461730957031}}, \"EndTime\": 1614048397.626245, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048397.341714}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2234.64045334 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] #quality_metric: host=algo-1, epoch=172, train loss <loss>=5.95058498383\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] Epoch[173] Batch[0] avg_epoch_loss=5.698845\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=5.69884490967\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] Epoch[173] Batch[5] avg_epoch_loss=5.938375\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=5.93837547302\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] Epoch[173] Batch [5]#011Speed: 5043.11 samples/sec#011loss=5.938375\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] Epoch[173] Batch[10] avg_epoch_loss=5.700241\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] #quality_metric: host=algo-1, epoch=173, batch=10 train loss <loss>=5.41447920799\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] Epoch[173] Batch [10]#011Speed: 3824.00 samples/sec#011loss=5.414479\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 318.93301010131836, \"sum\": 318.93301010131836, \"min\": 318.93301010131836}}, \"EndTime\": 1614048397.945784, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048397.626328}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2037.34343275 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] #quality_metric: host=algo-1, epoch=173, train loss <loss>=5.7002408071\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:37 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] Epoch[174] Batch[0] avg_epoch_loss=6.383854\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=6.38385391235\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] Epoch[174] Batch[5] avg_epoch_loss=6.107722\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=6.10772212346\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] Epoch[174] Batch [5]#011Speed: 4244.94 samples/sec#011loss=6.107722\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] processed a total of 607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 312.7560615539551, \"sum\": 312.7560615539551, \"min\": 312.7560615539551}}, \"EndTime\": 1614048398.259032, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048397.945863}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1939.91058228 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] #quality_metric: host=algo-1, epoch=174, train loss <loss>=6.05918226242\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] Epoch[175] Batch[0] avg_epoch_loss=5.378623\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=5.37862300873\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] Epoch[175] Batch[5] avg_epoch_loss=5.958756\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=5.95875620842\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] Epoch[175] Batch [5]#011Speed: 4214.92 samples/sec#011loss=5.958756\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] Epoch[175] Batch[10] avg_epoch_loss=6.095021\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] #quality_metric: host=algo-1, epoch=175, batch=10 train loss <loss>=6.25853977203\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] Epoch[175] Batch [10]#011Speed: 4913.23 samples/sec#011loss=6.258540\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] processed a total of 694 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 320.0719356536865, \"sum\": 320.0719356536865, \"min\": 320.0719356536865}}, \"EndTime\": 1614048398.579728, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048398.259119}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2167.4908251 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] #quality_metric: host=algo-1, epoch=175, train loss <loss>=6.09502146461\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] Epoch[176] Batch[0] avg_epoch_loss=6.311913\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=6.31191253662\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] Epoch[176] Batch[5] avg_epoch_loss=5.982750\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=5.98275025686\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] Epoch[176] Batch [5]#011Speed: 4850.40 samples/sec#011loss=5.982750\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 292.19889640808105, \"sum\": 292.19889640808105, \"min\": 292.19889640808105}}, \"EndTime\": 1614048398.872489, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048398.579797}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2110.72288767 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] #quality_metric: host=algo-1, epoch=176, train loss <loss>=5.88433074951\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:38 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] Epoch[177] Batch[0] avg_epoch_loss=5.835347\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] #quality_metric: host=algo-1, epoch=177, batch=0 train loss <loss>=5.83534669876\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] Epoch[177] Batch[5] avg_epoch_loss=6.002367\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] #quality_metric: host=algo-1, epoch=177, batch=5 train loss <loss>=6.00236741702\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] Epoch[177] Batch [5]#011Speed: 5159.54 samples/sec#011loss=6.002367\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 296.25821113586426, \"sum\": 296.25821113586426, \"min\": 296.25821113586426}}, \"EndTime\": 1614048399.169334, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048398.872569}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2115.55598745 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] #quality_metric: host=algo-1, epoch=177, train loss <loss>=6.08873114586\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] Epoch[178] Batch[0] avg_epoch_loss=5.593501\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] #quality_metric: host=algo-1, epoch=178, batch=0 train loss <loss>=5.593501091\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] Epoch[178] Batch[5] avg_epoch_loss=5.988485\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] #quality_metric: host=algo-1, epoch=178, batch=5 train loss <loss>=5.98848501841\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] Epoch[178] Batch [5]#011Speed: 5047.16 samples/sec#011loss=5.988485\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] Epoch[178] Batch[10] avg_epoch_loss=5.774978\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] #quality_metric: host=algo-1, epoch=178, batch=10 train loss <loss>=5.51877059937\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] Epoch[178] Batch [10]#011Speed: 4959.55 samples/sec#011loss=5.518771\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 330.17683029174805, \"sum\": 330.17683029174805, \"min\": 330.17683029174805}}, \"EndTime\": 1614048399.500089, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048399.169418}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1949.78996279 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] #quality_metric: host=algo-1, epoch=178, train loss <loss>=5.7749784643\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] Epoch[179] Batch[0] avg_epoch_loss=6.067867\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] #quality_metric: host=algo-1, epoch=179, batch=0 train loss <loss>=6.06786680222\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] Epoch[179] Batch[5] avg_epoch_loss=5.980852\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] #quality_metric: host=algo-1, epoch=179, batch=5 train loss <loss>=5.98085244497\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] Epoch[179] Batch [5]#011Speed: 4780.04 samples/sec#011loss=5.980852\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 322.79300689697266, \"sum\": 322.79300689697266, \"min\": 322.79300689697266}}, \"EndTime\": 1614048399.823409, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048399.500167}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1957.15213852 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] #quality_metric: host=algo-1, epoch=179, train loss <loss>=6.0603032589\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:39 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] Epoch[180] Batch[0] avg_epoch_loss=5.875018\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] #quality_metric: host=algo-1, epoch=180, batch=0 train loss <loss>=5.87501764297\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] Epoch[180] Batch[5] avg_epoch_loss=6.022327\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] #quality_metric: host=algo-1, epoch=180, batch=5 train loss <loss>=6.02232662837\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] Epoch[180] Batch [5]#011Speed: 4831.43 samples/sec#011loss=6.022327\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] Epoch[180] Batch[10] avg_epoch_loss=5.963306\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] #quality_metric: host=algo-1, epoch=180, batch=10 train loss <loss>=5.89248046875\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] Epoch[180] Batch [10]#011Speed: 4769.64 samples/sec#011loss=5.892480\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 319.9319839477539, \"sum\": 319.9319839477539, \"min\": 319.9319839477539}}, \"EndTime\": 1614048400.1439, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048399.823494}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2112.19514128 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] #quality_metric: host=algo-1, epoch=180, train loss <loss>=5.96330564672\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] Epoch[181] Batch[0] avg_epoch_loss=5.749670\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] #quality_metric: host=algo-1, epoch=181, batch=0 train loss <loss>=5.74967002869\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] Epoch[181] Batch[5] avg_epoch_loss=5.901091\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] #quality_metric: host=algo-1, epoch=181, batch=5 train loss <loss>=5.90109109879\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] Epoch[181] Batch [5]#011Speed: 4313.02 samples/sec#011loss=5.901091\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 329.0119171142578, \"sum\": 329.0119171142578, \"min\": 329.0119171142578}}, \"EndTime\": 1614048400.473436, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048400.143978}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1847.28270746 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] #quality_metric: host=algo-1, epoch=181, train loss <loss>=5.67503764629\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] Saved checkpoint to \"/opt/ml/model/state_596c991f-8353-4944-a261-1ec5df698efb-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 11.608123779296875, \"sum\": 11.608123779296875, \"min\": 11.608123779296875}}, \"EndTime\": 1614048400.485667, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048400.473517}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] Epoch[182] Batch[0] avg_epoch_loss=6.279484\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] #quality_metric: host=algo-1, epoch=182, batch=0 train loss <loss>=6.27948379517\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] Epoch[182] Batch[5] avg_epoch_loss=6.051042\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] #quality_metric: host=algo-1, epoch=182, batch=5 train loss <loss>=6.05104160309\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] Epoch[182] Batch [5]#011Speed: 4537.46 samples/sec#011loss=6.051042\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] processed a total of 614 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 337.26000785827637, \"sum\": 337.26000785827637, \"min\": 337.26000785827637}}, \"EndTime\": 1614048400.823075, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048400.485748}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1819.93242378 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] #quality_metric: host=algo-1, epoch=182, train loss <loss>=6.11498970985\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:40 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] Epoch[183] Batch[0] avg_epoch_loss=6.004301\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] #quality_metric: host=algo-1, epoch=183, batch=0 train loss <loss>=6.00430059433\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] Epoch[183] Batch[5] avg_epoch_loss=5.975479\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] #quality_metric: host=algo-1, epoch=183, batch=5 train loss <loss>=5.97547856967\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] Epoch[183] Batch [5]#011Speed: 4900.69 samples/sec#011loss=5.975479\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] Epoch[183] Batch[10] avg_epoch_loss=6.191477\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] #quality_metric: host=algo-1, epoch=183, batch=10 train loss <loss>=6.45067615509\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] Epoch[183] Batch [10]#011Speed: 4295.26 samples/sec#011loss=6.450676\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 333.16922187805176, \"sum\": 333.16922187805176, \"min\": 333.16922187805176}}, \"EndTime\": 1614048401.156777, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048400.823149}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2007.36947471 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] #quality_metric: host=algo-1, epoch=183, train loss <loss>=6.19147747213\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] Epoch[184] Batch[0] avg_epoch_loss=5.582150\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] #quality_metric: host=algo-1, epoch=184, batch=0 train loss <loss>=5.58214998245\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] Epoch[184] Batch[5] avg_epoch_loss=6.001575\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] #quality_metric: host=algo-1, epoch=184, batch=5 train loss <loss>=6.00157467524\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] Epoch[184] Batch [5]#011Speed: 5009.47 samples/sec#011loss=6.001575\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 301.54895782470703, \"sum\": 301.54895782470703, \"min\": 301.54895782470703}}, \"EndTime\": 1614048401.458919, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048401.156842}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2091.70230335 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] #quality_metric: host=algo-1, epoch=184, train loss <loss>=6.00403599739\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] Epoch[185] Batch[0] avg_epoch_loss=5.891289\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] #quality_metric: host=algo-1, epoch=185, batch=0 train loss <loss>=5.89128923416\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] Epoch[185] Batch[5] avg_epoch_loss=5.826669\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] #quality_metric: host=algo-1, epoch=185, batch=5 train loss <loss>=5.82666889826\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] Epoch[185] Batch [5]#011Speed: 4271.10 samples/sec#011loss=5.826669\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] Epoch[185] Batch[10] avg_epoch_loss=6.124338\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] #quality_metric: host=algo-1, epoch=185, batch=10 train loss <loss>=6.48154067993\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] Epoch[185] Batch [10]#011Speed: 4675.89 samples/sec#011loss=6.481541\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 329.03003692626953, \"sum\": 329.03003692626953, \"min\": 329.03003692626953}}, \"EndTime\": 1614048401.78852, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048401.459001}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1990.05224915 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] #quality_metric: host=algo-1, epoch=185, train loss <loss>=6.12433788993\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] Epoch[186] Batch[0] avg_epoch_loss=5.906256\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:41 INFO 140240734582592] #quality_metric: host=algo-1, epoch=186, batch=0 train loss <loss>=5.90625619888\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] Epoch[186] Batch[5] avg_epoch_loss=6.207357\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] #quality_metric: host=algo-1, epoch=186, batch=5 train loss <loss>=6.20735661189\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] Epoch[186] Batch [5]#011Speed: 4058.64 samples/sec#011loss=6.207357\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] Epoch[186] Batch[10] avg_epoch_loss=6.374997\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] #quality_metric: host=algo-1, epoch=186, batch=10 train loss <loss>=6.57616567612\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] Epoch[186] Batch [10]#011Speed: 4480.29 samples/sec#011loss=6.576166\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 331.87007904052734, \"sum\": 331.87007904052734, \"min\": 331.87007904052734}}, \"EndTime\": 1614048402.121016, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048401.788592}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1997.08537166 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] #quality_metric: host=algo-1, epoch=186, train loss <loss>=6.37499709563\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] Epoch[187] Batch[0] avg_epoch_loss=6.186579\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] #quality_metric: host=algo-1, epoch=187, batch=0 train loss <loss>=6.18657922745\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] Epoch[187] Batch[5] avg_epoch_loss=6.068277\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] #quality_metric: host=algo-1, epoch=187, batch=5 train loss <loss>=6.06827664375\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] Epoch[187] Batch [5]#011Speed: 4159.89 samples/sec#011loss=6.068277\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 323.3790397644043, \"sum\": 323.3790397644043, \"min\": 323.3790397644043}}, \"EndTime\": 1614048402.44514, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048402.121095}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1966.02783535 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] #quality_metric: host=algo-1, epoch=187, train loss <loss>=6.02256131172\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] Epoch[188] Batch[0] avg_epoch_loss=5.639848\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] #quality_metric: host=algo-1, epoch=188, batch=0 train loss <loss>=5.63984823227\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] Epoch[188] Batch[5] avg_epoch_loss=6.011462\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] #quality_metric: host=algo-1, epoch=188, batch=5 train loss <loss>=6.01146189372\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] Epoch[188] Batch [5]#011Speed: 4985.60 samples/sec#011loss=6.011462\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] processed a total of 609 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 297.9750633239746, \"sum\": 297.9750633239746, \"min\": 297.9750633239746}}, \"EndTime\": 1614048402.74374, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048402.445213}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2042.94681749 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] #quality_metric: host=algo-1, epoch=188, train loss <loss>=5.73393959999\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] Epoch[189] Batch[0] avg_epoch_loss=6.150864\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:42 INFO 140240734582592] #quality_metric: host=algo-1, epoch=189, batch=0 train loss <loss>=6.1508641243\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] Epoch[189] Batch[5] avg_epoch_loss=6.177713\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] #quality_metric: host=algo-1, epoch=189, batch=5 train loss <loss>=6.17771275838\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] Epoch[189] Batch [5]#011Speed: 4827.13 samples/sec#011loss=6.177713\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 331.47597312927246, \"sum\": 331.47597312927246, \"min\": 331.47597312927246}}, \"EndTime\": 1614048403.075812, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048402.743823}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1930.04757615 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] #quality_metric: host=algo-1, epoch=189, train loss <loss>=6.15655055046\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] Epoch[190] Batch[0] avg_epoch_loss=6.603573\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] #quality_metric: host=algo-1, epoch=190, batch=0 train loss <loss>=6.6035733223\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] Epoch[190] Batch[5] avg_epoch_loss=5.951496\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] #quality_metric: host=algo-1, epoch=190, batch=5 train loss <loss>=5.95149612427\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] Epoch[190] Batch [5]#011Speed: 4447.73 samples/sec#011loss=5.951496\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 321.14696502685547, \"sum\": 321.14696502685547, \"min\": 321.14696502685547}}, \"EndTime\": 1614048403.397538, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048403.075894}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1917.38899967 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] #quality_metric: host=algo-1, epoch=190, train loss <loss>=5.8128443718\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] Epoch[191] Batch[0] avg_epoch_loss=5.900160\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] #quality_metric: host=algo-1, epoch=191, batch=0 train loss <loss>=5.90015983582\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] Epoch[191] Batch[5] avg_epoch_loss=6.028006\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] #quality_metric: host=algo-1, epoch=191, batch=5 train loss <loss>=6.02800607681\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] Epoch[191] Batch [5]#011Speed: 4917.48 samples/sec#011loss=6.028006\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] Epoch[191] Batch[10] avg_epoch_loss=6.121959\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] #quality_metric: host=algo-1, epoch=191, batch=10 train loss <loss>=6.2347026825\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] Epoch[191] Batch [10]#011Speed: 4460.50 samples/sec#011loss=6.234703\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] processed a total of 678 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 336.23480796813965, \"sum\": 336.23480796813965, \"min\": 336.23480796813965}}, \"EndTime\": 1614048403.734402, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048403.397619}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2015.72760504 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] #quality_metric: host=algo-1, epoch=191, train loss <loss>=6.1219590794\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] Epoch[192] Batch[0] avg_epoch_loss=6.099425\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:43 INFO 140240734582592] #quality_metric: host=algo-1, epoch=192, batch=0 train loss <loss>=6.09942531586\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] Epoch[192] Batch[5] avg_epoch_loss=5.967062\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] #quality_metric: host=algo-1, epoch=192, batch=5 train loss <loss>=5.96706231435\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] Epoch[192] Batch [5]#011Speed: 4475.39 samples/sec#011loss=5.967062\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] Epoch[192] Batch[10] avg_epoch_loss=5.442088\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] #quality_metric: host=algo-1, epoch=192, batch=10 train loss <loss>=4.81211957932\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] Epoch[192] Batch [10]#011Speed: 4530.45 samples/sec#011loss=4.812120\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 349.4851589202881, \"sum\": 349.4851589202881, \"min\": 349.4851589202881}}, \"EndTime\": 1614048404.084415, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048403.734481}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1839.19176798 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] #quality_metric: host=algo-1, epoch=192, train loss <loss>=5.44208834388\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] Saved checkpoint to \"/opt/ml/model/state_4aa6e223-6d78-44b0-83a6-4369160c4756-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 9.479999542236328, \"sum\": 9.479999542236328, \"min\": 9.479999542236328}}, \"EndTime\": 1614048404.094567, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048404.084498}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] Epoch[193] Batch[0] avg_epoch_loss=5.676481\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] #quality_metric: host=algo-1, epoch=193, batch=0 train loss <loss>=5.67648077011\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] Epoch[193] Batch[5] avg_epoch_loss=5.839261\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] #quality_metric: host=algo-1, epoch=193, batch=5 train loss <loss>=5.8392607371\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] Epoch[193] Batch [5]#011Speed: 5277.56 samples/sec#011loss=5.839261\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 292.29092597961426, \"sum\": 292.29092597961426, \"min\": 292.29092597961426}}, \"EndTime\": 1614048404.386993, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048404.094636}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2157.89274809 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] #quality_metric: host=algo-1, epoch=193, train loss <loss>=5.82662448883\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] Epoch[194] Batch[0] avg_epoch_loss=5.674838\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] #quality_metric: host=algo-1, epoch=194, batch=0 train loss <loss>=5.67483758926\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] Epoch[194] Batch[5] avg_epoch_loss=5.988607\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] #quality_metric: host=algo-1, epoch=194, batch=5 train loss <loss>=5.98860732714\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] Epoch[194] Batch [5]#011Speed: 4257.53 samples/sec#011loss=5.988607\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] Epoch[194] Batch[10] avg_epoch_loss=5.976554\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] #quality_metric: host=algo-1, epoch=194, batch=10 train loss <loss>=5.96209068298\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] Epoch[194] Batch [10]#011Speed: 3945.17 samples/sec#011loss=5.962091\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 358.0169677734375, \"sum\": 358.0169677734375, \"min\": 358.0169677734375}}, \"EndTime\": 1614048404.745562, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048404.387077}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1798.22980269 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] #quality_metric: host=algo-1, epoch=194, train loss <loss>=5.97655430707\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] Epoch[195] Batch[0] avg_epoch_loss=5.638670\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] #quality_metric: host=algo-1, epoch=195, batch=0 train loss <loss>=5.63866996765\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] Epoch[195] Batch[5] avg_epoch_loss=5.916610\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] #quality_metric: host=algo-1, epoch=195, batch=5 train loss <loss>=5.91661024094\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:44 INFO 140240734582592] Epoch[195] Batch [5]#011Speed: 4184.65 samples/sec#011loss=5.916610\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] processed a total of 609 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 315.49596786499023, \"sum\": 315.49596786499023, \"min\": 315.49596786499023}}, \"EndTime\": 1614048405.061681, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048404.745633}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1929.68890709 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] #quality_metric: host=algo-1, epoch=195, train loss <loss>=5.65415606499\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] Epoch[196] Batch[0] avg_epoch_loss=5.665506\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] #quality_metric: host=algo-1, epoch=196, batch=0 train loss <loss>=5.66550588608\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] Epoch[196] Batch[5] avg_epoch_loss=5.893970\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] #quality_metric: host=algo-1, epoch=196, batch=5 train loss <loss>=5.89396969477\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] Epoch[196] Batch [5]#011Speed: 3960.53 samples/sec#011loss=5.893970\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] processed a total of 611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 310.50992012023926, \"sum\": 310.50992012023926, \"min\": 310.50992012023926}}, \"EndTime\": 1614048405.372798, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048405.061743}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1966.91849558 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] #quality_metric: host=algo-1, epoch=196, train loss <loss>=5.96926054955\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] Epoch[197] Batch[0] avg_epoch_loss=5.689533\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] #quality_metric: host=algo-1, epoch=197, batch=0 train loss <loss>=5.68953275681\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] Epoch[197] Batch[5] avg_epoch_loss=5.673828\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] #quality_metric: host=algo-1, epoch=197, batch=5 train loss <loss>=5.67382828395\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] Epoch[197] Batch [5]#011Speed: 4953.95 samples/sec#011loss=5.673828\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] Epoch[197] Batch[10] avg_epoch_loss=5.817204\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] #quality_metric: host=algo-1, epoch=197, batch=10 train loss <loss>=5.98925457001\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] Epoch[197] Batch [10]#011Speed: 4110.10 samples/sec#011loss=5.989255\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] processed a total of 706 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 370.8920478820801, \"sum\": 370.8920478820801, \"min\": 370.8920478820801}}, \"EndTime\": 1614048405.74427, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048405.372887}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1902.96469542 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] #quality_metric: host=algo-1, epoch=197, train loss <loss>=5.79134968917\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] Epoch[198] Batch[0] avg_epoch_loss=6.189777\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] #quality_metric: host=algo-1, epoch=198, batch=0 train loss <loss>=6.18977689743\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] Epoch[198] Batch[5] avg_epoch_loss=5.809668\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] #quality_metric: host=algo-1, epoch=198, batch=5 train loss <loss>=5.80966790517\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:45 INFO 140240734582592] Epoch[198] Batch [5]#011Speed: 5194.04 samples/sec#011loss=5.809668\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 300.7359504699707, \"sum\": 300.7359504699707, \"min\": 300.7359504699707}}, \"EndTime\": 1614048406.045637, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048405.744345}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2027.60192987 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] #quality_metric: host=algo-1, epoch=198, train loss <loss>=6.09806237221\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] Epoch[199] Batch[0] avg_epoch_loss=6.089062\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] #quality_metric: host=algo-1, epoch=199, batch=0 train loss <loss>=6.0890622139\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] Epoch[199] Batch[5] avg_epoch_loss=6.215525\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] #quality_metric: host=algo-1, epoch=199, batch=5 train loss <loss>=6.21552499135\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] Epoch[199] Batch [5]#011Speed: 4015.81 samples/sec#011loss=6.215525\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 315.4139518737793, \"sum\": 315.4139518737793, \"min\": 315.4139518737793}}, \"EndTime\": 1614048406.361648, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048406.045709}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1980.78784495 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] #quality_metric: host=algo-1, epoch=199, train loss <loss>=6.18790335655\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] Epoch[200] Batch[0] avg_epoch_loss=5.880312\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] #quality_metric: host=algo-1, epoch=200, batch=0 train loss <loss>=5.88031244278\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] Epoch[200] Batch[5] avg_epoch_loss=6.069003\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] #quality_metric: host=algo-1, epoch=200, batch=5 train loss <loss>=6.06900326411\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] Epoch[200] Batch [5]#011Speed: 4355.40 samples/sec#011loss=6.069003\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] Epoch[200] Batch[10] avg_epoch_loss=5.941370\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] #quality_metric: host=algo-1, epoch=200, batch=10 train loss <loss>=5.78821077347\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] Epoch[200] Batch [10]#011Speed: 4063.49 samples/sec#011loss=5.788211\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 368.7930107116699, \"sum\": 368.7930107116699, \"min\": 368.7930107116699}}, \"EndTime\": 1614048406.730982, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048406.36173}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1742.98232806 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] #quality_metric: host=algo-1, epoch=200, train loss <loss>=5.94137031382\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] Epoch[201] Batch[0] avg_epoch_loss=6.555026\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] #quality_metric: host=algo-1, epoch=201, batch=0 train loss <loss>=6.55502557755\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] Epoch[201] Batch[5] avg_epoch_loss=5.923999\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] #quality_metric: host=algo-1, epoch=201, batch=5 train loss <loss>=5.92399859428\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:46 INFO 140240734582592] Epoch[201] Batch [5]#011Speed: 4517.93 samples/sec#011loss=5.923999\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] Epoch[201] Batch[10] avg_epoch_loss=6.019989\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] #quality_metric: host=algo-1, epoch=201, batch=10 train loss <loss>=6.13517818451\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] Epoch[201] Batch [10]#011Speed: 4232.69 samples/sec#011loss=6.135178\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 329.7240734100342, \"sum\": 329.7240734100342, \"min\": 329.7240734100342}}, \"EndTime\": 1614048407.061306, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048406.731061}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1988.69822124 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] #quality_metric: host=algo-1, epoch=201, train loss <loss>=6.01998931711\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] Epoch[202] Batch[0] avg_epoch_loss=6.505682\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] #quality_metric: host=algo-1, epoch=202, batch=0 train loss <loss>=6.50568151474\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] Epoch[202] Batch[5] avg_epoch_loss=6.180944\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] #quality_metric: host=algo-1, epoch=202, batch=5 train loss <loss>=6.18094364802\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] Epoch[202] Batch [5]#011Speed: 4687.40 samples/sec#011loss=6.180944\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 299.6959686279297, \"sum\": 299.6959686279297, \"min\": 299.6959686279297}}, \"EndTime\": 1614048407.361595, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048407.061379}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2077.94022521 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] #quality_metric: host=algo-1, epoch=202, train loss <loss>=5.96905503273\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] Epoch[203] Batch[0] avg_epoch_loss=5.613489\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] #quality_metric: host=algo-1, epoch=203, batch=0 train loss <loss>=5.61348867416\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] Epoch[203] Batch[5] avg_epoch_loss=5.999565\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] #quality_metric: host=algo-1, epoch=203, batch=5 train loss <loss>=5.99956472715\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] Epoch[203] Batch [5]#011Speed: 4663.01 samples/sec#011loss=5.999565\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] Epoch[203] Batch[10] avg_epoch_loss=5.682382\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] #quality_metric: host=algo-1, epoch=203, batch=10 train loss <loss>=5.30176181793\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] Epoch[203] Batch [10]#011Speed: 4681.80 samples/sec#011loss=5.301762\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 326.0841369628906, \"sum\": 326.0841369628906, \"min\": 326.0841369628906}}, \"EndTime\": 1614048407.688226, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048407.361676}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2004.9049147 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] #quality_metric: host=algo-1, epoch=203, train loss <loss>=5.6823815866\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] Epoch[204] Batch[0] avg_epoch_loss=5.586482\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] #quality_metric: host=algo-1, epoch=204, batch=0 train loss <loss>=5.58648204803\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] Epoch[204] Batch[5] avg_epoch_loss=6.007239\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] #quality_metric: host=algo-1, epoch=204, batch=5 train loss <loss>=6.00723902384\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:47 INFO 140240734582592] Epoch[204] Batch [5]#011Speed: 4831.71 samples/sec#011loss=6.007239\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 346.1928367614746, \"sum\": 346.1928367614746, \"min\": 346.1928367614746}}, \"EndTime\": 1614048408.034944, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048407.688306}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1787.42133595 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] #quality_metric: host=algo-1, epoch=204, train loss <loss>=5.87819414139\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] Epoch[205] Batch[0] avg_epoch_loss=6.159882\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] #quality_metric: host=algo-1, epoch=205, batch=0 train loss <loss>=6.1598815918\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] Epoch[205] Batch[5] avg_epoch_loss=5.856551\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] #quality_metric: host=algo-1, epoch=205, batch=5 train loss <loss>=5.85655148824\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] Epoch[205] Batch [5]#011Speed: 3994.96 samples/sec#011loss=5.856551\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] Epoch[205] Batch[10] avg_epoch_loss=5.731595\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] #quality_metric: host=algo-1, epoch=205, batch=10 train loss <loss>=5.58164625168\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] Epoch[205] Batch [10]#011Speed: 4140.68 samples/sec#011loss=5.581646\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] processed a total of 679 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 337.3429775238037, \"sum\": 337.3429775238037, \"min\": 337.3429775238037}}, \"EndTime\": 1614048408.372945, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048408.035026}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2012.10855753 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] #quality_metric: host=algo-1, epoch=205, train loss <loss>=5.73159456253\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] Epoch[206] Batch[0] avg_epoch_loss=5.802595\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] #quality_metric: host=algo-1, epoch=206, batch=0 train loss <loss>=5.80259466171\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] Epoch[206] Batch[5] avg_epoch_loss=5.933778\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] #quality_metric: host=algo-1, epoch=206, batch=5 train loss <loss>=5.9337776502\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] Epoch[206] Batch [5]#011Speed: 4259.57 samples/sec#011loss=5.933778\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] Epoch[206] Batch[10] avg_epoch_loss=6.231583\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] #quality_metric: host=algo-1, epoch=206, batch=10 train loss <loss>=6.58894882202\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] Epoch[206] Batch [10]#011Speed: 4065.20 samples/sec#011loss=6.588949\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 331.1901092529297, \"sum\": 331.1901092529297, \"min\": 331.1901092529297}}, \"EndTime\": 1614048408.704731, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048408.373021}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1983.08392596 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] #quality_metric: host=algo-1, epoch=206, train loss <loss>=6.2315827283\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] Epoch[207] Batch[0] avg_epoch_loss=6.335952\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] #quality_metric: host=algo-1, epoch=207, batch=0 train loss <loss>=6.33595180511\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] Epoch[207] Batch[5] avg_epoch_loss=6.245172\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] #quality_metric: host=algo-1, epoch=207, batch=5 train loss <loss>=6.24517186483\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:48 INFO 140240734582592] Epoch[207] Batch [5]#011Speed: 4463.35 samples/sec#011loss=6.245172\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 300.199031829834, \"sum\": 300.199031829834, \"min\": 300.199031829834}}, \"EndTime\": 1614048409.00558, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048408.704802}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2084.46374267 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] #quality_metric: host=algo-1, epoch=207, train loss <loss>=5.96777181625\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] Epoch[208] Batch[0] avg_epoch_loss=5.799122\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] #quality_metric: host=algo-1, epoch=208, batch=0 train loss <loss>=5.79912185669\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] Epoch[208] Batch[5] avg_epoch_loss=6.036777\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] #quality_metric: host=algo-1, epoch=208, batch=5 train loss <loss>=6.03677694003\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] Epoch[208] Batch [5]#011Speed: 5008.05 samples/sec#011loss=6.036777\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] Epoch[208] Batch[10] avg_epoch_loss=6.159323\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] #quality_metric: host=algo-1, epoch=208, batch=10 train loss <loss>=6.3063785553\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] Epoch[208] Batch [10]#011Speed: 3955.55 samples/sec#011loss=6.306379\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 347.20897674560547, \"sum\": 347.20897674560547, \"min\": 347.20897674560547}}, \"EndTime\": 1614048409.35338, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048409.00566}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1905.94694212 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] #quality_metric: host=algo-1, epoch=208, train loss <loss>=6.15932312879\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] Epoch[209] Batch[0] avg_epoch_loss=5.695708\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] #quality_metric: host=algo-1, epoch=209, batch=0 train loss <loss>=5.69570827484\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] Epoch[209] Batch[5] avg_epoch_loss=5.797401\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] #quality_metric: host=algo-1, epoch=209, batch=5 train loss <loss>=5.79740095139\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] Epoch[209] Batch [5]#011Speed: 5146.60 samples/sec#011loss=5.797401\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] Epoch[209] Batch[10] avg_epoch_loss=5.761317\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] #quality_metric: host=algo-1, epoch=209, batch=10 train loss <loss>=5.71801538467\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] Epoch[209] Batch [10]#011Speed: 4996.64 samples/sec#011loss=5.718015\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 323.106050491333, \"sum\": 323.106050491333, \"min\": 323.106050491333}}, \"EndTime\": 1614048409.677044, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048409.353467}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2060.46580847 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] #quality_metric: host=algo-1, epoch=209, train loss <loss>=5.76131660288\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] Epoch[210] Batch[0] avg_epoch_loss=6.311038\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] #quality_metric: host=algo-1, epoch=210, batch=0 train loss <loss>=6.31103849411\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] Epoch[210] Batch[5] avg_epoch_loss=6.053991\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] #quality_metric: host=algo-1, epoch=210, batch=5 train loss <loss>=6.05399068197\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:49 INFO 140240734582592] Epoch[210] Batch [5]#011Speed: 4463.17 samples/sec#011loss=6.053991\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] Epoch[210] Batch[10] avg_epoch_loss=6.085266\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] #quality_metric: host=algo-1, epoch=210, batch=10 train loss <loss>=6.12279644012\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] Epoch[210] Batch [10]#011Speed: 4513.86 samples/sec#011loss=6.122796\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] processed a total of 693 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 384.627103805542, \"sum\": 384.627103805542, \"min\": 384.627103805542}}, \"EndTime\": 1614048410.06226, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048409.677129}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1801.2069417 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] #quality_metric: host=algo-1, epoch=210, train loss <loss>=6.08526602658\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] Epoch[211] Batch[0] avg_epoch_loss=5.352152\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] #quality_metric: host=algo-1, epoch=211, batch=0 train loss <loss>=5.35215234756\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] Epoch[211] Batch[5] avg_epoch_loss=5.665631\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] #quality_metric: host=algo-1, epoch=211, batch=5 train loss <loss>=5.66563121478\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] Epoch[211] Batch [5]#011Speed: 4081.17 samples/sec#011loss=5.665631\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 322.0179080963135, \"sum\": 322.0179080963135, \"min\": 322.0179080963135}}, \"EndTime\": 1614048410.384789, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048410.062336}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1915.4341137 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] #quality_metric: host=algo-1, epoch=211, train loss <loss>=5.88012528419\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] Epoch[212] Batch[0] avg_epoch_loss=5.858241\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] #quality_metric: host=algo-1, epoch=212, batch=0 train loss <loss>=5.8582406044\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] Epoch[212] Batch[5] avg_epoch_loss=6.013752\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] #quality_metric: host=algo-1, epoch=212, batch=5 train loss <loss>=6.01375214259\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] Epoch[212] Batch [5]#011Speed: 5292.94 samples/sec#011loss=6.013752\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 283.2639217376709, \"sum\": 283.2639217376709, \"min\": 283.2639217376709}}, \"EndTime\": 1614048410.668722, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048410.384856}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2191.38140021 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] #quality_metric: host=algo-1, epoch=212, train loss <loss>=6.11007695198\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] Epoch[213] Batch[0] avg_epoch_loss=5.869763\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] #quality_metric: host=algo-1, epoch=213, batch=0 train loss <loss>=5.86976337433\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] Epoch[213] Batch[5] avg_epoch_loss=6.019526\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] #quality_metric: host=algo-1, epoch=213, batch=5 train loss <loss>=6.01952648163\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] Epoch[213] Batch [5]#011Speed: 4472.76 samples/sec#011loss=6.019526\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] Epoch[213] Batch[10] avg_epoch_loss=5.795361\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] #quality_metric: host=algo-1, epoch=213, batch=10 train loss <loss>=5.52636137009\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] Epoch[213] Batch [10]#011Speed: 5017.17 samples/sec#011loss=5.526361\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 318.220853805542, \"sum\": 318.220853805542, \"min\": 318.220853805542}}, \"EndTime\": 1614048410.987521, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048410.668804}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2048.13804611 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] #quality_metric: host=algo-1, epoch=213, train loss <loss>=5.79536052184\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:50 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] Epoch[214] Batch[0] avg_epoch_loss=5.655360\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] #quality_metric: host=algo-1, epoch=214, batch=0 train loss <loss>=5.65536022186\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] Epoch[214] Batch[5] avg_epoch_loss=5.995668\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] #quality_metric: host=algo-1, epoch=214, batch=5 train loss <loss>=5.99566785494\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] Epoch[214] Batch [5]#011Speed: 5093.42 samples/sec#011loss=5.995668\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] processed a total of 590 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 306.57196044921875, \"sum\": 306.57196044921875, \"min\": 306.57196044921875}}, \"EndTime\": 1614048411.294605, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048410.987602}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1923.70998197 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] #quality_metric: host=algo-1, epoch=214, train loss <loss>=6.01039428711\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] Epoch[215] Batch[0] avg_epoch_loss=6.383305\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] #quality_metric: host=algo-1, epoch=215, batch=0 train loss <loss>=6.38330459595\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] Epoch[215] Batch[5] avg_epoch_loss=6.180765\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] #quality_metric: host=algo-1, epoch=215, batch=5 train loss <loss>=6.18076523145\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] Epoch[215] Batch [5]#011Speed: 5082.10 samples/sec#011loss=6.180765\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 295.1180934906006, \"sum\": 295.1180934906006, \"min\": 295.1180934906006}}, \"EndTime\": 1614048411.59028, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048411.294692}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2123.689653 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] #quality_metric: host=algo-1, epoch=215, train loss <loss>=6.06198048592\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] Epoch[216] Batch[0] avg_epoch_loss=6.076499\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] #quality_metric: host=algo-1, epoch=216, batch=0 train loss <loss>=6.07649850845\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] Epoch[216] Batch[5] avg_epoch_loss=5.912778\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] #quality_metric: host=algo-1, epoch=216, batch=5 train loss <loss>=5.91277798017\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] Epoch[216] Batch [5]#011Speed: 4124.94 samples/sec#011loss=5.912778\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] Epoch[216] Batch[10] avg_epoch_loss=5.580176\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] #quality_metric: host=algo-1, epoch=216, batch=10 train loss <loss>=5.18105421066\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] Epoch[216] Batch [10]#011Speed: 4866.93 samples/sec#011loss=5.181054\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 331.62903785705566, \"sum\": 331.62903785705566, \"min\": 331.62903785705566}}, \"EndTime\": 1614048411.922463, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048411.590364}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1935.220468 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] #quality_metric: host=algo-1, epoch=216, train loss <loss>=5.58017626676\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:51 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] Epoch[217] Batch[0] avg_epoch_loss=6.238945\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] #quality_metric: host=algo-1, epoch=217, batch=0 train loss <loss>=6.23894548416\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] Epoch[217] Batch[5] avg_epoch_loss=5.740752\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] #quality_metric: host=algo-1, epoch=217, batch=5 train loss <loss>=5.74075206121\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] Epoch[217] Batch [5]#011Speed: 4608.63 samples/sec#011loss=5.740752\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] Epoch[217] Batch[10] avg_epoch_loss=5.717489\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] #quality_metric: host=algo-1, epoch=217, batch=10 train loss <loss>=5.68957395554\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] Epoch[217] Batch [10]#011Speed: 4572.34 samples/sec#011loss=5.689574\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] processed a total of 705 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 341.92895889282227, \"sum\": 341.92895889282227, \"min\": 341.92895889282227}}, \"EndTime\": 1614048412.264946, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048411.922542}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2061.0184008 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] #quality_metric: host=algo-1, epoch=217, train loss <loss>=5.39771845937\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] Saved checkpoint to \"/opt/ml/model/state_60472301-8547-40b3-83c3-36db622998a2-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 11.092901229858398, \"sum\": 11.092901229858398, \"min\": 11.092901229858398}}, \"EndTime\": 1614048412.27666, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048412.265032}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] Epoch[218] Batch[0] avg_epoch_loss=6.031549\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] #quality_metric: host=algo-1, epoch=218, batch=0 train loss <loss>=6.03154945374\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] Epoch[218] Batch[5] avg_epoch_loss=6.075202\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] #quality_metric: host=algo-1, epoch=218, batch=5 train loss <loss>=6.07520151138\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] Epoch[218] Batch [5]#011Speed: 4640.65 samples/sec#011loss=6.075202\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] processed a total of 601 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 329.93006706237793, \"sum\": 329.93006706237793, \"min\": 329.93006706237793}}, \"EndTime\": 1614048412.606738, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048412.276744}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1820.96389173 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] #quality_metric: host=algo-1, epoch=218, train loss <loss>=6.17953491211\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] Epoch[219] Batch[0] avg_epoch_loss=6.410228\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] #quality_metric: host=algo-1, epoch=219, batch=0 train loss <loss>=6.41022825241\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] Epoch[219] Batch[5] avg_epoch_loss=6.209963\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] #quality_metric: host=algo-1, epoch=219, batch=5 train loss <loss>=6.20996316274\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] Epoch[219] Batch [5]#011Speed: 5116.16 samples/sec#011loss=6.209963\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 292.33694076538086, \"sum\": 292.33694076538086, \"min\": 292.33694076538086}}, \"EndTime\": 1614048412.899666, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048412.606818}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2188.39971988 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] #quality_metric: host=algo-1, epoch=219, train loss <loss>=6.08878908157\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:52 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] Epoch[220] Batch[0] avg_epoch_loss=5.597758\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] #quality_metric: host=algo-1, epoch=220, batch=0 train loss <loss>=5.59775781631\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] Epoch[220] Batch[5] avg_epoch_loss=5.905491\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] #quality_metric: host=algo-1, epoch=220, batch=5 train loss <loss>=5.90549063683\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] Epoch[220] Batch [5]#011Speed: 4111.37 samples/sec#011loss=5.905491\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] Epoch[220] Batch[10] avg_epoch_loss=6.134681\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] #quality_metric: host=algo-1, epoch=220, batch=10 train loss <loss>=6.40970840454\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] Epoch[220] Batch [10]#011Speed: 3988.63 samples/sec#011loss=6.409708\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 331.93516731262207, \"sum\": 331.93516731262207, \"min\": 331.93516731262207}}, \"EndTime\": 1614048413.232209, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048412.899737}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1951.56046917 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] #quality_metric: host=algo-1, epoch=220, train loss <loss>=6.13468053124\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] Epoch[221] Batch[0] avg_epoch_loss=5.526402\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] #quality_metric: host=algo-1, epoch=221, batch=0 train loss <loss>=5.52640199661\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] Epoch[221] Batch[5] avg_epoch_loss=5.974034\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] #quality_metric: host=algo-1, epoch=221, batch=5 train loss <loss>=5.97403415044\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] Epoch[221] Batch [5]#011Speed: 4468.03 samples/sec#011loss=5.974034\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] Epoch[221] Batch[10] avg_epoch_loss=6.141146\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] #quality_metric: host=algo-1, epoch=221, batch=10 train loss <loss>=6.3416809082\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] Epoch[221] Batch [10]#011Speed: 4829.96 samples/sec#011loss=6.341681\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 322.0958709716797, \"sum\": 322.0958709716797, \"min\": 322.0958709716797}}, \"EndTime\": 1614048413.554829, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048413.232285}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2051.38683219 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] #quality_metric: host=algo-1, epoch=221, train loss <loss>=6.14114631306\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] Epoch[222] Batch[0] avg_epoch_loss=6.083744\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] #quality_metric: host=algo-1, epoch=222, batch=0 train loss <loss>=6.08374404907\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] Epoch[222] Batch[5] avg_epoch_loss=5.979458\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] #quality_metric: host=algo-1, epoch=222, batch=5 train loss <loss>=5.97945817312\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] Epoch[222] Batch [5]#011Speed: 4278.02 samples/sec#011loss=5.979458\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 364.2618656158447, \"sum\": 364.2618656158447, \"min\": 364.2618656158447}}, \"EndTime\": 1614048413.919627, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048413.554907}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1717.99064199 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] #quality_metric: host=algo-1, epoch=222, train loss <loss>=6.05282101631\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:53 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] Epoch[223] Batch[0] avg_epoch_loss=6.191167\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] #quality_metric: host=algo-1, epoch=223, batch=0 train loss <loss>=6.19116687775\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] Epoch[223] Batch[5] avg_epoch_loss=5.936052\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] #quality_metric: host=algo-1, epoch=223, batch=5 train loss <loss>=5.93605216344\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] Epoch[223] Batch [5]#011Speed: 4315.06 samples/sec#011loss=5.936052\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] Epoch[223] Batch[10] avg_epoch_loss=6.095109\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] #quality_metric: host=algo-1, epoch=223, batch=10 train loss <loss>=6.28597755432\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] Epoch[223] Batch [10]#011Speed: 4893.80 samples/sec#011loss=6.285978\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 330.31392097473145, \"sum\": 330.31392097473145, \"min\": 330.31392097473145}}, \"EndTime\": 1614048414.250545, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048413.919705}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2036.66633862 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] #quality_metric: host=algo-1, epoch=223, train loss <loss>=6.0951091593\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] Epoch[224] Batch[0] avg_epoch_loss=5.654036\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] #quality_metric: host=algo-1, epoch=224, batch=0 train loss <loss>=5.65403556824\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] Epoch[224] Batch[5] avg_epoch_loss=5.890756\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] #quality_metric: host=algo-1, epoch=224, batch=5 train loss <loss>=5.8907558918\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] Epoch[224] Batch [5]#011Speed: 4394.10 samples/sec#011loss=5.890756\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] Epoch[224] Batch[10] avg_epoch_loss=6.136162\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] #quality_metric: host=algo-1, epoch=224, batch=10 train loss <loss>=6.43064985275\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] Epoch[224] Batch [10]#011Speed: 5133.22 samples/sec#011loss=6.430650\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 314.7709369659424, \"sum\": 314.7709369659424, \"min\": 314.7709369659424}}, \"EndTime\": 1614048414.565882, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048414.250631}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2061.04403289 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] #quality_metric: host=algo-1, epoch=224, train loss <loss>=6.13616223769\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] Epoch[225] Batch[0] avg_epoch_loss=6.235948\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] #quality_metric: host=algo-1, epoch=225, batch=0 train loss <loss>=6.23594760895\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] Epoch[225] Batch[5] avg_epoch_loss=5.869896\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] #quality_metric: host=algo-1, epoch=225, batch=5 train loss <loss>=5.86989561717\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] Epoch[225] Batch [5]#011Speed: 5009.00 samples/sec#011loss=5.869896\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] Epoch[225] Batch[10] avg_epoch_loss=5.775258\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] #quality_metric: host=algo-1, epoch=225, batch=10 train loss <loss>=5.66169319153\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] Epoch[225] Batch [10]#011Speed: 4962.63 samples/sec#011loss=5.661693\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 310.66203117370605, \"sum\": 310.66203117370605, \"min\": 310.66203117370605}}, \"EndTime\": 1614048414.87707, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048414.565959}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2120.40892828 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] #quality_metric: host=algo-1, epoch=225, train loss <loss>=5.77525815097\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:54 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] Epoch[226] Batch[0] avg_epoch_loss=6.430067\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] #quality_metric: host=algo-1, epoch=226, batch=0 train loss <loss>=6.43006658554\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] Epoch[226] Batch[5] avg_epoch_loss=6.104845\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] #quality_metric: host=algo-1, epoch=226, batch=5 train loss <loss>=6.10484536489\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] Epoch[226] Batch [5]#011Speed: 4324.32 samples/sec#011loss=6.104845\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 304.75616455078125, \"sum\": 304.75616455078125, \"min\": 304.75616455078125}}, \"EndTime\": 1614048415.18243, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048414.877154}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2043.58897532 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] #quality_metric: host=algo-1, epoch=226, train loss <loss>=5.94372572899\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] Epoch[227] Batch[0] avg_epoch_loss=6.351140\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] #quality_metric: host=algo-1, epoch=227, batch=0 train loss <loss>=6.35113954544\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] Epoch[227] Batch[5] avg_epoch_loss=5.821942\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] #quality_metric: host=algo-1, epoch=227, batch=5 train loss <loss>=5.82194201152\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] Epoch[227] Batch [5]#011Speed: 4154.11 samples/sec#011loss=5.821942\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] processed a total of 603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 306.7591190338135, \"sum\": 306.7591190338135, \"min\": 306.7591190338135}}, \"EndTime\": 1614048415.489789, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048415.182497}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1964.97561771 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] #quality_metric: host=algo-1, epoch=227, train loss <loss>=5.72818911076\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] Epoch[228] Batch[0] avg_epoch_loss=5.819185\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] #quality_metric: host=algo-1, epoch=228, batch=0 train loss <loss>=5.81918478012\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] Epoch[228] Batch[5] avg_epoch_loss=6.048308\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] #quality_metric: host=algo-1, epoch=228, batch=5 train loss <loss>=6.04830813408\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] Epoch[228] Batch [5]#011Speed: 4691.66 samples/sec#011loss=6.048308\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] Epoch[228] Batch[10] avg_epoch_loss=6.083554\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] #quality_metric: host=algo-1, epoch=228, batch=10 train loss <loss>=6.12584981918\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] Epoch[228] Batch [10]#011Speed: 4929.15 samples/sec#011loss=6.125850\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 307.42812156677246, \"sum\": 307.42812156677246, \"min\": 307.42812156677246}}, \"EndTime\": 1614048415.797807, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048415.489857}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2090.77075954 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] #quality_metric: host=algo-1, epoch=228, train loss <loss>=6.08355435458\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] Epoch[229] Batch[0] avg_epoch_loss=6.161792\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:55 INFO 140240734582592] #quality_metric: host=algo-1, epoch=229, batch=0 train loss <loss>=6.16179180145\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] Epoch[229] Batch[5] avg_epoch_loss=6.038523\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] #quality_metric: host=algo-1, epoch=229, batch=5 train loss <loss>=6.03852264086\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] Epoch[229] Batch [5]#011Speed: 4722.27 samples/sec#011loss=6.038523\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 315.05393981933594, \"sum\": 315.05393981933594, \"min\": 315.05393981933594}}, \"EndTime\": 1614048416.113368, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048415.797883}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1995.67252787 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] #quality_metric: host=algo-1, epoch=229, train loss <loss>=5.9984726429\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] Epoch[230] Batch[0] avg_epoch_loss=5.978007\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] #quality_metric: host=algo-1, epoch=230, batch=0 train loss <loss>=5.97800683975\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] Epoch[230] Batch[5] avg_epoch_loss=6.121389\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] #quality_metric: host=algo-1, epoch=230, batch=5 train loss <loss>=6.12138923009\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] Epoch[230] Batch [5]#011Speed: 4536.31 samples/sec#011loss=6.121389\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] Epoch[230] Batch[10] avg_epoch_loss=5.866526\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] #quality_metric: host=algo-1, epoch=230, batch=10 train loss <loss>=5.56069021225\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] Epoch[230] Batch [10]#011Speed: 3749.31 samples/sec#011loss=5.560690\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 345.1199531555176, \"sum\": 345.1199531555176, \"min\": 345.1199531555176}}, \"EndTime\": 1614048416.459054, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048416.113454}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1900.13861839 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] #quality_metric: host=algo-1, epoch=230, train loss <loss>=5.86652604016\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] Epoch[231] Batch[0] avg_epoch_loss=6.149815\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] #quality_metric: host=algo-1, epoch=231, batch=0 train loss <loss>=6.14981460571\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] Epoch[231] Batch[5] avg_epoch_loss=5.795200\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] #quality_metric: host=algo-1, epoch=231, batch=5 train loss <loss>=5.79520042737\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] Epoch[231] Batch [5]#011Speed: 4602.39 samples/sec#011loss=5.795200\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] Epoch[231] Batch[10] avg_epoch_loss=5.959769\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] #quality_metric: host=algo-1, epoch=231, batch=10 train loss <loss>=6.15725183487\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] Epoch[231] Batch [10]#011Speed: 4263.71 samples/sec#011loss=6.157252\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 330.8100700378418, \"sum\": 330.8100700378418, \"min\": 330.8100700378418}}, \"EndTime\": 1614048416.790399, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048416.459134}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1988.22277358 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] #quality_metric: host=algo-1, epoch=231, train loss <loss>=5.95976924896\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] Epoch[232] Batch[0] avg_epoch_loss=6.268291\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:56 INFO 140240734582592] #quality_metric: host=algo-1, epoch=232, batch=0 train loss <loss>=6.26829147339\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] Epoch[232] Batch[5] avg_epoch_loss=5.934737\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] #quality_metric: host=algo-1, epoch=232, batch=5 train loss <loss>=5.93473736445\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] Epoch[232] Batch [5]#011Speed: 4921.94 samples/sec#011loss=5.934737\u001b[0m\n",
      "\n",
      "2021-02-23 02:47:09 Uploading - Uploading generated training model\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] Epoch[232] Batch[10] avg_epoch_loss=5.619026\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] #quality_metric: host=algo-1, epoch=232, batch=10 train loss <loss>=5.24017281532\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] Epoch[232] Batch [10]#011Speed: 5109.61 samples/sec#011loss=5.240173\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 313.6558532714844, \"sum\": 313.6558532714844, \"min\": 313.6558532714844}}, \"EndTime\": 1614048417.104616, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048416.790478}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2090.69665537 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] #quality_metric: host=algo-1, epoch=232, train loss <loss>=5.61902620576\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] Epoch[233] Batch[0] avg_epoch_loss=5.683784\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] #quality_metric: host=algo-1, epoch=233, batch=0 train loss <loss>=5.68378400803\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] Epoch[233] Batch[5] avg_epoch_loss=5.958116\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] #quality_metric: host=algo-1, epoch=233, batch=5 train loss <loss>=5.9581155777\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] Epoch[233] Batch [5]#011Speed: 4511.63 samples/sec#011loss=5.958116\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] processed a total of 615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 338.0858898162842, \"sum\": 338.0858898162842, \"min\": 338.0858898162842}}, \"EndTime\": 1614048417.443234, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048417.104693}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1818.40782152 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] #quality_metric: host=algo-1, epoch=233, train loss <loss>=5.7565615654\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] Epoch[234] Batch[0] avg_epoch_loss=6.042914\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] #quality_metric: host=algo-1, epoch=234, batch=0 train loss <loss>=6.04291439056\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] Epoch[234] Batch[5] avg_epoch_loss=5.932217\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] #quality_metric: host=algo-1, epoch=234, batch=5 train loss <loss>=5.93221704165\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] Epoch[234] Batch [5]#011Speed: 4382.91 samples/sec#011loss=5.932217\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 303.62892150878906, \"sum\": 303.62892150878906, \"min\": 303.62892150878906}}, \"EndTime\": 1614048417.747513, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048417.443313}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2070.68573927 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] #quality_metric: host=algo-1, epoch=234, train loss <loss>=5.97976493835\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] Epoch[235] Batch[0] avg_epoch_loss=6.006907\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] #quality_metric: host=algo-1, epoch=235, batch=0 train loss <loss>=6.0069065094\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] Epoch[235] Batch[5] avg_epoch_loss=6.085773\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] #quality_metric: host=algo-1, epoch=235, batch=5 train loss <loss>=6.08577307065\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:57 INFO 140240734582592] Epoch[235] Batch [5]#011Speed: 4909.71 samples/sec#011loss=6.085773\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] Epoch[235] Batch[10] avg_epoch_loss=5.763423\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] #quality_metric: host=algo-1, epoch=235, batch=10 train loss <loss>=5.37660369873\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] Epoch[235] Batch [10]#011Speed: 4314.18 samples/sec#011loss=5.376604\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 320.6801414489746, \"sum\": 320.6801414489746, \"min\": 320.6801414489746}}, \"EndTime\": 1614048418.068774, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048417.747578}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2020.01426395 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] #progress_metric: host=algo-1, completed 59 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] #quality_metric: host=algo-1, epoch=235, train loss <loss>=5.76342335614\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] Epoch[236] Batch[0] avg_epoch_loss=6.599876\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] #quality_metric: host=algo-1, epoch=236, batch=0 train loss <loss>=6.59987592697\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] Epoch[236] Batch[5] avg_epoch_loss=6.233915\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] #quality_metric: host=algo-1, epoch=236, batch=5 train loss <loss>=6.23391477267\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] Epoch[236] Batch [5]#011Speed: 4037.64 samples/sec#011loss=6.233915\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] Epoch[236] Batch[10] avg_epoch_loss=6.152978\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] #quality_metric: host=algo-1, epoch=236, batch=10 train loss <loss>=6.05585460663\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] Epoch[236] Batch [10]#011Speed: 4290.23 samples/sec#011loss=6.055855\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 352.1151542663574, \"sum\": 352.1151542663574, \"min\": 352.1151542663574}}, \"EndTime\": 1614048418.42145, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048418.068848}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1851.05282367 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] #progress_metric: host=algo-1, completed 59 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] #quality_metric: host=algo-1, epoch=236, train loss <loss>=6.15297833356\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] Epoch[237] Batch[0] avg_epoch_loss=6.198624\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] #quality_metric: host=algo-1, epoch=237, batch=0 train loss <loss>=6.19862365723\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] Epoch[237] Batch[5] avg_epoch_loss=6.081430\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] #quality_metric: host=algo-1, epoch=237, batch=5 train loss <loss>=6.08142964045\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] Epoch[237] Batch [5]#011Speed: 5020.07 samples/sec#011loss=6.081430\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 320.4998970031738, \"sum\": 320.4998970031738, \"min\": 320.4998970031738}}, \"EndTime\": 1614048418.742496, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048418.421528}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1936.82297897 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] #progress_metric: host=algo-1, completed 59 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] #quality_metric: host=algo-1, epoch=237, train loss <loss>=6.14778466225\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] Epoch[238] Batch[0] avg_epoch_loss=5.890813\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:58 INFO 140240734582592] #quality_metric: host=algo-1, epoch=238, batch=0 train loss <loss>=5.89081335068\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] Epoch[238] Batch[5] avg_epoch_loss=5.929317\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] #quality_metric: host=algo-1, epoch=238, batch=5 train loss <loss>=5.92931699753\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] Epoch[238] Batch [5]#011Speed: 4646.51 samples/sec#011loss=5.929317\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] Epoch[238] Batch[10] avg_epoch_loss=5.971263\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] #quality_metric: host=algo-1, epoch=238, batch=10 train loss <loss>=6.02159891129\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] Epoch[238] Batch [10]#011Speed: 4385.18 samples/sec#011loss=6.021599\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] processed a total of 694 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 340.1639461517334, \"sum\": 340.1639461517334, \"min\": 340.1639461517334}}, \"EndTime\": 1614048419.083268, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048418.742584}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2039.46654111 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] #progress_metric: host=algo-1, completed 59 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] #quality_metric: host=algo-1, epoch=238, train loss <loss>=5.97126332196\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] Epoch[239] Batch[0] avg_epoch_loss=6.271602\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] #quality_metric: host=algo-1, epoch=239, batch=0 train loss <loss>=6.27160215378\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] Epoch[239] Batch[5] avg_epoch_loss=5.884572\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] #quality_metric: host=algo-1, epoch=239, batch=5 train loss <loss>=5.88457226753\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] Epoch[239] Batch [5]#011Speed: 4842.98 samples/sec#011loss=5.884572\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 308.1979751586914, \"sum\": 308.1979751586914, \"min\": 308.1979751586914}}, \"EndTime\": 1614048419.392024, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048419.08335}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2043.29812119 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] #quality_metric: host=algo-1, epoch=239, train loss <loss>=5.93401122093\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] Epoch[240] Batch[0] avg_epoch_loss=5.623351\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] #quality_metric: host=algo-1, epoch=240, batch=0 train loss <loss>=5.62335062027\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] Epoch[240] Batch[5] avg_epoch_loss=5.735643\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] #quality_metric: host=algo-1, epoch=240, batch=5 train loss <loss>=5.7356432279\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] Epoch[240] Batch [5]#011Speed: 4745.88 samples/sec#011loss=5.735643\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 313.51494789123535, \"sum\": 313.51494789123535, \"min\": 313.51494789123535}}, \"EndTime\": 1614048419.706158, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048419.392108}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2034.34092673 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] #quality_metric: host=algo-1, epoch=240, train loss <loss>=5.91098051071\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] Epoch[241] Batch[0] avg_epoch_loss=6.057379\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] #quality_metric: host=algo-1, epoch=241, batch=0 train loss <loss>=6.05737924576\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] Epoch[241] Batch[5] avg_epoch_loss=6.022136\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] #quality_metric: host=algo-1, epoch=241, batch=5 train loss <loss>=6.02213597298\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:46:59 INFO 140240734582592] Epoch[241] Batch [5]#011Speed: 4171.17 samples/sec#011loss=6.022136\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] Epoch[241] Batch[10] avg_epoch_loss=5.923451\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] #quality_metric: host=algo-1, epoch=241, batch=10 train loss <loss>=5.8050280571\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] Epoch[241] Batch [10]#011Speed: 4314.00 samples/sec#011loss=5.805028\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 338.0768299102783, \"sum\": 338.0768299102783, \"min\": 338.0768299102783}}, \"EndTime\": 1614048420.044702, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048419.706223}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1927.82563407 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] #quality_metric: host=algo-1, epoch=241, train loss <loss>=5.92345055667\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] Epoch[242] Batch[0] avg_epoch_loss=5.540838\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] #quality_metric: host=algo-1, epoch=242, batch=0 train loss <loss>=5.54083776474\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] Epoch[242] Batch[5] avg_epoch_loss=6.036571\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] #quality_metric: host=algo-1, epoch=242, batch=5 train loss <loss>=6.03657054901\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] Epoch[242] Batch [5]#011Speed: 5056.65 samples/sec#011loss=6.036571\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 297.02091217041016, \"sum\": 297.02091217041016, \"min\": 297.02091217041016}}, \"EndTime\": 1614048420.342318, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048420.044791}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2137.03376156 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] #quality_metric: host=algo-1, epoch=242, train loss <loss>=5.9924059391\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] Epoch[243] Batch[0] avg_epoch_loss=5.771885\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] #quality_metric: host=algo-1, epoch=243, batch=0 train loss <loss>=5.77188491821\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] Epoch[243] Batch[5] avg_epoch_loss=5.911073\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] #quality_metric: host=algo-1, epoch=243, batch=5 train loss <loss>=5.9110733668\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] Epoch[243] Batch [5]#011Speed: 4662.35 samples/sec#011loss=5.911073\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] Epoch[243] Batch[10] avg_epoch_loss=6.005916\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] #quality_metric: host=algo-1, epoch=243, batch=10 train loss <loss>=6.11972608566\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] Epoch[243] Batch [10]#011Speed: 4076.90 samples/sec#011loss=6.119726\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 341.5811061859131, \"sum\": 341.5811061859131, \"min\": 341.5811061859131}}, \"EndTime\": 1614048420.684489, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048420.342402}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1913.88707049 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] #quality_metric: host=algo-1, epoch=243, train loss <loss>=6.00591551174\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] Epoch[244] Batch[0] avg_epoch_loss=5.851887\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] #quality_metric: host=algo-1, epoch=244, batch=0 train loss <loss>=5.85188674927\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] Epoch[244] Batch[5] avg_epoch_loss=5.859124\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] #quality_metric: host=algo-1, epoch=244, batch=5 train loss <loss>=5.85912394524\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:00 INFO 140240734582592] Epoch[244] Batch [5]#011Speed: 4238.64 samples/sec#011loss=5.859124\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 326.8320560455322, \"sum\": 326.8320560455322, \"min\": 326.8320560455322}}, \"EndTime\": 1614048421.011841, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048420.68457}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1954.30855958 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] #quality_metric: host=algo-1, epoch=244, train loss <loss>=5.92680182457\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] Epoch[245] Batch[0] avg_epoch_loss=6.176015\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] #quality_metric: host=algo-1, epoch=245, batch=0 train loss <loss>=6.17601537704\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] Epoch[245] Batch[5] avg_epoch_loss=6.008715\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] #quality_metric: host=algo-1, epoch=245, batch=5 train loss <loss>=6.00871531169\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] Epoch[245] Batch [5]#011Speed: 4206.04 samples/sec#011loss=6.008715\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] Epoch[245] Batch[10] avg_epoch_loss=5.812348\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] #quality_metric: host=algo-1, epoch=245, batch=10 train loss <loss>=5.5767077446\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] Epoch[245] Batch [10]#011Speed: 5070.83 samples/sec#011loss=5.576708\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 325.6399631500244, \"sum\": 325.6399631500244, \"min\": 325.6399631500244}}, \"EndTime\": 1614048421.338172, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048421.01194}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2090.5472827 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] #quality_metric: host=algo-1, epoch=245, train loss <loss>=5.81234823574\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] Epoch[246] Batch[0] avg_epoch_loss=6.023772\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] #quality_metric: host=algo-1, epoch=246, batch=0 train loss <loss>=6.02377176285\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] Epoch[246] Batch[5] avg_epoch_loss=5.867280\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] #quality_metric: host=algo-1, epoch=246, batch=5 train loss <loss>=5.86728040377\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] Epoch[246] Batch [5]#011Speed: 4084.49 samples/sec#011loss=5.867280\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 360.90803146362305, \"sum\": 360.90803146362305, \"min\": 360.90803146362305}}, \"EndTime\": 1614048421.699603, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048421.338248}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1736.87163616 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] #quality_metric: host=algo-1, epoch=246, train loss <loss>=5.99638600349\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] Epoch[247] Batch[0] avg_epoch_loss=6.207244\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] #quality_metric: host=algo-1, epoch=247, batch=0 train loss <loss>=6.20724391937\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] Epoch[247] Batch[5] avg_epoch_loss=5.758891\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] #quality_metric: host=algo-1, epoch=247, batch=5 train loss <loss>=5.75889102618\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:01 INFO 140240734582592] Epoch[247] Batch [5]#011Speed: 4898.21 samples/sec#011loss=5.758891\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] Epoch[247] Batch[10] avg_epoch_loss=6.202140\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] #quality_metric: host=algo-1, epoch=247, batch=10 train loss <loss>=6.73403816223\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] Epoch[247] Batch [10]#011Speed: 3952.47 samples/sec#011loss=6.734038\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 376.5721321105957, \"sum\": 376.5721321105957, \"min\": 376.5721321105957}}, \"EndTime\": 1614048422.076668, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048421.699657}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1707.04237576 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] #quality_metric: host=algo-1, epoch=247, train loss <loss>=6.20213972438\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] Epoch[248] Batch[0] avg_epoch_loss=5.986493\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] #quality_metric: host=algo-1, epoch=248, batch=0 train loss <loss>=5.98649311066\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] Epoch[248] Batch[5] avg_epoch_loss=5.886970\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] #quality_metric: host=algo-1, epoch=248, batch=5 train loss <loss>=5.88697036107\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] Epoch[248] Batch [5]#011Speed: 4278.77 samples/sec#011loss=5.886970\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] Epoch[248] Batch[10] avg_epoch_loss=5.961000\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] #quality_metric: host=algo-1, epoch=248, batch=10 train loss <loss>=6.04983577728\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] Epoch[248] Batch [10]#011Speed: 4034.28 samples/sec#011loss=6.049836\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 363.7208938598633, \"sum\": 363.7208938598633, \"min\": 363.7208938598633}}, \"EndTime\": 1614048422.440863, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048422.076731}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1789.10096771 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] #quality_metric: host=algo-1, epoch=248, train loss <loss>=5.96100009571\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] Epoch[249] Batch[0] avg_epoch_loss=6.261524\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] #quality_metric: host=algo-1, epoch=249, batch=0 train loss <loss>=6.2615237236\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] Epoch[249] Batch[5] avg_epoch_loss=5.893127\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] #quality_metric: host=algo-1, epoch=249, batch=5 train loss <loss>=5.89312696457\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] Epoch[249] Batch [5]#011Speed: 4181.81 samples/sec#011loss=5.893127\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 372.80797958374023, \"sum\": 372.80797958374023, \"min\": 372.80797958374023}}, \"EndTime\": 1614048422.81426, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048422.440972}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1630.32838294 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] #quality_metric: host=algo-1, epoch=249, train loss <loss>=5.82451024055\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:02 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] Epoch[250] Batch[0] avg_epoch_loss=5.739464\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] #quality_metric: host=algo-1, epoch=250, batch=0 train loss <loss>=5.73946380615\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] Epoch[250] Batch[5] avg_epoch_loss=5.696284\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] #quality_metric: host=algo-1, epoch=250, batch=5 train loss <loss>=5.69628381729\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] Epoch[250] Batch [5]#011Speed: 4771.07 samples/sec#011loss=5.696284\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] Epoch[250] Batch[10] avg_epoch_loss=5.717044\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] #quality_metric: host=algo-1, epoch=250, batch=10 train loss <loss>=5.7419552803\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] Epoch[250] Batch [10]#011Speed: 5240.32 samples/sec#011loss=5.741955\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] processed a total of 712 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 332.75699615478516, \"sum\": 332.75699615478516, \"min\": 332.75699615478516}}, \"EndTime\": 1614048423.147598, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048422.814344}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2138.92870224 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] #quality_metric: host=algo-1, epoch=250, train loss <loss>=5.94864594936\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] Epoch[251] Batch[0] avg_epoch_loss=5.599805\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] #quality_metric: host=algo-1, epoch=251, batch=0 train loss <loss>=5.59980535507\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] Epoch[251] Batch[5] avg_epoch_loss=5.920016\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] #quality_metric: host=algo-1, epoch=251, batch=5 train loss <loss>=5.92001636823\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] Epoch[251] Batch [5]#011Speed: 3876.35 samples/sec#011loss=5.920016\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] Epoch[251] Batch[10] avg_epoch_loss=5.554932\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] #quality_metric: host=algo-1, epoch=251, batch=10 train loss <loss>=5.11683120728\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] Epoch[251] Batch [10]#011Speed: 3444.67 samples/sec#011loss=5.116831\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 411.68713569641113, \"sum\": 411.68713569641113, \"min\": 411.68713569641113}}, \"EndTime\": 1614048423.559874, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048423.147685}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1558.97527865 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] #quality_metric: host=algo-1, epoch=251, train loss <loss>=5.55493220416\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] Epoch[252] Batch[0] avg_epoch_loss=5.736560\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] #quality_metric: host=algo-1, epoch=252, batch=0 train loss <loss>=5.73655986786\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] Epoch[252] Batch[5] avg_epoch_loss=6.168667\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] #quality_metric: host=algo-1, epoch=252, batch=5 train loss <loss>=6.16866723696\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] Epoch[252] Batch [5]#011Speed: 3571.03 samples/sec#011loss=6.168667\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] Epoch[252] Batch[10] avg_epoch_loss=5.979941\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] #quality_metric: host=algo-1, epoch=252, batch=10 train loss <loss>=5.7534696579\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] Epoch[252] Batch [10]#011Speed: 3260.95 samples/sec#011loss=5.753470\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] processed a total of 704 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 418.76912117004395, \"sum\": 418.76912117004395, \"min\": 418.76912117004395}}, \"EndTime\": 1614048423.979199, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048423.559955}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1680.50780555 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] #quality_metric: host=algo-1, epoch=252, train loss <loss>=5.97994106466\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:03 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:04 INFO 140240734582592] Epoch[253] Batch[0] avg_epoch_loss=5.614931\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:04 INFO 140240734582592] #quality_metric: host=algo-1, epoch=253, batch=0 train loss <loss>=5.61493062973\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:04 INFO 140240734582592] Epoch[253] Batch[5] avg_epoch_loss=5.978375\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:04 INFO 140240734582592] #quality_metric: host=algo-1, epoch=253, batch=5 train loss <loss>=5.97837527593\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:04 INFO 140240734582592] Epoch[253] Batch [5]#011Speed: 3832.79 samples/sec#011loss=5.978375\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:04 INFO 140240734582592] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 375.607967376709, \"sum\": 375.607967376709, \"min\": 375.607967376709}}, \"EndTime\": 1614048424.355443, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048423.979308}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:04 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1687.35495964 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:04 INFO 140240734582592] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:04 INFO 140240734582592] #quality_metric: host=algo-1, epoch=253, train loss <loss>=5.90888671875\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:04 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:04 INFO 140240734582592] Epoch[254] Batch[0] avg_epoch_loss=5.891591\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:04 INFO 140240734582592] #quality_metric: host=algo-1, epoch=254, batch=0 train loss <loss>=5.89159107208\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:04 INFO 140240734582592] Epoch[254] Batch[5] avg_epoch_loss=6.046900\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:04 INFO 140240734582592] #quality_metric: host=algo-1, epoch=254, batch=5 train loss <loss>=6.04690035184\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:04 INFO 140240734582592] Epoch[254] Batch [5]#011Speed: 3839.55 samples/sec#011loss=6.046900\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:04 INFO 140240734582592] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 385.18500328063965, \"sum\": 385.18500328063965, \"min\": 385.18500328063965}}, \"EndTime\": 1614048424.74122, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048424.35553}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:04 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1647.91688219 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:04 INFO 140240734582592] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:04 INFO 140240734582592] #quality_metric: host=algo-1, epoch=254, train loss <loss>=6.010922575\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:04 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:04 INFO 140240734582592] Epoch[255] Batch[0] avg_epoch_loss=6.190603\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:04 INFO 140240734582592] #quality_metric: host=algo-1, epoch=255, batch=0 train loss <loss>=6.19060277939\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] Epoch[255] Batch[5] avg_epoch_loss=5.861874\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] #quality_metric: host=algo-1, epoch=255, batch=5 train loss <loss>=5.86187402407\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] Epoch[255] Batch [5]#011Speed: 4751.31 samples/sec#011loss=5.861874\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 345.7639217376709, \"sum\": 345.7639217376709, \"min\": 345.7639217376709}}, \"EndTime\": 1614048425.087697, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048424.741323}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=1835.84479107 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] #quality_metric: host=algo-1, epoch=255, train loss <loss>=5.99950261116\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] Epoch[256] Batch[0] avg_epoch_loss=5.733394\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] #quality_metric: host=algo-1, epoch=256, batch=0 train loss <loss>=5.73339366913\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] Epoch[256] Batch[5] avg_epoch_loss=5.833132\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] #quality_metric: host=algo-1, epoch=256, batch=5 train loss <loss>=5.83313186963\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] Epoch[256] Batch [5]#011Speed: 4691.25 samples/sec#011loss=5.833132\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] Epoch[256] Batch[10] avg_epoch_loss=5.807720\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] #quality_metric: host=algo-1, epoch=256, batch=10 train loss <loss>=5.77722597122\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] Epoch[256] Batch [10]#011Speed: 4093.54 samples/sec#011loss=5.777226\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 328.18007469177246, \"sum\": 328.18007469177246, \"min\": 328.18007469177246}}, \"EndTime\": 1614048425.416471, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048425.087785}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2007.40223411 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] #quality_metric: host=algo-1, epoch=256, train loss <loss>=5.80772009763\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] Epoch[257] Batch[0] avg_epoch_loss=5.684449\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] #quality_metric: host=algo-1, epoch=257, batch=0 train loss <loss>=5.68444871902\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] Epoch[257] Batch[5] avg_epoch_loss=5.816074\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] #quality_metric: host=algo-1, epoch=257, batch=5 train loss <loss>=5.81607437134\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] Epoch[257] Batch [5]#011Speed: 5190.43 samples/sec#011loss=5.816074\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] Epoch[257] Batch[10] avg_epoch_loss=5.745644\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] #quality_metric: host=algo-1, epoch=257, batch=10 train loss <loss>=5.66112670898\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] Epoch[257] Batch [10]#011Speed: 4324.96 samples/sec#011loss=5.661127\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 320.5080032348633, \"sum\": 320.5080032348633, \"min\": 320.5080032348633}}, \"EndTime\": 1614048425.737565, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048425.416537}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] #throughput_metric: host=algo-1, train throughput=2036.76185504 records/second\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] #quality_metric: host=algo-1, epoch=257, train loss <loss>=5.74564361572\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] Loading parameters from best epoch (217)\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.deserialize.time\": {\"count\": 1, \"max\": 3.7620067596435547, \"sum\": 3.7620067596435547, \"min\": 3.7620067596435547}}, \"EndTime\": 1614048425.742, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048425.737625}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] stopping training now\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] Final loss: 5.39771845937 (occurred at epoch 217)\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] #quality_metric: host=algo-1, train final_loss <loss>=5.39771845937\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 WARNING 140240734582592] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 32.75108337402344, \"sum\": 32.75108337402344, \"min\": 32.75108337402344}}, \"EndTime\": 1614048425.775606, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048425.742057}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 48.522233963012695, \"sum\": 48.522233963012695, \"min\": 48.522233963012695}}, \"EndTime\": 1614048425.791329, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048425.775672}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 2.7790069580078125, \"sum\": 2.7790069580078125, \"min\": 2.7790069580078125}}, \"EndTime\": 1614048425.794222, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048425.791401}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:05 INFO 140240734582592] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.bind.time\": {\"count\": 1, \"max\": 0.025987625122070312, \"sum\": 0.025987625122070312, \"min\": 0.025987625122070312}}, \"EndTime\": 1614048425.79487, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048425.794267}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.score.time\": {\"count\": 1, \"max\": 255.89609146118164, \"sum\": 255.89609146118164, \"min\": 255.89609146118164}}, \"EndTime\": 1614048426.050739, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048425.794926}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:06 INFO 140240734582592] #test_score (algo-1, RMSE): 3426.97305213\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:06 INFO 140240734582592] #test_score (algo-1, mean_absolute_QuantileLoss): 50205.89097222222\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:06 INFO 140240734582592] #test_score (algo-1, mean_wQuantileLoss): 0.02394580630174053\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:06 INFO 140240734582592] #test_score (algo-1, wQuantileLoss[0.1]): 0.016136701811678793\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:06 INFO 140240734582592] #test_score (algo-1, wQuantileLoss[0.2]): 0.017650647712907253\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:06 INFO 140240734582592] #test_score (algo-1, wQuantileLoss[0.3]): 0.018444167119969913\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:06 INFO 140240734582592] #test_score (algo-1, wQuantileLoss[0.4]): 0.021744511115726946\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:06 INFO 140240734582592] #test_score (algo-1, wQuantileLoss[0.5]): 0.02754160781276195\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:06 INFO 140240734582592] #test_score (algo-1, wQuantileLoss[0.6]): 0.030364773878190726\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:06 INFO 140240734582592] #test_score (algo-1, wQuantileLoss[0.7]): 0.031038879378331073\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:06 INFO 140240734582592] #test_score (algo-1, wQuantileLoss[0.8]): 0.029874005048061265\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:06 INFO 140240734582592] #test_score (algo-1, wQuantileLoss[0.9]): 0.02271696283803683\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:06 INFO 140240734582592] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.0239458063017\u001b[0m\n",
      "\u001b[34m[02/23/2021 02:47:06 INFO 140240734582592] #quality_metric: host=algo-1, test RMSE <loss>=3426.97305213\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 86329.18310165405, \"sum\": 86329.18310165405, \"min\": 86329.18310165405}, \"setuptime\": {\"count\": 1, \"max\": 9.124994277954102, \"sum\": 9.124994277954102, \"min\": 9.124994277954102}}, \"EndTime\": 1614048426.057423, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614048426.050806}\n",
      "\u001b[0m\n",
      "\n",
      "2021-02-23 02:47:24 Completed - Training job completed\n",
      "Training seconds: 141\n",
      "Billable seconds: 141\n",
      "CPU times: user 1.1 s, sys: 47.5 ms, total: 1.15 s\n",
      "Wall time: 5min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_channels = {\n",
    "    \"train\": train_path,\n",
    "    \"test\": test_path\n",
    "}\n",
    "\n",
    "estimator.fit(inputs=data_channels, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "tough-consideration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/deepar_electricity/DeepAR-Electricity.ipynb\n",
    "class DeepARPredictor(sagemaker.predictor.Predictor):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(\n",
    "            *args,              \n",
    "            serializer=IdentitySerializer(content_type='application/json'),\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "    def predict(self, ts, cat=None, dynamic_feat=None, num_samples=100, return_samples=False, quantiles=['0.1', '0.5', '0.9']):\n",
    "        '''Requests the prediction of for the time series listed in `ts`, each with the (optional)\n",
    "        corresponding category listed in `cat`.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        ts (pandas.Series object) : The time series to predict\n",
    "        cat (int) : The group associated to the time series (default: None)\n",
    "        num_samples (int) : number of samples to compute at prediction time (default: 100)\n",
    "        return_samples : boolean indicating whether to include samples in the response (default: False)\n",
    "        quantiles : list of strings specifying the quantiles to compute (default: [\"0.1\", \"0.5\", \"0.9\"])\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        List of `pandas.DataFrame` objects, each containing the predictions.\n",
    "        '''\n",
    "        \n",
    "        prediction_time = ts.index[-1] + ts.index.freq\n",
    "        quantiles = [str(q) for q in quantiles]\n",
    "        req = self.__encode_request(ts, cat, dynamic_feat, num_samples, return_samples, quantiles)\n",
    "        res = super(DeepARPredictor, self).predict(req)\n",
    "        return self.__decode_response(res, ts.index.freq, prediction_time, return_samples)\n",
    "    \n",
    "    def __encode_request(self, ts, cat, dynamic_feat, num_samples, return_samples, quantiles):\n",
    "        instance = series_to_dict(ts, cat if cat is not None else None, dynamic_feat if dynamic_feat else None)\n",
    "        \n",
    "        configuration = {\n",
    "            \"num_samples\": num_samples,\n",
    "            \"output_types\": [\"quantiles\", \"samples\"] if return_samples else [\"quantiles\"],\n",
    "            \"quantiles\": quantiles\n",
    "        }\n",
    "        \n",
    "        http_request_data = {\n",
    "            \"instances\": [instance],\n",
    "            \"configuration\": configuration\n",
    "        }\n",
    "        \n",
    "        return json.dumps(http_request_data).encode('utf-8')\n",
    "    \n",
    "    def __decode_response(self, response, freq, prediction_time, return_samples):\n",
    "        # we only sent one time series so we only receive one in return\n",
    "        # however, if possible one will pass multiple time series as predictions will then be faster\n",
    "        predictions = json.loads(response.decode('utf-8'))['predictions'][0]\n",
    "        prediction_length = len(next(iter(predictions['quantiles'].values())))\n",
    "        prediction_index = pd.date_range(start=prediction_time, freq=freq, periods=prediction_length)\n",
    "        if return_samples:\n",
    "            dict_of_samples = {'sample_' + str(i): s for i, s in enumerate(predictions['samples'])}\n",
    "        else:\n",
    "            dict_of_samples = {}\n",
    "        return pd.DataFrame(data={**predictions['quantiles'], **dict_of_samples}, index=prediction_index)\n",
    "\n",
    "    def set_frequency(self, freq):\n",
    "        self.freq = freq\n",
    "        \n",
    "def encode_target(ts):\n",
    "    return [x if np.isfinite(x) else \"NaN\" for x in ts]        \n",
    "\n",
    "def series_to_dict(ts, cat=None, dynamic_feat=None):\n",
    "    '''Given a pandas.Series object, returns a dictionary encoding the time series.\n",
    "\n",
    "    Paramenters\n",
    "    -----------\n",
    "    ts : a pands.Series object with the target time series\n",
    "    cat : an integer indicating the time series category\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A dictionary\n",
    "    '''\n",
    "    \n",
    "    obj = {\"start\": str(ts.index[0]), \"target\": encode_target(ts)}\n",
    "    if cat is not None:\n",
    "        obj[\"cat\"] = cat\n",
    "    if dynamic_feat is not None:\n",
    "        obj[\"dynamic_feat\"] = dynamic_feat        \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-luxembourg",
   "metadata": {},
   "source": [
    "# Evaluating the model\n",
    "\n",
    "The method that can be used for cross-validating the time-series model is cross-validation on a rolling basis, or *Time Series Split Cross-Validation*. Start with a small subset of data for training purpose, forecast for the later data points and then checking the accuracy for the forecasted data points. The same forecasted data points are then included as part of the next training dataset and subsequent data points are forecasted. What we need to do is to create 4 pairs of training/test sets that follow those two rules:\n",
    "\n",
    "* every test set contains unique observations\n",
    "* observations from the training set occur before their corresponding test set \n",
    "\n",
    "Source: https://medium.com/@soumyachess1496/cross-validation-in-time-series-566ae4981ce4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-greek",
   "metadata": {},
   "source": [
    "<img src='img/time-series-cross-validation.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-debate",
   "metadata": {},
   "source": [
    "The evaluation metric choosed for this project is the mean absolute percentage error (MAPE), is a measure of prediction accuracy of a forecasting method in statistics, for example in trend estimation, also used as a loss function for regression problems in machine learning. It usually expresses the accuracy as a ratio defined by the formula:\n",
    "\n",
    "# $$MAPE = \\frac{1}{n} \\sum_{t=1}^n \\frac{| \\widehat{y}_t - y_{t} |}{y_{t}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "postal-spelling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!CPU times: user 241 ms, sys: 17.7 ms, total: 259 ms\n",
      "Wall time: 6min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    predictor_cls=DeepARPredictor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "hybrid-emerald",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAD4CAYAAADPccAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3hUZfbA8e9JD4SEJEAICSH03kLoShFpivQiIoK6Ylnb/lZRd3Vtu65tdXXXxiqKgiAgKqJUKTYQ6R1CJwQIIZQEUifv7497wYChJZNMZuZ8nidPJu9tZy5hTt77NjHGoJRSSjmLj6sDUEop5Vk0sSillHIqTSxKKaWcShOLUkopp9LEopRSyqn8XB2As1WpUsXEx8e7OgyllHIrq1evTjPGVHXGuTwuscTHx7Nq1SpXh6GUUm5FRPY561z6KEwppZRTaWJRSinlVJdNLCIyUURSRWRTobIIEVkoIkn29/ALjmkrIg4RGVqobIy9f5KIjClU3kZENorIThF5U0TkSq6hlFKqfLqSNpaPgP8CHxcqexz4zhjzoog8bv/8GICI+AIvAfPP7iwiEcDTQCJggNUiMtsYcxx4BxgHrAC+BfoAcy91jauVl5dHcnIy2dnZxTlcFSEoKIjY2Fj8/f1dHYpSqpy5bGIxxnwvIvEXFA8AutmvJwFL+e1D/wHgc6Btof17AwuNMekAIrIQ6CMiS4FQY8xyu/xjYCBWYrnUNa5KcnIylSpVIj4+HrtCpErAGMOxY8dITk6mdu3arg5HKVXOFLeNJcoYcwjA/l4NQERigEHAuxfsHwMcKPRzsl0WY7++sPyi1yiKiIwTkVUisuro0aO/256dnU1kZKQmFScRESIjI7UGqJQqkrMb7/8NPGaMcVxQXtQnurlE+VUxxkwwxiQaYxKrVi26G7YmFefS+6mUupjijmM5IiLRxphDIhINpNrlicA0+0OnCnCDiORj1US6FTo+FuvRVrL9unB5ymWuoZRSylkKCmDZi049ZXFrLLOBsz27xgBfARhjahtj4o0x8cBM4D5jzJdYDfm9RCTc7t3VC5hvP+LKEJEOdm+w286e62LXcFe+vr60atWKZs2aMWzYMM6cOVPscy1dupR+/foBMHv2bF588eK/FCdOnODtt98+93NKSgpDhw696P5KKS+Slw0zb4dlLzn1tFfS3XgqsBxoKCLJInIn8CLQU0SSgJ72zxdlN9o/D/xqfz13tiEfuBd4H9gJ7MJquOdqr1HeBQcHs27dOjZt2kRAQADvvnt+M5QxhoKCgqs+b//+/Xn88ccvuv3CxFKjRg1mzpx51ddRSnmY08fg4/6w5Uvo+bxTT33ZxGKMGWmMiTbG+BtjYo0xHxhjjhljehhj6tvf04s4bqwxZmahnycaY+rZXx8WKl9ljGlmjKlrjLnf2EtaXsk13NW1117Lzp072bt3L40bN+a+++4jISGBAwcOsGDBAjp27EhCQgLDhg0jMzMTgHnz5tGoUSOuueYaZs2ade5cH330Effffz8AR44cYdCgQbRs2ZKWLVvy888/8/jjj7Nr1y5atWrFo48+yt69e2nWrBlgdWq4/fbbad68Oa1bt2bJkiXnzjl48GD69OlD/fr1GT9+fBnfIaVUqTq2Cz64HlLWwbCPoPODTj29x80VdiVGvLf8d2X9WkQzumM8WbkOxn648nfbh7aJZVhiTdJP53Lv5NXnbfvs7o5XfO38/Hzmzp1Lnz59ANi+fTsffvghb7/9Nmlpafz9739n0aJFVKxYkZdeeonXXnuN8ePHc9ddd7F48WLq1avHiBEjijz3gw8+SNeuXfniiy9wOBxkZmby4osvsmnTJtatWwfA3r17z+3/1ltvAbBx40a2bdtGr1692LFjBwDr1q1j7dq1BAYG0rBhQx544AFq1qx5xe9TKVVO7f8Fpt4MIjDma4hr7/RL6JQuZSQrK4tWrVqRmJhIXFwcd955JwC1atWiQ4cOAKxYsYItW7bQuXNnWrVqxaRJk9i3bx/btm2jdu3a1K9fHxHh1ltvLfIaixcv5t577wWsNp2wsLBLxvTjjz8yevRoABo1akStWrXOJZYePXoQFhZGUFAQTZo0Yd8+p81Pp5Rylc1fwKSbIDgc7lxYKkkFvLTGcqkaRnCA7yW3R1QMuKoayrnz2m0sF6pYseK518YYevbsydSpU8/bZ926daXSvdd+6likwMDAc699fX3Jz893+vWVUmXEGPj5TVj4N6jZAUZOhQoRpXY5rbGUIx06dOCnn35i586dAJw5c4YdO3bQqFEj9uzZw65duwB+l3jO6tGjB++88w4ADoeDU6dOUalSJTIyMorcv0uXLkyZMgWAHTt2sH//fho2bOjst6WUciVHPnzzf1ZSaToIbvuqVJMKaGIpV6pWrcpHH33EyJEjadGiBR06dGDbtm0EBQUxYcIEbrzxRq655hpq1apV5PFvvPEGS5YsoXnz5rRp04bNmzcTGRlJ586dadasGY8++uh5+9933304HA6aN2/OiBEj+Oijj86rqSil3FxOJkwbCasmQueHYchE8A8q9cvKpR6HuKPExERz4UJfW7dupXHjxi6KyHPpfVWqHDt1CD4dDkc2w42vQuIdl9xdRFYbYxKdcWmvbGNRSimPdmQzTBkO2Sfgls+gfs8yvbwmFqWU8iS7lsD02yCgItw+F6JblHkI2sailFKeYu1kmDIUwmrCHxa5JKmA1liUUsr9GQNLXoDvX4Y63WH4xxAU6rJwNLEopZQ7y8+B2Q/Ahs+g9Wjo9zr4unZlV00sSinlrrKOw2ejYe8PcN2TcO0j1lQtLqZtLGWk8LT5N910EydOnCj2ueLj40lLS3NidEopt3N8H3zQGw78AoP/B10eLRdJBTSxlJnC0+ZHREScmwBSKaWu2sHV8H4PyDwCo7+AFsNdHdF5NLG4QMeOHTl48OC5n1955RXatm1LixYtePrpp8+VDxw4kDZt2tC0aVMmTJjgilCVUuXNtm/gwxvBv4I1kWT8Na6O6He8r41l7uNweKNzz1m9OfS9snXIHA4H33333bnZjRcsWEBSUhIrV67EGEP//v35/vvv6dKlCxMnTiQiIoKsrCzatm3LkCFDiIyMdG7sSin3seJdmPc4xCTAyGkQUs3VERVJayxl5Oy0+ZGRkaSnp9OzpzUSdsGCBSxYsIDWrVuTkJDAtm3bSEpKAuDNN9+kZcuWdOjQgQMHDpwrV0p5mQIHzHsC5j0GjW6EMXPKbVIBb6yxXGHNwtnOtrGcPHmSfv368dZbb/Hggw9ijOGJJ57g7rvvPm//pUuXsmjRIpYvX06FChXo1q0b2dnZLoldKeVCuWdg1l2wbQ50uA96/R18fF0d1SVpjaWMhYWF8eabb/Lqq6+Sl5dH7969mThx4rkliA8ePEhqaionT54kPDycChUqsG3bNlasWOHiyJVSZS4zFSb1s9pV+rwEff5Z7pMKeGONpRxo3bo1LVu2ZNq0aYwePZqtW7fSsaO1eFhISAiTJ0+mT58+vPvuu7Ro0YKGDRueW2VSKeUlju6wpmfJTIWbp1iPwNyETpuvik3vq1KlZO+PMO0W8A2wZieOaVOql9txJIOG1UOdNm2+PgpTSqnyZMMM+GQQhFS3JpIspaSy7fAptqScAiAq1LmLf2liUUqp8sAY+P4VmPUHqNke7pwP4fFOv0xmTj7/+GYLN775Iy98uxWAsGDnzi3mNW0sxhiknEx34Ak87RGqUi7lyIM5D1vT3rcYAf3/A37OXSbcGMPcTYd57ustHD6Vzch2NRnfu5FTr3GWVySWoKAgjh07RmRkpCYXJzDGcOzYMYKCSn/tbKU8XvYpa2Gu3Uugy3jo/pdSmfPr6w2HeHDqWppEh/L2rQkkxIU7/RpneUViiY2NJTk5maNHj7o6FI8RFBREbGysq8NQyr2dTLaWEE7bDgPegta3OvX02XkO9h47TaPqofRpWp2Xh7RgcEIMfr6l2wpy2cQiIhOBfkCqMaaZXRYBfAbEA3uB4caY4yIyCnjMPjQTuNcYs94+pg/wBuALvG+MedEurw1MAyKANcBoY0yuiAQCHwNtgGPACGPM3uK8SX9/f2rXrl2cQ5VSqnQc2gCfDofc0zBqJtTt7tTTL92eytOzN5Od52DZo90J8vdleNuaTr3GxVxJ2voI6HNB2ePAd8aY+sB39s8Ae4CuxpgWwPPABAAR8QXeAvoCTYCRItLEPuYl4HX7XMeBO+3yO4Hjxph6wOv2fkop5f6SFsKHfUF84Y55Tk0qh05mce/k1Yz98Fd8fYTXhrciyL9sB1VeNrEYY74H0i8oHgBMsl9PAgba+/5sjDlul68Azj4raQfsNMbsNsbkYtVQBojV4HEdMPPCc11wjZlAD9EGEqWUu1s1ET4dARF1rO7EUU2dduo9aafp8a9lLN6WyiO9GjD3oWvpXK+K085/pYrbxhJljDkEYIw5JCJFzYZ2JzDXfh0DHCi0LRloD0QCJ4wx+YXKYy48xhiTLyIn7f11hSullPspKIDvnoWf/g31e8HQDyEwxCmnTs3IplqlIOIjK3DXtXUY2iaWmhEVnHLu4iiVxnsR6Y6VWM4uFFBUTcNcovxSxxR1vXHAOIC4uLirilUppUpdXjZ8eQ9s/gIS74C+r4BvyT9+0zJzeHHuNr7deIiF/9eVmMrB/KlnAycEXDLFfWdHRCTarq1EA6lnN4hIC+B9oK8x5phdnAwUbjWKBVKwah+VRcTPrrWcLS98TLKI+AFh/P6RHADGmAnY7TmJiYk6wEIpVX6cPmZNz3JgBfR8Djo9WOLuxI4Cw9SV+3l53jbO5Dq4q0sdwis4d5BjSRQ3scwGxgAv2t+/AhCROGAWVs+uHYX2/xWob/cAOwjcDNxijDEisgQYitXucu5cha6x3N6+2OioPKWUOzm2C6YMs7oVD/sImg4q8Slz8wsYMWE5a/efoEOdCJ4f0Iz6UZVKHqsTXUl346lAN6CKiCQDT2MllOkiciewHxhm7/43rHaQt+129nxjTKLdRnI/MB+ru/FEY8xm+5jHgGki8ndgLfCBXf4B8ImI7MSqqdxc0jerlFJl5sBKmHqzNVXLmK8hrn2JTpeT7yDQz5cAPx861Y1kTMd4BrSqUS4HfXvF7MZKKVWmNn8Js8ZBWIw1RiWybrFPZYzhq3UpvPDtVt4b3YbWpTRiXkScNruxV4y8V0qpMmEM/PwfWPiUNZHkzVOhYmSxT7czNYOnvtzM8t3HaBkbVubjUYpLE4tSSjmDIx/mjodVH0CTgTDoPfAv/nx6b36XxH8WJxHs78vfBzZjZLs4fH3K32OvomhiUUqpksrJhJl3QNJ86PwQ9HgGfIo3H9fZmdj9fX3o3zKGJ25oRJUQ5850XNo0sSilVEmcOmTN+XVkE9z4GrS98/LHFOFA+hme/XozgxNiuaF5NPd0rVMuG+avhCYWpZQqriNbrO7EWcdh5GfQoNdVnyIn38H7P+zhP4uT8BHh+sZRAG6bVEATi1JKFc/upfDZaPCvAHfMheiWV32KX3Yf44kvNrL76Gn6NqvOU/2aUKNysPNjLWOaWJRS6mqtnQJfPwhVGsCoGRBWvLWJjmTkkO8wfHh7W7o3LGrKRfekiUUppa6UMbD0n7DsJajTHYZPgqCwKz4831HAJyv24esj3NYxnptaRNOrSZTbdCO+UppYlFLqSuTnwuwHYMM0aHUr3PRv8L3y+bnW7D/Ok19sYsuhU/RpWp3RHWohIh6XVEATi1JKXV7Wcas9Ze8P0P1J6PLIFU8keeJMLi/N2860X/cTVSmIt0cl0LdZdbdunL8cTSxKKXUpx/dZPb/Sd8OgCdByxFUdvuvoaWauPsCdnWvzcM8GhAR6/seu579DpZQqroNrrNUeHTlw25cQf83ljwG2HT7F8l3HuL1zbdrUCueH8ddRPaz4o/DdjSYWpZQqyrZv4fM7oWIVGDsHqja87CGZOfn8e+EOPvx5L5WD/RnSJpbQIH+vSiqgiUUppX7vl/dg7mNQozXc8hmEXLorsDGGbzce5rk5mzlyKoeR7WoyvncjQoPKz+JbZUkTi1JKnVXggAVPwoq3oeGNMOR9CLj82vFHM3L484x11KkSwju3tiGhlKa2dxeaWJRSCiD3DMy6C7bNgfb3Qu9/gM/FuwJn5zn4ZsMhBifEUC00iOl3d6RJdCh+vsWbfNKTaGJRSqnMozB1hNVY3+dF6HDvJXdfuj2Vp2dvZt+xM9SpWpHWceG0iK1cRsGWf5pYlFLe7egOmDIUMlNhxGRo3O+iu6acyOL5OVuYu+kwdapWZMof2pfaio7uTBOLUsp77f0Jpt1ijaAf+w3EtrnorgUFhlv+t4JDJ7N5tHdD/nBtbQL9PG/UvDNoYlFKeacNM+Cr+yA83ppIMjy+yN3W7j9Os5gw/H19+OfgFsSGB1Mz4vIN+t5MW5mUUt7FGPj+VZj1B4htB3cuKDKppGXm8Ofp6xn09s9MW7kfgI51IzWpXAGtsSilvIcjD+b8CdZ+As2Hw4D/gt/5y/46CgxTV+7n5XnbyMpzcF+3ugxpU7xp8b2VJhallHfIPgUzxsCuxdDlUej+1yInknzs8w3MXJ1MxzqRPD+wKfWqVXJBsO5NE4tSyvOdPGhNJJm2Hfr/FxJGn785Kw8fgUpB/tzSPo5r61ehf8saHj0DcWnSNhallGc7tAHe7wEnD1iN9IWSijGGL9cepMe/lvHK/O0AJMSFM6BVjCaVEtAai1LKcyUthBljrVUe75gHUU3PbdqZmsGTX25ixe50WsaGMaxNTdfF6WE0sSilPNOqD+GbP0NUE7hlBoRGn9v0xdpkxs/cQLC/L/8Y1Iyb28bh66M1FGe57KMwEZkoIqkisqlQWYSILBSRJPt7uF0uIvKmiOwUkQ0iklDomDH2/kkiMqZQeRsR2Wgf86bY9c+LXUMppS6poAAWPQNzHoZ6PeD2ueeSSnaeA4A2cREMbh3L4ke6Map9LU0qTnYlbSwfAX0uKHsc+M4YUx/4zv4ZoC9Q3/4aB7wDVpIAngbaA+2Apwslinfsfc8e1+cy11BKqaLlZVtrqPz4OiTeATdPhcBKHEg/wx8m/cq9k1djjCEusgIvDW1BlZDAy59TXbXLJhZjzPdA+gXFA4BJ9utJwMBC5R8bywqgsohEA72BhcaYdGPMcWAh0MfeFmqMWW6MMcDHF5yrqGsopdTvnUmHjwfA5llw/bNw42vkGOGtJTvp+foyft51jE51q2CMqwP1fMVtY4kyxhwCMMYcEpGzq+DEAAcK7Zdsl12qPLmI8ktd43dEZBxWrYe4uLhiviWllNs6tsvqTnwyGYZ+CM0Gs+NIBvdMXs3uo6e5oXl1nurXhOiwYFdH6hWc3Xhf1INKU4zyq2KMmQBMAEhMTNS/R5TyJgdWwtSbralaxszG1GyPAFGhQURUCOCp25vQveGlV4BUzlXccSxH7MdY2N9T7fJkoHCfvVgg5TLlsUWUX+oaSill2fIVTLoJgsLIv30BHx6IYvh7y8l3FBAW7M/MeztpUnGB4iaW2cDZnl1jgK8Kld9m9w7rAJy0H2fNB3qJSLjdaN8LmG9vyxCRDnZvsNsuOFdR11BKeTtj4Of/wPQxUL0F6/vMpP/Uwzz79RaCA/w4lZ3v6gi92mUfhYnIVKAbUEVEkrF6d70ITBeRO4H9wDB792+BG4CdwBngdgBjTLqIPA/8au/3nDHmbIeAe7F6ngUDc+0vLnENpZQ3K3DAvMdh5QTyGw3gWb8HmfzhNqIqBfH2qAT6Nquuo+ZdTIyHdZFITEw0q1atcnUYSqnSkJ8Ds8bBli+h4/3k9XiWgW8vp1PdSB66vgEhgTrmu7hEZLUxJtEZ59J/BaWUe8g+RcG0Ufjs/Z5PK4+jX9dnCPXz44v7OhPgp9Melif6r6GUKvey0lM49lZPCvb+xMO59/F+/o3sPnoaQJNKOaQ1FqVUuXYieTsZ799EpDnBC2F/o0+vm3mtSRQ+Og1LuaWJRSlV7hxIP8OqfekMqn6MylOHEOiXy+5eU3mq7XXaMO8GNLEopcqNTQdP8t73u/lmQwpd/LYyMPh1JDic4LHf0rRqA1eHp66QJhallMslHcnguTlb+CEpjZBAP/7VZDcD976EVK4Ht34OoTVcHaK6CtrqpZRyiXxHAUczcgAIDvBlV2omj/VpxK+99jBo11NIjQS4/VtNKm5IayxKqTJ1JjefGauS+d8Pu6lbNYRJd7QjNrwCP4zvju+yF2DhK9DwBhg6Efx10kh3pIlFKVUm0k/nMunnvXy8fC/Hz+SREFeZUe3t2cgd+fh+83+wZhK0Hg39/g2++vHkrvRfTilVJqau3M8b3yVxfeMo7ulah8T4CGtDXhZ8/gfYNgeufQSuexK055db08SilCoVZ3t49W4aRb8WNbi1Qy16N42iXrVKv+2UdQKmjoT9y6Hvy9D+btcFrJxGE4tSymmMMfy4M433lu3mx51pVAr0o128tQp5WLA/YcH+v+186hBMHgJpO2DoB9BsiIuiVs6miUUp5TT3T13LNxsOERUayBN9GzGyfRyhQf6/3zEtCT4ZDFnpMGoG1O1e9sGqUqOJRSlVbGdy85m5OpkhCbFUDPSjf8sadG1QlQGtahDo51v0QcmrYcpQEB8YOwdqtC7boFWp08SilLpqxzJzmLR8Hx8v38uJM3mEBfszoFUMvZtWv/SBOxfBZ7dBxSow+guIrFsm8aqypYlFKXXFcvMLeH7OFqavOkBOfgE9m0Rxd5dCPbwuZcN0+PJeqNrYGk1fKar0A1YuoYlFKXVZKSeyqFE5mAA/H3anZTKwVQx3dal9fg+vS1n+Fsz/C8RfCzdPgaCw0g1YuZQmFqVUkYwxfJ+UxnvLdrFq33F+fKw71SoF8ckd7a98ynpjYNHT8NMb0Lg/DP4f+AeVbuDK5TSxKKXOk+co4JsNh3h32S62Hc4gKjSQR3o1oEKA9XFxxUnFkQezH4T1n0LiHXDDq+BzkQZ95VE0sSilznPweBZ/mr6OulVDeGVoCwa0irn6VRpzz8CMsZA0H7r9BbqO19H0XkQTi1JeLi0zh0k/7yXlRDb/Gt6S+CoV+fK+zjSPCSveKo1n0uHT4XBwNfR73aqtKK+iiUUpL7U37TT/+2E3M1cnk+sooHeT6uQ7CvDz9aFlzcrFO+nJZGvg4/E9MGwSNOnv3KCVW9DEopQXmrMhhQemrsXfx4fBCTHc1aUOdauGlOykqdtg8mDIybDGqMRf45xgldvRxKKUFzDGsGzHUYL9fWlfJ5JOdatwb9e6jO0UT7VQJ/TS2v+L9fjLL9BanKt685KfU7ktTSxKebA8RwFzNqTw3rLdbDucwfWNo2hfJ5KIigGM79PIORfZPs9qqA+Ntmoq4fHOOa9yW5pYlPJQX6xN5pV520k5mU2DqBBeHdaS/i2dvMzv2ikw+wGrhjJqJoRUde75lVsq0Zr3IvKQiGwSkc0i8rBd1kpEVojIOhFZJSLt7HIRkTdFZKeIbBCRhELnGSMiSfbXmELlbURko33MmyLaX1GpS0nLzCE7zwHA6RwHsREVmDg2kXkPdWFom9ir7zZ8McbAj6/DV/dB7S7WZJKaVJSt2L9lItIMuAtoB7QE+olIfeBl4FljTCvgb/bPAH2B+vbXOOAd+zwRwNNAe/tcT4tIuH3MO/a+Z4/rU9x4lfJke9NO89cvNtLpxcXMWJ0MwC3t4ph+d0euaxRVvG7DF1NQYE3PsugZaDYUbpkOgVc4tYvyCiV5FNYYWGGMOQMgIsuAQYABQu19woAU+/UA4GNjjAFWiEhlEYkGugELjTHp9nkWAn1EZCkQaoxZbpd/DAwE5pYgZqU8yvoDJ3jv+13M3XQYfx8fhrSJoXPdSOAqRshfjfxcq5aycQa0vwd6/xN8nFQLUh6jJIllE/APEYkEsoAbgFXAw8B8EXkVq0bUyd4/BjhQ6Phku+xS5clFlP+OiIzDqtkQFxdXgreklHt5evZmdh/NtHp4dY6nWqVSnIcrJxOmj4Zdi6HH03DNn3Q0vSpSsROLMWariLwELAQygfVAPnAv8CdjzOciMhz4ALgeKOo30BSjvKhYJgATABITE4vcRyl3l5tfwNfrU/h4xT4mjkkkMiSQ14a3pFpoECGBpdwP53QaTBkGh9ZD//9CwujSvZ5yayWqwxpjPjDGJBhjugDpQBIwBphl7zIDq90ErBpHzUKHx2I9JrtUeWwR5Up5lcycfN7/YTddX1nCn2esJzvXweFT2QDUqRpS+knl+D74oBekbrGmvNekoi6jRL+RIlLNGJMqInHAYKAj8ADQFVgKXIeVbABmA/eLyDSshvqTxphDIjIfeKFQg30v4AljTLqIZIhIB+AX4DbgPyWJVyl3c/JMHl1fXcKJM3l0qBPBC4Ob061BVcqsg+ThTTB5CORnwW1fQVyHsrmucmsl/VPnc7uNJQ/4ozHmuIjcBbwhIn5ANnbbB/AtVjvMTuAMcDuAnUCeB36193vubEM+1mO1j4BgrEZ7bbhXHm/30UyW7z7GqPa1CKvgzz1d69K+dgSt48Ivf7Az7f0Jpo6EgIpwx3yo1rhsr6/cllidtDxHYmKiWbVqlavDUOqqrd1/nHeX7WLBliME+fmy/InrqFwhwDXBbP0aZt4J4bXg1llQueblj1FuTURWG2MSnXEuHXmvlIslHcngr19uYuWedMKC/bm/ez1u6xjvuqSy6kP45v+gRgKMmgEVrmA9e6UK0cSilAvk5hdw7HQO0WHBhFXw52hGDk/1a8LNbWtSsbQb4y/GGPj+FVjyD6jXE4ZPsh6DKXWVNLEoVYYyc/KZtnI/H/y4h5rhFZh+T0eqVQpi8Z+7ll2DfFEKHDD3Mfj1f9DiZhjwX/D1d108yq1pYlGqDBw8kcWUFfv4ZMU+MrLz6Vgnkru71sEYg4i4Nqnk58Csu2DLV9DpQbj+WR1Nr0pEE4tSpSQjOw8/Hx+CA3z5busR3l22i77NohnXpU7xV2h0tuxTMO0W2PsD9Po7dHrA1REpD6CJRSknchQYftyZxuerk5m/+TDP9G/KyHZxDGwdQ/eG1agZUcHVIVawidMAABiYSURBVP4m4whMGQKpW2HQBGg5wtURKQ+hiUUpJ3AUGF6at40v1x4kNSOHsGB/hiXG0squmYQG+RMaVI7aLI7tspYRzkyFkdOgfk9XR6Q8iCYWpYrpaEYOGw+e4LpGUfj6CGv3H6dlzcoMSYihe6NqBPr5ujrEoqWsgylDrQb7MV9DrFOGLih1jiYWpa5Cdp6DRVuPMGvNQZbtOIqvj7DmqZ6EBPoxbVxHfEtjqnpn2r0Upo2C4HBr4GPVBq6OSHkgTSxKXaH5mw/zyIz1ZGTnEx0WxN1d6jA4IebcJJDlPqlsmgVf3A2R9eDWzyHUycsUK2XTxKLURew7dppZaw7SoU4kHetGUq9aCD2bRDE0IZb2dSLLfyIp7JcJMHc81GwPt0yzaixKlRJNLEoVcjIrj282HGLWmmRW7TuOCPj5CB3rRlK3agivDW/l6hCvjjHWSPrvX4GGN8DQieAf7OqolIfTxKK83tlBisYYBr31E7vTTlOvWgiP9WnEwNY1iA5z0w9iRz588ydY8zG0Hg39/g2++l9elT79LVNeyRjD5pRTzFpzkJ93pfH1A9fg7+vDX29sTNVKgTSPCXPtaPiSysuCz/8A2+bAtY/AdU/qMsKqzGhiUV4lLTOHz1cnM2vNQbYfycDfV+jRKIqTWXlUCQmkR+MoV4dYclknrHVU9i+Hvi9D+7tdHZHyMppYlMfLynWQnecgvGIAO45k8M+522gdV5nnBzbjphbRrpuevjScOmQNfExLgqEfQLMhro5IeSFNLMojFRQYftmTzqw1yXy78RAj2sbxt5ua0KF2JEse6UbtKh44HXxaEnwyGLLSrXVU6nZ3dUTKS2liUR7n7aU7mbJiPwdPZBES6MeNLaK5sUU0AD4+4plJJXm1NZpefGDsHKjR2tURKS+miUW5vRNnclmyPZWBrWIQEfalnaFetRDG92lIrybVCQ4op1OrOEvSIpg+GipWhdFfQGRdV0ekvJwmFuWWcvMLWLo9lVlrDrJ4Wyq5jgKaRIfRsHol/jm4OT7uNHixJDZMhy/vhaqNrdH0lTyg84Fye5pYlNvZkHyCMRNXcvxMHlVCAhjdsRaDE2JoEBUC4D1JZflbMP8vEH8t3DwFgsJcHZFSgCYW5QZSTmTxxdqDVA8NYkibWOpVC6Fbw2r0b1mDa+tXwc/Xy1Y7NAYWPQ0/vQGN+8Pg/4F/kKujUuocTSyqXDqdk8+8TYf5fE0yy3cfwxgYnhjLkDaxVAjw4/URbja1irM48mD2g7D+U0i8A254FXw8vA1JuR1NLKrcODu1CsBD09ayaGsqcREVeKhHfQa1jqFWpAf25roauadhxlhIWgDd/gJdx+toelUuaWJRLpd0JIPP1xzk6/UpzLqvE1GhQdzXvR73dK1Lm1rh7j21irOcSYdPh8PB1dDvdau2olQ5pYlFucSp7DxmrU7m8zUH2XjwJL4+QtcGVcnIziMqNIiEOJ3W/ZyTydbAx+N7YNgkaNLf1REpdUklavUUkYdEZJOIbBaRhwuVPyAi2+3ylwuVPyEiO+1tvQuV97HLdorI44XKa4vILyKSJCKfiYgHzb3hfXLyHaScyAKsaVaem7OFAmN4ql8TVjzRg4lj21KvWiUXR1nOpG6FD3pBxiFrjIomFeUGil1jEZFmwF1AOyAXmCci3wCxwACghTEmR0Sq2fs3AW4GmgI1gEUicnZd1LeAnkAy8KuIzDbGbAFeAl43xkwTkXeBO4F3ihuzKnvGGNbsP8GsNcnM2XCIFrFhfHJne6JCg1j2aHdqRlRwdYjl1/5frMdffoFw+7dQvbmrI1LqipTkUVhjYIUx5gyAiCwDBgGJwIvGmBwAY0yqvf8AYJpdvkdEdmIlJYCdxpjd9nmmAQNEZCtwHXCLvc8k4Bk0sbiN6b8e4J1lu9iTdpogfx96N63OkITYc9s1qVzC9rkw43YIjbZqKuHxro5IqStWksSyCfiHiEQCWcANwCqgAXCtiPwDyAYeMcb8CsQAKwodn2yXARy4oLw9EAmcMMbkF7G/KocysvOYu+kwN7WoQXCALyeycokKDeTebnXp26w6lYL8XR2ie1g72epSXL05jJoJIVVdHZFSV6XYicUYs1VEXgIWApnAeiDfPmc40AFoC0wXkTpAUV17DEW385hL7P87IjIOGAcQFxd3dW9ElUi+o4Cfdh1j1ppk5m8+THZeAZUC/ejbPJq7rq3DuC46b9UVMwZ+fB2+exbqdIcRn0Cgtjkp91OiXmHGmA+ADwBE5AWsWkVjYJYxxgArRaQAqGJvq1no8FggxX5dVHkaUFlE/OxaS+H9L4xjAjABIDExscjko5wvNSObfm/+SGpGDmHB/gxrU5PBCTG0qlkZQLsJX42CAljwV1jxNjQbCgPfAT/tq6LcU4kSi4hUM8akikgcMBjoCBRgtY0stRvnA7CSxGzgUxF5Davxvj6wEqtmUl9EagMHsRr4bzHGGBFZAgwFpgFjgK9KEq8qmaMZOXy17iBZuQ4e6FGfqiGB3NA8mg51IuneqCqBfjoCvFjyc62JJDfNhPb3QO9/go+XTVOjPEpJx7F8brex5AF/NMYcF5GJwEQR2YTVW2yMXXvZLCLTgS1Yj8z+aIxxAIjI/cB8wBeYaIzZbJ//MWCaiPwdWItdO1JlJzvPwcItR5i1Jpnvk9JwFBg61Y3k/uvqISI807+pq0N0bzkZ8Nlo2L0EejwN1/xJR9MrtyfWZ77nSExMNKtWrXJ1GB7jhW+3MuH73USHBTGodQyDE2J0rImznE6zFuc6tAFuegMSRrs6IuXFRGS1MSbRGefSkffqPKmnsvnP4p0MSoghIS6cW9rF0bVBVTrUicTXW6ajLwvH98Eng+DUQWvK+4Z9XR2RUk6jiUUBcPx0Lu9+v4tJP+8l32GoVy2EhLhw4qtUJN4Tl/J1pcObYPIQyM+C276CuA6ujkgpp9LEonj/h928sSiJzNx8BrWK4eHrGxAXqYMXS8XeH2HqSAgIgTvmQ7XGro5IKafTxOKlsvMcBPj64OMj5OQX0KleJH/u1ZAGUdp+Umq2fg0z74TwWnDrLKhc8/LHKOWGNLF4mTxHAdNXHeDN75J4ql8T+rWowX3d6uqYk9JSUAD7foS1U2DjdKiRAKNmQIUIV0emVKnRxOIlHAWG2esP8vrCJPannyGxVjg1KgcDOpCxVJzYD+s+tb5O7IPAUGj7B7j+GQjQNivl2TSxeIm7P1nNoq1HaBIdyodj29KtYVVNKM6Wl2U97lo7GfZ8Dxio3RWuexIa9YMAbbdS3kETi4cyxvDTzmO0qRVOcIAvI9vVZGDrGtzQLBof7TbsPMZYqzqunQybZkHOSagcB92egFYjrddKeRlNLB5o9b50Xpm/nRW703nmpiaM7VybHo2jXB2WZ8k4Ahs+g3VT4Og28AuGJgOg9SiodY1OyaK8miYWD7I55ST/WrCDxdtSqRISwDM3NWFke/2L2WkcebBjvlU7SVoAxgGx7axR800HQVCYqyNUqlzQxOJBnv16C9sOnWJ8n4aM7RRPhQD953WKI5utXl0bPoMzaRASBZ3uh1a3QtUGlz9eKS+jnzxu7OCJLP67eCd/ur4+1UKDeHlIC8IrBhAWrAtqlVjWcdg403rUlbIWfPyhYR9oPRrq9gBf/a+j1MXo/w43dDQjh7eW7OTTX/YD0KV+Ffo2j9apV0qqwAG7l1rJZOsccORAVDPo8yI0Hw4VI10doVJuQROLGzHG8NrCHbz/wx5yHQUMT4zlgevqnxuPoorp2C5rvMn6qdakkEGVoc0YaDUKolvqNPZKXSVNLG4gN7+AAD8fRITk41n0bBLFn3o2oLbWUIovJxO2fGXVTvb9BOIDda+D3v+AhjeAX6CrI1TKbWliKcey8xx8+st+3l66i4/vaEeTGqG8OqylTl9fXMbA/hWwbjJs/hJyMyGiDvT4G7QcCaE1XB2hUh5BE0s5lO8o4PM1ybyxKImUk9l0LLQWiiaVYjiVYj3mWjsF0ndZMws3HWj16orroI+6lHIyTSzlTEGBYcBbP7E55RQta1bmlWEt6VyviqvDcj/5ObD9W2vMya7FYAqgVme49s/WQMbAEFdHqJTH0sRSDhhj+GVPOu1rR+DjI9zcLo6oSoH0bBKl83ldrUPrrWSycYbVZTg0xkomrW6xHnsppUqdJhYXW77rGK/M38aa/Sf46Pa2dGtYjdEdark6LPdy+pg1Jf3aKXBkI/gGQuN+Vq+uOt3Ax9fVESrlVTSxuMi6Ayd4df52ftyZRvXQIF4Y1FwfeV0NRz7s+s6qnWyfCwV5UKM13PAqNB8KweGujlApr6WJxQXyHAXc88lqch0FPHljY27tUIsgf/2r+oqkJVnJZP00yDwMFapAu3HW5I9RTV0dnVIKTSxlZt+x03z4016euKERgX6+/O+2RGpXrUhIoP4TXFb2Kdg8y3rUlbwSxBfq94LWt1rf/QJcHaFSqhD9VCtlh09m8+biJKb/egA/X+GmljVoUyuc5rE6E+4lFV7Sd8tXkJ8FVRtBz+ehxQiopMsAKFVeaWIpJdl5Dv61YDuTlu/DGMOo9nH8sXs9qoUGuTq08u3Eflg31RoRf3ZJ35Y3W7WTmDY65kQpN6CJxckcBQZfHyHQz4eVe48zoGUNHuxRn5oRuiztRV10Sd+nrN5d/joXmlLuRBOLk2TlOpi0fC9TftnH7D9eQ3jFAGbc3ZEAP11JsEjGwME1sPYTXdJXKQ9TosQiIg8BdwEC/M8Y8+9C2x4BXgGqGmPSxBrp9wZwA3AGGGuMWWPvOwZ40j7078aYSXZ5G+AjIBj4FnjIGGNKErOz5eYXMO3X/fxn8U6OZuTQrWFVMnPyCa8YoEmlKJmpVo8uXdJXKY9V7MQiIs2wkko7IBeYJyLfGGOSRKQm0BPYX+iQvkB9+6s98A7QXkQigKeBRMAAq0VktjHmuL3POGAFVmLpA8wtbszOdio7jxvf/IED6Vm0i4/g7VEJtI2PcHVY5c/ZJX3XTbG+n7ek72AICnV1hEopJypJjaUxsMIYcwZARJYBg4CXgdeB8cBXhfYfAHxs1zhWiEhlEYkGugELjTHp9nkWAn1EZCkQaoxZbpd/DAzExYnFGMOmg6doHhtGaJA/N7WoQfs6kXSpX0WnX7nQkS1Wu4ku6auUVylJYtkE/ENEIoEsrEdcq0SkP3DQGLP+gg/aGOBAoZ+T7bJLlScXUf47IjIOq2ZDXFzpPJs3xrBsx1H+tWAHm1NO8t2fu1G7SkXG92lUKtdzW0Uu6dvX6tWlS/oq5RWK/b/cGLNVRF4CFgKZwHogH/gr0KuIQ4r6c94Uo7yoWCYAEwASExOd3gazck86r87fzsq96dSMCOaVoS2J015ev9ElfZVShZToz0djzAfABwAi8gJwBBgFnK2txAJrRKQdVo2jZqHDY4EUu7zbBeVL7fLYIvYvU8cyc7j1g1+oHOzP8wObMSKxpjbKn5W+21rSd92nuqSvUuqckvYKq2aMSRWROGAw0NEY80ah7XuBRLtX2GzgfhGZhtV4f9IYc0hE5gMviMjZWQN7AU8YY9JFJENEOgC/ALcB/ylJvFdqZ2oG3248zIM96hMZEshHY9vSOi6c4ACdz4vc09ZI+LWTdUlfpVSRSvrA+3O7jSUP+KPdk+tivsVqh9mJ1d34dgA7gTwP/Grv99zZhnzgXn7rbjyXUm64P5B+hn8vSuKLtckE+/sypE0sMZWD6eTtsw4XuaRvXV3SVylVJClnw0JKLDEx0axateqqjjl5Jo9/LdzO1JX7ERHGdKzFPV3rEhni5X99nzwIG6bpkr5KeQERWW2MSXTGuby6i44xBhHB11eYt+kwwxJr8sB19YgO88IpRLJPQso6SFljjYhPWQcn7WFIuqSvUuoqeGViyczJZ+KPe1iyPZWZ93QiJNCPZY929542lNwzcHhjoSSyFo4l/bY9PB5i20C7u6DRjRBZ12WhKqXcj1clluw8B5NX7OPtpbtIP51L76ZRZGTnUblCgOcmFUceHNl8fk0kdYs1+h2gUjTUSLCmoo9pbb2uoLMHKKWKz2sSy56004ycsILDp7K5tn4VHunVkJY1K7s6LOcqcFgrLBauiRzeaI0rAWu53hoJ0KA3xCRYr0OjXRuzUsrjeHRicRQY9qSdpl61EOIiKtCpbiRDE2PpVNcDenkZA8f3np9EDq23emyB1dAe3cp6nHU2iYTHa4O7UqrUeWRiMcawYMsRXluwg9SMbH547DpCAv14bUQrV4dWfKcOnZ9EUtZClt0r2zcQqjeHVrdADftxVpX64OOhj/eUUuWaxyWWzJx8Br79M+sPnKB2lYo8N6AZFfzd7AP2TLqdROwEkrIGMg5Z28QXqjWxFsA6m0SqNdF135VS5YbHJZY9aaeJOJXNy0NaMDghBj/fcj79Sk6G9Qjr4BorgaSstR5xnRVZH2p3+S2JVG8OATpPmVKq/PK4xBIXUYElj3Yj0K8c1lLysuHIpvOTyNHtnJtbMyzO6pnVZqyVRGq0gqAwV0aslFJXzeMSS1iwf/lIKo58OLr1tyRycI3Vzbcg39pesZrVqN50kJ1EWkNIVdfGrJRSTuBxicUlCgqsKU8K10QObYD8LGt7UJiVODo9aH2PSYDQGO2hpZTySJpYrpYxcPLA+UkkZR3knLK2+1ewpoxPvOO3JBJRR5OIUspraGK5nMzU8x9npay1ltkFa3XE6s2g+bDfkkiVhrpKolLKq+knYGFZJ37r3nt2+pNT9urI4gNVG0GDPlajekyCtUqirj+ilFLn8d7Eknvaagc5l0TWWCsinhVRx5oa/mxNpHoLndlXKaWugHcklvxcq5vvuUGHa+DoNjAF1vbQGCuBtL7VHi/S2ppXSyml1FXzzMRyZMv5NZEjm8GRa22rEGl1721802+DDitFuTZepZTyIJ6XWA5tgHc6Wq8DKlntIR3u/S2JVI7THlpKKVWKPC+xVIiAQf+2kkhkPfAp51O6KKWUh/G8xBIWCy1vdnUUSinltfTPeaWUUk6liUUppZRTaWJRSinlVJpYlFJKOZUmFqWUUk6liUUppZRTaWJRSinlVJpYlFJKOZUYY1wdg1OJSAaw3dVxeJAqQJqrg/AQei+dS++nczU0xlRyxok8b+Q9bDfGJLo6CE8hIqv0fjqH3kvn0vvpXCKyylnn0kdhSimlnEoTi1JKKafyxMQywdUBeBi9n86j99K59H46l9Pup8c13iullHItT6yxKKWUciFNLEoppZyq3CcWEakpIktEZKuIbBaRh+zyCBFZKCJJ9vdwu1xE5E0R2SkiG0QkodC5xtj7J4nIGFe9J1dy8v2cJyInRGSOq96PKznrXopIKxFZbp9jg4iMcOX7chUn3s9aIrJaRNbZ57nHle/LVZz5f93eHioiB0Xkv5e9uDGmXH8B0UCC/boSsANoArwMPG6XPw68ZL++AZgLCNAB+MUujwB229/D7dfhrn5/7no/7W09gJuAOa5+X+58L4EGQH37dQ3gEFDZ1e/Pje9nABBovw4B9gI1XP3+3PV+FjrfG8CnwH8vd+1yX2MxxhwyxqyxX2cAW4EYYAAwyd5tEjDQfj0A+NhYVgCVRSQa6A0sNMakG2OOAwuBPmX4VsoFJ95PjDHfARllGX954qx7aYzZYYxJss+TAqQCVcvwrZQLTryfucaYHHufQNzgyUxpcOb/dRFpA0QBC67k2m51w0UkHmgN/AJEGWMOgXUDgWr2bjHAgUKHJdtlFyv3WiW8n6oQZ91LEWmH9Rf3rtKNuHwr6f20HwNtsLe/ZCdsr1WS+ykiPsC/gEev9Hpuk1hEJAT4HHjYGHPqUrsWUWYuUe6VnHA/lc1Z99L+6/AT4HZjTIFzo3QfzrifxpgDxpgWQD1gjIhEOT9S9+CE+3kf8K0x5kAR24vkFolFRPyxbswUY8wsu/hIoWpaNNbjA7CybM1Ch8cCKZco9zpOup8K591LEQkFvgGetB9DeCVn/27aNZXNwLWlGXd55aT72RG4X0T2Aq8Ct4nIi5e6brlPLCIiwAfAVmPMa4U2zQbO9uwaA3xVqPw2u4dDB+CkXd2bD/QSkXC7F0Qvu8yrOPF+ej1n3UsRCQC+wHq+PaOMwi93nHg/Y0Uk2D5nONAZL5zx3Fn30xgzyhgTZ4yJBx7B+j19/JIXL+2eCSX9Aq7Bqo5tANbZXzcAkcB3QJL9PcLeX4C3sJ5RbwQSC53rDmCn/XW7q9+bB9zPH4CjQBbWXzu9Xf3+3PFeArcCeYXOsQ5o5er358b3s6d9jvX293Gufm/ufD8vOOdYrqBXmE7popRSyqnK/aMwpZRS7kUTi1JKKafSxKKUUsqpNLEopZRyKk0sSimlnEoTi1JKKafSxKKUUsqp/h9iAlXqNxvi6wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAD4CAYAAADPccAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3wVVf7/8dcnPSEhIQk1AULvPfSqSBUEEQVUREVQrOuuBf26a1l3rWtbEWUFEXFBVxERQToCAtJ7D0RI6AkEQgiknN8fM/CLkZZwk7n35vN8PPJIcu7cuZ87hLxz5sycI8YYlFJKKVfxcboApZRS3kWDRSmllEtpsCillHIpDRallFIupcGilFLKpfycLsDVoqOjTVxcnNNlKKWUR1m7du1xY0xZV+zL64IlLi6ONWvWOF2GUkp5FBH5zVX70lNhSimlXEqDRSmllEtpsCillHIprxtjuZSsrCySkpLIzMx0uhSvERQURGxsLP7+/k6XopRyMyUiWJKSkggLCyMuLg4Rcbocj2eMISUlhaSkJKpVq+Z0OUopN1MiToVlZmYSFRWloeIiIkJUVJT2AJVSl1QiggXQUHExPZ5KqcspMcGilPISxsC+pbD5G8jJdroadQkaLMXE19eXpk2b0rBhQ26//XYyMjIKva/FixfTp08fAGbMmMHrr79+2W1PnjzJRx99dPH7gwcPMnDgwEK/tlKOMQb2/gyf9YbP+8C3w+E/N0DyOqcrU/losBST4OBgNmzYwJYtWwgICODjjz/+3ePGGHJzcwu831tuuYXRo0df9vH8wVKpUiW++eabAr+OUo4xBvYtgYk3w6Rb4EQi9H4bBk6A9KPwaVeY9QxknnK6UmXTYHFAx44d2bNnD4mJidSrV4+HH36Y5s2bc+DAAebOnUvbtm1p3rw5t99+O+np6QD89NNP1K1blw4dOjBt2rSL+5o4cSKPPvooAEeOHOHWW2+lSZMmNGnShOXLlzN69GgSEhJo2rQpTz/9NImJiTRs2BCwLmq47777aNSoEc2aNWPRokUX9zlgwAB69uxJrVq1eOaZZ4r5CClluxAon/eF1L1WoDy+HlqNgIa3waOroOUDsGocjGkF2763gkg5qkRcbpzfoE9W/KGtT+OKDG0bx9nzOdz72ao/PD6wRSy3x1cm9cx5Rk1e+7vHvnqw7TW/dnZ2NrNnz6Znz54A7Ny5k88++4yPPvqI48eP8+qrrzJ//nxKlSrFG2+8wTvvvMMzzzzDiBEjWLhwITVr1mTQoEGX3Pfjjz9O586d+e6778jJySE9PZ3XX3+dLVu2sGHDBgASExMvbj9mzBgANm/ezI4dO+jevTu7du0CYMOGDaxfv57AwEDq1KnDY489RuXKla/5fSp1XfYthcWvw2/LIKwi9HoLmt8D/kG/3y4oHHq/BY0Hw8wn4Ot7oFYPq61MVWdqV9pjKS5nz56ladOmxMfHU6VKFYYPHw5A1apVadOmDQArV65k27ZttG/fnqZNm/L555/z22+/sWPHDqpVq0atWrUQEe6+++5LvsbChQsZNWoUYI3phIeHX7GmZcuWMXToUADq1q1L1apVLwZL165dCQ8PJygoiPr16/Pbby6bn06py9u3FD672RpDSU2wAuXxDdB65B9DJa/YFjBiMXT/ByQug4/awC/vQ05WsZWu/r8S2WO5Ug8jOMD3io9HlgooUA/l4n7tMZb8SpUqdfFrYwzdunVjypQpv9tmw4YNRXJ5r7nCKYPAwMCLX/v6+pKdrVffqCK0byn8/AYkLoXQCtDrTWg+7Mphkp+vH7R7FOr3g9nPwLy/waavoc97ULll0dWu/kB7LG6kTZs2/PLLL+zZsweAjIwMdu3aRd26ddm3bx8JCQkAfwieC7p27crYsWMByMnJ4dSpU4SFhXH69OlLbt+pUye+/PJLAHbt2sX+/fupU6eOq9+WUpeXuAwm9rF6KMd3W4HyxEZo/WDBQiWviMowZAoM+hIyUmF8N5j5Zzh70rW1q8vSYHEjZcuWZeLEiQwZMoTGjRvTpk0bduzYQVBQEOPGjePmm2+mQ4cOVK166XPH77//PosWLaJRo0a0aNGCrVu3EhUVRfv27WnYsCFPP/3077Z/+OGHycnJoVGjRgwaNIiJEyf+rqeiVJG5ECgTb7YCpecb8MSG6wuU/Or1sQb324yCtZ9Zg/tbvtXB/WIgVzod4oni4+NN/oW+tm/fTr169RyqyHvpcVUFlvgLLH7NPuVVHjr8GVoMA//gon3dgxvghyfg0AaoeZN1dVmkznOXl4isNcbEu2JfJXKMRSlVzPIHSs/XocW9RR8oF1RqCiMWwqr/wMK/W4P7nZ+Fdo+Br87Q7WoaLEqpovPbcitQ9i1xJlDy8vGFNg9Bvb7w07Ow4GVrcL/ve1ClTfHX48WuOsYiIhNE5KiIbMnTdruIbBWRXBH5Q9dJRKqISLqIPJWnraeI7BSRPSIyOk97NRH5VUR2i8hXIhJgtwfa3++xH4+73jerlComvy23bmr8rBcc3QE9XrMG5duMciZU8gqPgUGTYchUOJ8OE3rAjMfh7Aln6/Ii1zJ4PxHoma9tCzAAWHKZ57wLzL7wjYj4AmOAXkB9YIiI1LcffgN41xhTCzgBDLfbhwMnjDE17f29cQ21KqWc9NsK+PyWPwZK24edD5T86vSCh1dap8PWT4YPW8Km/+ngvgtcNViMMUuA1Hxt240xOy+1vYj0B/YCW/M0twL2GGP2GmPOA1OBfmLdnHEjcGHyqs+B/vbX/ezvsR/vKjpXu1Lu6WKg9ISj26HHP/9/oASEOF3d5QWGQvdX4cGfIaIqTHsAvugPKQlOV+bRXHq5sYiUAp4FXs73UAxwIM/3SXZbFHDSGJOdr/13z7EfT7O3v9TrjhSRNSKy5tixY654K0qpa7F/JUzqd4lAecS9AyW/Co1g+FzrarHkdfBRW/j5Lcg+53RlHsnV97G8jHVaKz1f+6V6GuYK7Vd6zh8bjRlnjIk3xsSXLVv2mostTnmnze/bty8nTxb+Zq24uDiOHz/uwuqUKqALgTKhBxzZak2l4omBkpePrzW55SOroG5vWPQqfNzBuqJNFYirg6U18KaIJAJ/Ap4XkUexeiJ5ZzCMBQ4Cx4EIEfHL107e59iPh5PvlJwnyTttfmRk5MUJIJXyKPt/hUn98wXKJmsqFU8NlPxKV4TbJ8Jd30B2JkzsDdMfse7iV9fEpcFijOlojIkzxsQB7wH/NMZ8CKwGatlXgAUAg4EZxro7cxFwYeWpYcD39tcz7O+xH19ovORuzrZt25KcnHzx+7feeouWLVvSuHFjXnzxxYvt/fv3p0WLFjRo0IBx48Y5UapSlouB0h2ObLHGJZ7Y6F2Bkl+tbvDwr9D+T7BpKnwYDxum6OD+NbjqfSwiMgXoAkSLSBLwIlbP4d9AWeBHEdlgjOlxuX0YY7LtnsscwBeYYIy5MLj/LDBVRF4F1gPj7fbxwBcissd+vcGFeH9/NHs0HN7skl1dVKER9Lr8Ko555eTksGDBgouzG8+dO5fdu3ezatUqjDHccsstLFmyhE6dOjFhwgQiIyM5e/YsLVu25LbbbiMq6pLDTEoVjQOrrPtQEhZCSLQVKPH3Q0Cpqz/XGwSEQLeXofEdMPNJmP4QbPgS+rwL0bWcrs5tXTVYjDFDLvPQd1d53kv5vp8FzLrEdnuxrhrL354J3H61+jzFhWnzExMTadGiBd26dQOsYJk7dy7NmjUDID09nd27d9OpUyc++OADvvvOOswHDhxg9+7dGiyqeOQPlG5/h5bDS06g5Fe+Adz3E6z7HOa/CGPbWdPRdHjSdXObeZGSd+f9NfYsXO3CGEtaWhp9+vRhzJgxPP744xhjeO6553jwwQd/t/3ixYuZP38+K1asICQkhC5dupCZmelI7aoEObDKWmArYYEGSn4+PhB/H9S9GeY8Dz+/Dlu+sXov1To5XZ1b0dmNi1l4eDgffPABb7/9NllZWfTo0YMJEyZcXII4OTmZo0ePkpaWRpkyZQgJCWHHjh2sXLnS4cqVVzuwCr4YYE0xf2gDdHsF/rQJ2j+uoZJfaDm47VO4exrk5lgzDHz3EJzRKzUvKHk9FjfQrFkzmjRpwtSpUxk6dCjbt2+nbVtr8bDQ0FAmT55Mz549+fjjj2ncuDF16tS5uMqkUi51YLV9ymsBhERZgRI/3LpxUF1Zza7w8ApY8ra1WuWun6zj1/Ruq3dTgum0+arQ9Lh6sAOrrVM5e+ZbgdL+CQ2U63F0hzW4v385VGlnnR4rV9fpqgpEp81XShVO0hqrh3IhUG56GVo+oIFyvcrVhXt/tK4Ym/dX68bK9k9Ap6fcb460YqDBolRJkLTGGpTfM08Dpaj4+EDzodbklnNfgKVvWytW9nkHatzodHXFqsScCPS2U35O0+PpIZLWwuSB8GlXSF4LN71k3Snf4U8aKkWlVDTc+jHcMwPEB764Fb59ANKPOl1ZsSkRPZagoCBSUlKIiopCJ0i+fsYYUlJSCArS6/fdVtJaawxl91wIjrQCpeUIDZPiVL0zjFoOy96FZe9Y/xY3vQzNhzk6uH/s9DlW7E1hRUIKaxJTmf5Ie0oFujYKSkSwxMbGkpSUhM587DpBQUHExsY6XYbKL3+gdH3RmlgxMMzpykom/yC44TloNNAa3J/5J9g4Bfq8B+XrX/35LvTLnuO8NGMru49atzaEBvrRqlokJ89mabAUhr+/P9WqVXO6DKWKTvJaWPwG7J4DwWU0UNxNdC0Y9gNsnGrdXPlJR2uBsU7PuHyutbSzWazal8qKhBRW7E3hia416dmwIhEh/lSMCGZA81ja1oiiYaXS+PkWTc+pRASLUl7rD4HyN2g1UgPFHYlA0yFQu4d15diyd2HLNLj5X9aEl4VkjEFESMvIYuiEX9mSnEaugUA/H1pULUOQvy8ADSqFM+n+P8yeVSQ0WJTyRMnr4Oc3rJvyNFA8S0gk9BsDTYZYp8e+HAgNboWer0NYhas+PTMrh7W/nWBFQgrLE45Ts1wobw5sQulgPyqGB9GlTjna1YiiaeWIi6FS3DRYlPIk+QPlxr9agRJU2unKVEHFdYCHlsEvH8CSt2DPAusPhPj7rUXHbDm5Bl8f66Kjp/63kRkbDnI+JxdfH6FxbDi1y1t/TIgInwx1yf2N161E3HmvlMc7uN465bVrNgRFWOfnNVC8R0oC/Phn2LuY3Eot2BH/CgtPlmd5QgoJx9JZMborPj7CJz8nkHLmPG2rR9GyWiShLhx01zvvlSop8gfKjS9Aqwc1ULxITq6BMtXxHTqdFdPHUmvD69RO7svSnF6cibqX3o1iyMjKITTQjwc713C63GuiwaKUO9JA8Vq5uYbth0+xIiGFlXtT+HVvKp8Oi6d19Sj8mg3mP7lNuev0BB5M/B8Psglqvw2BDZwuu0A0WJRyJwc3WGMoO2dBUDjc8AK0Hml9rTySMYZz2bkE+fuy52g6Az9ezsmMLADiokLo06Qi4SH+ALSMi6RlXDugHex/AH74E0wZBPX6Qq83oXQlB9/JtdNgUcodaKB4DWMMiSkZLE84bvdKUrm1WSX+7+b6VIkMoUf9CrSuHknbGlFUDL/CBJVV2sCDS2DFh9bPRkIru+c64neD++5IB++VctKhjdYpr50/WiHS9lFo/aAGiodJO5tFeLDV6+j9/lK2HToFQPnSgbStHsXNjSvRrX75wr9A6j748S/WujmVmll37ldq6orSL3Ll4L0Gi1JO0EDxaIfSzlp3ttt3t/v7+rDoqS4AfLp0L0H+vrSrEUW16FKum5/QGNg6DX56Ds4cg9YPwQ3Pu+zeJb0qTClPdWiTdVpjx0wIDIcuz1uBEhzhdGXqCo6dPkd0aAAiwmuztvPJkr0AhAf706Z6JG2rR5Gba/DxER7oWL1oihCBhrdBja6w4BVYORa2fW+NvdTrUzSvWUgaLEoVh5P7rb80NVA8wokz51m5N+XiLMC7j6Yz/8+dqFkujM61y1I2LJA21aOoX7E0Pj7FPGN6cIS1xkuTIdakll/dBXVuht5vQrh7TAyrp8KUKmqbv4GZfwaTY93Y2PohDRQ3cyozC5ML4SH+LN19jKHjVwEQEuBLfFwk7WpEMaB5DOXC3GypiJwsq+ey+DVArFNjrR8C34L3GXSM5Qo0WJTbyEyDWU/Dpq+gcmsYMA7KxDldlQLOnMtmVWIqK+0xki3JaTzdoy6jutQgLSOLL1Ym0rZGFI1jI/AvohmAXerkfvjxKWsy0gqNoO/7ENOiQLvQYLkCDRblFvavhGkjIC0JOj8LHZ8q1F+RyjUys3I4dvoclSNDOJ+dS9NX5pJxPgd/X6FZ5TK0qRFFjwblaVDJgy+eMAa2z4DZz8Lpw9ZlyTe+cM0XhOjgvVLuKicblrxpTSoYXhnu+wmqtHa6qhLnXHYO6/efvHjV1ob9J2kUG863o9oR4OfD/91cj6qRpWhRtQzBAe59T8g1E4H6/aD6DbDwVVg1Drb/YM2aXL+f9XhxlaI9FqVcJHWf1UtJWm0NrPZ6U6dgKSZZObnsPHyahjHWX+cjJq1h3rYj1oVUlcJpWyOK9jWj6Vy7rMOVFqPktdad+4c3Qa0e0PstKFP1spvrqbAr0GBRxc4Ya2XAWU+B+FpX7DQa6HRVXi0317DlYBrL7XtJViemknE+h7Uv3ERUaCDLE46TnplN62pRF6dLKZFysmHVJ7DwH4CBLqOhzcPg+8djosFyBRosqlidPWFd8bV1GlRtD7d+AhGVna7K641fto+/z9wGQM1yobSrEUXb6lF0qVPOe05tuVJakjX2smMmlGsAfd+Dyr9fTVLHWJRyB4nLYNqDkH7YWqCp/Z/cfg4nT3Y6M4uDJzOpUyGMO1tVITzYn061o93vEmB3FB4Lg7+E7TNh9jMwvjvE3wddXyySS9894Do6pdxM9nmY/zJM7AN+gTB8LnT8i4ZKETHGMGvzIW5652dGTV5LTq4hOMCXgS1iNVQKql4feORX63TY2onwYUvrPisXn7nSHotSBXF8D0x7wFovpfk90OM1CAx1uiqvdSA1g799v4VFO49Rv2Jp/jmg0cVlelUhBYZBz39C4zusO/e/HQ4b/uvSl9BgUepaGAPrJsFPo61eyh1fQP1bnK7Kq207eIoBY3/BR4QXbq7Hve3i8POEmxU9RaWm8MACWP0pLPi7S3etwaLU1WSkwozHrIHPap3h1o89ZsElT3Qy4zwRIQHUrRDGfe2rcXebqsREXGHdElV4Pr7WnHX1+sL/xbhut1fbQEQmiMhREdmSp+12EdkqIrkiEp+nvZuIrBWRzfbnG/M81sJu3yMiH4g9l7SIRIrIPBHZbX8uY7eLvd0eEdkkIs1d9q6VulYJi2BsO9g1B7q/CkOna6gUkbSMLJ6btpkuby/mePo5fHyEZ3vW1VApDi7+mb6WfuVEoGe+ti3AAGBJvvbjQF9jTCNgGPBFnsfGAiOBWvbHhX2OBhYYY2oBC+zvAXrl2Xak/Xylikf2OZjzf/BFf+uc9IgF1gSSPnoqxtWMMUxfn0zXdxbz9ZoDDGweS7C/Xgjhya56KswYs0RE4vK1bQf+sICNMWZ9nm+3AkEiEghEAqWNMSvs500C+gOzgX5AF/s5nwOLgWft9knGutFmpYhEiEhFY8yhAr1DpQrq2E5rQPPwZogfbvVUAkKcrsorZWbl8MDna1i25zhNKkfw+f0NPXu+LgUU7RjLbcB6Y8w5EYkBkvI8lgRcOKFX/kJYGGMOiUg5uz0GOHCJ5/whWERkJFavhipVqrj0TagSxBhYM97qqQSUgiFToU4vp6vySsYYRIQgf18qR4bw934NuLN1Vb3iy0sUSb9eRBoAbwAPXmi6xGZXu3D6mp9jjBlnjIk3xsSXLVuC5gJSrpN+DKYMttYVr9oeRq3QUCkiKxJS6PX+UnYfOQ3AawMaMbRtnIaKF3F5j0VEYoHvgHuMMQl2cxKQd2mzWOCg/fWRC6e4RKQicDTPcypf5jlKuc7u+TB9lLV+Ss83oNVIHUspAinp5/jHrO1MW5dMlcgQTmVmOV2SKiIuDRYRiQB+BJ4zxvxyod0OjdMi0gb4FbgH+Lf98Aysgf7X7c/f52l/VESmAq2BNB1fUS6VlQnzX4RfP4Zy9eGe6VC+gdNVeaVv1ybx9x+3ceZcNo/cUIPHbqxFkA7Qe62rBouITMEaXI8WkSTgRSAVKxjKAj+KyAZjTA/gUaAm8FcR+au9i+7GmKPAKKwrzIKxBu1n24+/DnwtIsOB/cDtdvssoDewB8gA7ruud6pUXke2wrcPwNFt0HoU3PQS+Ov0IEVl99F0apcL4x+3NqRW+TCny1FFTGc3ViVLbq41jfi8F62V9fqPhVo3OV2V18nMyuHfC3fTtno0HWpFcz47Fz8fwUfHUdyWzm6sVGGcPgzTH4aEBVC7F/T7EEpFO12V1/l51zH+On0L+1Mz8BGhQ61oAvx0zKok0WBRJcOOWTDjUTh/Bm7+l3V/SjEu1VoSHD2VySsztzFz0yGqly3FlBFtaFsjyumylAM0WJR3O58Bc/8P1kyACo3gtvFQto7TVXml+duPMnfbEZ68qTYPdalOoJ8OzpdUGizKex3aaA3QH99lTcdy41+tmYmVy2w9mMbBk5l0q1+ewS0r07FWNJUjdZaCkk6DRXmf3FxY8SEseMUaQxk6HWrc4HRVXuXMuWzenbeLz5YnEhcVwo11y+HrIxoqCtBgUd7m1EH47kHYtwTq9oFb/g0hkU5X5VXmbj3MSzO2cjAtkyGtqjC6Z129a179jgaL8h7bvocZj0POeStQmg3VAXoX25R0kpFfrKVO+TC+vbMZLapqaKs/0mBRnu9curWy4/ovoFIzGPApRNd0uiqvkZ2Ty4YDJ4mPi6RxbASfDG3BjXXL4a+rOarL0GBRni15rTVAn7oPOv4FujwHvv5OV+U1Nhw4yfPTNrP76GkW/qULlSND6NGggtNlKTenwaI8U24OLHsXFr8GoRXg3pkQ18HpqrzGqcws3p6zky9W/ka5sEDeH9yM2DK6kqO6NhosyvOc3A/THoT9y6HBAOjzDgSXcboqr5GZlUOv95ZyMO0sw9rG8ZfutQkL0l6gunYaLMqzbP4GZv4ZTC7c+gk0HqQD9C6Skn6OqNBAgvx9eahLDZrEhtM4NsLpspQH0tE35RkyT1m9lG+HW3fOP7QUmgzWUHGBrJxcPlq8h/ZvLGTp7mMADG1TVUNFFZr2WJT72/8rTBsBaQeg82jo9DT46o+uK6xJTOX57zaz60g6PRqUp2a5UKdLUl5A/3cq95WTDUvegiVvQngs3PcTVGntdFVe4x8/buM/S/cRExHMp/fEc1P98k6XpLyEBotyT6n7YNpISFoFjQdD77cgqLTTVXm8C+sviQjVy4YyslN1nuhai1KB+qtAuY7+NCn3YgxsnAqzngbxsWYjbjTQ6aq8wt5j6bwwfQu3NKnE4FZVGNKqitMlKS+lwaLcx9kT1hVfW6dBlXYw4BOI0F9+1yszK4exixMYuziBQH8fbmse63RJystpsCj3kLjMuuor/bA1vX2HJ8FH1/O4XqsTU3n2m03sPX6GW5pU4oU+9SgXFuR0WcrLabAoZ+VkWXfPL30HIqvB/XMhtoXTVXmN9HPZ5BjDpPtb0al2WafLUSWEBotyTkqCdV/KwfXWTMQ9X4dAvdz1euTmGr5ec4CTZ7N4qHMNbqhTjvZP6przqnhpsKjiZ4w1E/HsZ8E3AO6YBPX7OV2Vx9t15DTPT9vMmt9O0LFWNCM7VsfHRzRUVLHTYFHFKyMVfngctv8AcR2taVnCY5yuyqOdPZ/DBwt3858lewkL8uOtgY0Z2CIW0VkJlEM0WFTx2bsYvnsIzhyHbq9A28fAR/+avl77UzP4dOle+jeL4fne9YgsFeB0SaqE02BRRS/7HCx8FZb/G6JqwpCpUKmp01V5tCOnMpmz9TD3tI2jToUwFj3Vhdgyut68cg8aLKpoHdtpLcR1eBPE3w/d/wEB+guwsHJyDZNX/sZbc3aSlZNL13rliYkI1lBRbkWDRRUNY2DNBJjzf1aQDJ4CdXs7XZVH25KcxvPfbWZTUhoda0Xz934NiYnQxbeU+9FgUa535jh8/yjsmg01boT+YyFMl7O9HmfP5zB0/K/4+vjw/uCm3NKkkg7OK7elwaJca/d8mD4KMk9a96W0elAH6AvJGMOKhBTaVI8iOMCXsXe3oF7F0oQH62qOyr3p/3jlGlmZMHs0fHkbhETBiEXQZpSGSiElnchgxKQ13Pnpr/y4+RAAbapHaagoj6A9FnX9jmy1BuiPboPWD8FNL4G/nvsvjOycXD77JZF35u0C4LledenZUE8jKs+iwaIKzxj49ROY9zcICoe7voFa3ZyuyqM9/OU65m47Qte65Xi5XwO92kt5JA0WVTinj8D3D8Oe+VC7J9zyIYTqJIeFcSoziwBfH4L8fRnWLo4BzWPo0aCCDs4rj6XBogpu52z4/hE4fwZu/hfEDwf9JVhgxhhmbjrEKzO3MSi+Mk/1qEP7mtFOl6XUdbvqyKqITBCRoyKyJU/b7SKyVURyRSQ+3/bPicgeEdkpIj3ytPe02/aIyOg87dVE5FcR2S0iX4lIgN0eaH+/x348zhVvWF2H8xnWQlxTBkNYJRj5M7R8QEOlEPanZDDss9U8NmU9FUoH0aOBjqMo73Etl+xMBHrma9sCDACW5G0UkfrAYKCB/ZyPRMRXRHyBMUAvoD4wxN4W4A3gXWNMLeAEMNxuHw6cMMbUBN61t1NOObQRxnWGNeOh7aMwYgGUq+t0VR5p+vpkur37M+t+O8FLfesz/ZH2NIoNd7ospVzmqqfCjDFL8vcWjDHbgUudA+4HTDXGnAP2icgeoJX92B5jzF77eVOBfiKyHbgRuNPe5nPgJWCsva+X7PZvgA9FRIwx5trfnrpuubmw4kNY8Ip1GfHQ6VDjBqer8kg5uQZfH6FuxTBuql+ev95cnwrhupqj8j6uHmOJAVbm+T7JbgM4kK+9NRAFnDTGZF9i+5gLzzHGZItImr398fwvKiIjgZEAVaroGukuc+qgNYsVcQ4AABk7SURBVBvxvp+hbh+45d8QEul0VR4nJ9fwzrydHDyZybuDmlK3QmnG3Nnc6bKUKjKuvnvtUifbTSHar7SvPzYaM84YE2+MiS9bVq9Mcol9S2Bse0haDX0/gEGTNVQKIS0ji/snrmbMogQC/XzIzdUOt/J+ru6xJAGV83wfCxy0v75U+3EgQkT87F5L3u0v7CtJRPyAcCDVxfWq/IyB1Z9aqztG1YDB/4XoWk5X5ZF2HD7Fg1+s5eDJs/zz1kbc2Vp706pkcHWPZQYw2L6iqxpQC1gFrAZq2VeABWAN8M+wx0sWAQPt5w8Dvs+zr2H21wOBhTq+UsSyz8MPT8Csp6wbHR9YoKFSSOeyc7jvs9VknM9h6sg2GiqqRLlqj0VEpgBdgGgRSQJexOo5/BsoC/woIhuMMT2MMVtF5GtgG5ANPGKMybH38ygwB/AFJhhjttov8SwwVUReBdYD4+328cAX9gUAqVhhpIpK+jH4eijsXwEd/gw3vgA+vk5X5XFycg0+AoF+vrw/uBlVo0IoX1oH6FXJIt7WCYiPjzdr1qxxugzPcmgjTLkTMlKg34fQaODVn6P+4MSZ8zw2ZT2dakczslMNp8tRqkBEZK0xJv7qW16dTj1b0m35Fsb3AAzc/5OGSiFtPZhG3w+XsWpfKhHBuua8Ktl0SpeSKjcXFr0KS/8FldvAoC8gtJzTVXmk7zck8+y3m4gIDuDrh9rStHKE0yUp5SgNlpIo8xRMG2mt8Nj8Huj9NvgFOl2VR9p3/AxPfrWB+KqRjLmrOWXD9DgqpcFS0qQkwJQhkLLHChSd66tQzmXnEOjnS7XoUnwxvDWtqkXi76tnlpUCHWMpWRIWwn9uhDNHYeh30GqEhkohbE5Ko+u/fmbRzqMAtK8ZraGiVB76v6EkMAZWjIHJt0HpStaywdU7O12VR/p2bRK3fbyc3FxDVCkdpFfqUvRUmLfLPgczn4QNX1rzfd36MQSGOV2Vx8nKyeUfP25n4vJE2lSPZMydzYkK1fEUpS5Fg8WbnT4MX91tzffV+VnoPBp8tJNaGLO3HGbi8kSGd6jGc73q4qenvpS6LA0Wb5W8FqbeBZlpcMckqN/P6Yo8Usb5bEIC/OjbuCIVw4NoGacTcSp1Nfpnlzfa+BVM6AU+/jB8roZKIX21ej8d31hEwrF0RERDRalrpD0Wb5KbA/NfhOX/hqod4I7PoZSuoV5Q57NzefmHrXz563461IymTIgO0itVEBos3uLsSfh2OOyZb92b0vN18PV3uiqPc/RUJqO+XMfa307wYOfqPN29jo6nKFVAGize4PhumDIYTiRCn/cg/j6nK/JY45bsZdvBU3x4ZzP6NK7kdDlKeSQNFk+3a67VU/ENgGE/QNV2TlfkkdLOZhEe7M9TPeowuFVlapbTS7KVKizt43sqY2DZe/DfO6BMVRi5SEOlEM5l5/DctE30H/MLpzOzCPL31VBR6jppj8UTZZ2FGY/D5q+hfn/o/xEElHK6Ko9zOC2TUV+uZf3+kzxyQw1CAvS/g1KuoP+TPE1aMnx1Fxxcb63y2PEpne+rEFYnpjJq8joyzmcz9q7m9GpU0emSlPIaGiye5MAq66bHrAwYPAXq9na6Io9kjOGtOTsJC/LjvyNaU7u8nvpSypU0WDzF+snWnF+lY2DYDChXz+mKPE5mVg7nsnMJD/bnwzubEejnS3iwXpKtlKtpsLi7nGyY+wL8Ohaqd4GBn0GI3gFeUAdPnuWhyWspExLAxPtaUi4syOmSlPJaGizuLCMVvrkP9i6G1qOg+6vgq/9kBbVybwqPfLmOc9m5vHNHTUTHpJQqUvpbyl0d3W6t9HgqGfqNgWZ3O12RxzHG8Nkvifxj1nbiokL4ZGg8NcuFOl2WUl5Pg8Ud7fjRWpPePwTu/REqt3K6Io90KjObcUv20rVuOf51RxPCgnQ8RanioMHiToyBpW/DwlehYlMY/F8Ij3G6Ko9zOC2T6NAAwoP9mfZwOyqUDsLHR09/KVVc9M57d3H+DPzvXitUGt0O9/+koVIIv+w5Tq/3l/Du/F0AVIoI1lBRqphpj8UdnNwPU++Ew1ug2yvQ7nG96bGAjDF8unQfr83eTo2yoQxsUdnpkpQqsTRYnPbbcvhqKOSchzu/htrdna7I42Scz+bZbzfzw8aD9GpYgbdub0JooP5oK+UU/d/npDUTYNbTUCbOupO+bG2nK/JIv6VksGD7EZ7pWYdRnWvo5cRKOUyDxQk5WTD7WVgzHmreBLeNh+AIp6vyOHuOplOzXCj1KpZmyTM3EB0a6HRJSil08L74nTkOk/pbodLucev0l4ZKgRhjGLs4ge7v/sxPWw4BaKgo5Ua0x1KcDm+GKXdC+hG4dRw0GeR0RR7nzLlsnv5mI7M2H6ZP44p0ql3W6ZKUUvlosBSXbd/Ddw9BUDjcPxtiWjhdkcfZd/wMD36xhj1H03m+d11GdKyu4ylKuSENlqKWmws/vw4/vwGxLWHQZAir4HRVHmlLchrHTp9j0v2t6VAr2ulylFKXcU1jLCIyQUSOisiWPG2RIjJPRHbbn8vY7eEi8oOIbBSRrSJyX57nDLO33y0iw/K0txCRzSKyR0Q+EPvP0Mu9hsc4dxq+HmqFStO7YNhMDZUCys01bElOA6Bvk0osfvoGDRWl3Ny1Dt5PBHrmaxsNLDDG1AIW2N8DPAJsM8Y0AboA/xKRABGJBF4EWgOtgBfzBMVYYCRQy/7oeZXXcH+p+2B8d9g5C3q8Zk0k6a9TtRfE6cwsHpq8lgEfLWfvsXQAXT9FKQ9wTcFijFkCpOZr7gd8bn/9OdD/wuZAmN3rCLWflw30AOYZY1KNMSeAeUBPEakIlDbGrDDGGGBSnn1d7jXc296f4T83wKmDcPe30PZhvZO+gBKOpdN/zC8s2HGU0b3qUi26lNMlKaWu0fWMsZQ3xhwCMMYcEpFydvuHwAzgIBAGDDLG5IpIDHAgz/OTgBj7I+kS7Vd6DfdkDKz6D/w0GqJqwpApEFXD6ao8zrxtR3jyqw0E+PkweXhr2taIcrokpVQBFMXgfQ9gA3AjUAOYJyJLgUv9yW6u0H7NRGQk1qk0qlSpUqBiXSb7PMz6C6ybBLV7wYBxEFTamVo83Pr9J6gWXYqPh7YgJiLY6XKUUgV0PTdIHrFPY2F/Pmq33wdMM5Y9wD6gLlZPJO/MgLFYvZok++v87Vd6jd8xxowzxsQbY+LLlnXgvob0o/B5XytUOv7Fmu5eQ6VATmVmsf3QKQD+0r0O/3uorYaKUh7qeoJlBnDhyq5hwPf21/uBrgAiUh6oA+wF5gDdRaSMPWjfHZhjn+o6LSJt7HGZe/Ls63Kv4T4OboBxXeDQRhg4Abr+DXx0QoOC2H3kNP0+/IXhE1dzLjsHXx8hyN/X6bKUUoV0TafCRGQK1hVe0SKShHV11+vA1yIyHCtMbrc3/zswUUQ2Y53metYYc9zez9+B1fZ2rxhjLlwQMArryrNgYLb9wRVewz1s/ga+fxRComD4HKjYxOmKPM5PWw7xl683Ehzgy0d3tSDQTwNFKU8n1oVY3iM+Pt6sWbOmaF8kNwcW/h2WvQtV2sIdkyDUva8rcDc5uYZ35u1kzKIEmlSO4OO7m1MxXE99KeUUEVlrjIl3xb70zvuCyjwF3z4Au+dAi3uh11vgF+B0VR5HgB2HTjO4ZWVe7tdAeypKeRENloJISYApQyBlD/R+G1o+oPenFNDOw6cJDfIjJiKYsXe3IMBPx6OU8jb6v/pa7Vlg3fR45hjc8z20GqGhUkA/bjrErR/9wt+mWzMDaago5Z20x3I1xsCKMTDvr1C2Hgz5r7Xio7pmObmGN+fs4JOf99K8SgT/HNDI6ZKUUkVIg+VKsjJh5pOw8b9Qry/0/xgCQ52uyqOkZWTx6JR1LN19nLtaV+HFvg20p6KUl9NguZxTh+CruyF5DXR5Djo9o/enFIKvr5CSfp7XBzRicCuHZkVQShUrDZZLSVoLU++0pr2/4wuof4vTFXmc+duO0L5mNKGBfvzwWAd8fXQ8SqmSQv8Ez2/jVPisl3UJ8fC5GioFlJ2Ty6szt/HApDWMX7YXQENFqRJGeywX5GTD/BdhxYcQ1xFu/xxK6ay6BZGSfo7HpqxneUIK97aL48HOOrOzUiWRBgvA2RPwzXBIWAAtR0DP18BXF5QqiG0HTzFi0hqOpZ/j7dubMLBF7NWfpJTyShosx3bBlMFwcj/0fd+6m14VWKlAX0oH+zP27uY0jo1wuhyllINK9hjLrrnwaVfITINhP2ioFFBWTi5frzmAMYaqUaWY9XgHDRWlVAntsRgDv7wH81+GCo2s9VMiKl/9eeqiY6fP8ch/17FqXyqxEcG0qxmN6EwESilKYrCcz4AZj8GWb6DBAOg3BgJCnK7Ko2w8cJKHJq/lRMZ53hvUlHY1o50uSSnlRkpWsKQlW/enHNpoLcjV4c8631cBfb8hmae/2UTZ0EC+eagdDWPCnS5JKeVmSk6w7P/VupM+6ywMmQJ1ejldkUeKDg2kTfUo3hvUlMhSulyAUuqPSkawrJsEM/8M4bHWIH25uk5X5FGOns5k2e7jDGgeS/ua0bSrEaXjKUqpy/LuYMnJhjnPw6pPoPoN1pr0IZFOV+VR1v52glGT13LmXDadapclOjRQQ0UpdUXeGywZqfC/YbBvCbR5BLq9Ar7e+3ZdLeN8NlNXHeC12dupGB7MpOGtiA4NdLospZQH8M7ftEe2wdQhcOog9PsImt3ldEUexRhDj/eWcCD1LJ1rl+X9wU2JCNHxFKXUtfG+YMlMg/HdIKAU3DsLKrd0uiK3t/vIaaatT2Zt4gmmjmyDj4/wVPc6VCgdRMu4SHx0EkmlVAF4X7Ck7oXoTjD4Syhdyelq3FZK+jm+33CQaeuT2JJ8Cl8foXPtspzKzCIiJIB+TWOcLlEp5aG8L1hCIuG+WeAf7HQlbiczK4fzObmUDvJn3f6TvDJzGw1jSvO3PvXp26QSZcN0DEUpdf28L1giqmqo5JGba1idmMq0dcnM2nyI+9rH8efudehcuyxzn+xE7fJhTpeolPIy3hcs6qJ/L9jN1NUHSD55lpAAX3o2rECn2mUBCPDz0VBRShUJDRYvcuLMeX5JOE6fxtbY0o4jp6lethRP96hD9wblCQnQf26lVNHT3zQe7lx2Dgu3H2Xa+mQW7zxKVo6hSWwElSND+GBwM10WWClV7DRYPNiqfamMmLSGtLNZlA0L5N52cdzaLJbKkdZszRoqSiknaLB4kP0pGXy3Ppka5UrRp3El6pQP48a65ejfLIb2NaLw8y3Z67YppdyDBoubS8vI4sfNh/hufRKrE08gAve2i6NP40qEh/jz7qCmTpeolFK/o8HihnJzzcW73Ud+sYZf96VSs1woz/SsQ/+mMVSK0MuplVLuS4PFTRhj2JSUxrR1SczZeoSf/tSRiJAAnupRhyA/XxrGlNZZhZVSHkGDxWEp6eeYuvoA365LYu+xMwT4+dCtfnlOZ2YTERJAyzid5l8p5Vk0WBxwOjOLU5nZxEQEcyozm7fm7KRVXCQjO1anV6OKhAf7O12iUkoV2lWDRUQmAH2Ao8aYhnZbJPAVEAckAncYY07Yj3UB3gP8gePGmM52e0/gfcAX+NQY87rdXg2YCkQC64ChxpjzIhIITAJaACnAIGNMoivetBOyc3JZuuc409YlM3frYbrWK8dHd7WgWnQpVj7XlQrhQU6XqJRSLnEt16dOBHrmaxsNLDDG1AIW2N8jIhHAR8AtxpgGwO12uy8wBugF1AeGiEh9e19vAO/a+zoBDLfbhwMnjDE1gXft7TzSJz8n0Oa1hdz32WqW7j7GHfGVGdmpxsXHNVSUUt7kqj0WY8wSEYnL19wP6GJ//TmwGHgWuBOYZozZbz/3qL1NK2CPMWYvgIhMBfqJyHbgRvt5F/b1EjDWfo2X7PZvgA9FRIwxpgDvzxGH0zKZuekgw9rF4e/rw/nsXFpUjWBA81huqFOOAD+930Qp5b0KO8ZS3hhzCMAYc0hEytnttQF/EVkMhAHvG2MmATHAgTzPTwJaA1HASWNMdp72CwuBXHyOMSZbRNLs7Y/nL0ZERgIjAapUqVLIt3R9zpzLZs7Ww0xbl8wvCccxBhrGhNOmehSPda3lSE1KKeUEVw/e+2GNiXQFgoEVIrISuNR1suYK7Vzlsd83GjMOGAcQHx9f7D2avcfS6fPvZWScz6FyZDCP3ViLW5vFUC26VHGXopRSjitssBwRkYp2b6UicOGUVxLWgP0Z4IyILAGa2O2V8zw/FjiI1fuIEBE/u9dyoZ08z0kSET8gHEgtZL0utfPwaaatTyI0wI/HutYiLqoUQ9tU5ab65YmvWkbvN1FKlWiFDZYZwDDgdfvz93b791hjIX5AANbprneBHUAt+wqwZGAwcKcxxojIImAg1pVhefd14TVW2I8vdHJ85ejpTGZsOMh365PZevAUfj5C/2bWWTsfH+G53vWcKk0ppdzKtVxuPAVroD5aRJKAF7EC5WsRGQ7sx776yxizXUR+AjYBuViXFW+x9/MoMAfrcuMJxpit9ks8C0wVkVeB9cB4u3088IWI7MHqqQy+/rdbMJlZOQT6+SAivD1nJ1+vSaJxbDgv9bWW8o0K1aV8lVIqP/GAi6wKJD4+3qxZs6bQz8/NNfy6L5Vp65KYveUwU0a0oVFsOInHz5Cdm0vNcrrqolLK+4jIWmNMvCv2pXfe29LOZjFuSQLT1x8k+eRZSgX40rtRRYIDfAGI04F4pZS6JiU6WFLPnOfgybM0jAkn0M+HySv306xKBM/0rEP3+hUuhopSSqlrV+KCJTMrh4U7jjJtnbWUb1x0KeY92Ykgf19WPHejrguvlFLXqUT9Fv1iRSJvzdnJqcxsyoUFMrxDNW5tHnPx8mANFaWUun5e/Zs08fgZvlufzOBWlakYHkzZsEC61ivPgOYxtKsRrWvCK6VUEfC6YMnJNUxe+RvT1iWxbv9JRKB62VL0axpDz4YV6dmwotMlKqWUV/O6YNlx+DQvTN9C7fKhjO5Vl35NK1ExXJfyVUqp4uJ1wVIxPIgZj3WgQSVdylcppZzgdcESWSqAhjHhTpehlFIlli4MopRSyqU0WJRSSrmUBotSSimX0mBRSinlUhosSimlXEqDRSmllEtpsCillHIpDRallFIu5XUrSIrIaWCn03V4kWjguNNFeAk9lq6lx9O16hhjXLJErtfdeQ/sdNXymgpEZI0eT9fQY+laejxdS0QKv6Z7PnoqTCmllEtpsCillHIpbwyWcU4X4GX0eLqOHkvX0uPpWi47nl43eK+UUspZ3thjUUop5SANFqWUUi7l9sEiIpVFZJGIbBeRrSLyhN0eKSLzRGS3/bmM3S4i8oGI7BGRTSLSPM++ckRkg/0xw6n35CQXH88qIjLX3tc2EYlz5l05x1XHU0RuyPOzuUFEMkWkv5Pvrbi5+GfzTXsf2+1tStxysi4+nm+IyBb7Y9BVX9wY49YfQEWguf11GLALqA+8CYy220cDb9hf9wZmAwK0AX7Ns690p9+P0x8uPp6LgW7216FAiNPvz5OPZ559RgKpJe14uupYAu2AXwBf+2MF0MXp9+fBx/NmYB7WfY+lgDVA6Su9ttv3WIwxh4wx6+yvTwPbgRigH/C5vdnnwIW/7voBk4xlJRAhIhWLuWy35arjKSL1AT9jzDx7X+nGmIzifC/uoIh+PgcCs0va8XThsTRAEBAABAL+wJFieyNuwoXHsz7wszEm2xhzBtgI9LzSa7t9sORln2ppBvwKlDfGHALrAALl7M1igAN5npZktwEEicgaEVlZ0k4zXMp1Hs/awEkRmSYi60XkLRHxLa7a3ZELfj4vGAxMKcpa3d31HEtjzApgEXDI/phjjNlePJW7p+v82dwI9BKREBGJBm4AKl/p9TxmShcRCQW+Bf5kjDl1hVOml3rgwjXVVYwxB0WkOrBQRDYbYxKKoFy354Lj6Qd0xPph3Q98BdwLjHd5sR7ART+f2H8hNgLmuLxID3G9x1JEagL1gFi7bZ6IdDLGLHF9te7veo+nMWauiLQElgPHsE4tZl/pNT2ixyIi/lgH5ktjzDS7+ciFUwj256N2exK/T9NY4CCAMebC571Y4wPNirx4N+Si45kErDfG7DXGZAPTgeaUQK76+bTdAXxnjMkq2qrdk4uO5a3ASvv0bDrWuEGb4qjf3bjwd+c/jDFNjTHdsAJo95Ve1+2Dxb6aYzyw3RjzTp6HZgDD7K+HAd/nab/HvsKhDZBmjDkkImVEJNDeZzTQHthWLG/CjbjqeAKrgTIiUtbe7kb0eF7P8bxgCCX0NJgLj+V+oLOI+Nm/WDtjjS+UKC783ekrIlH2PhsDjYG5V3zxor4y4Xo/gA5Ypwo2ARvsj95AFLAAKzkXAJH29gKMARKAzUC8+f9XimzGOl+4GRju9Hvz5ONpP9bN3s9mYCIQ4PT78/DjGQckAz5Ovy9PPpZYV4J9ghUm24B3nH5vHn48g+zjuA1YCTS92mvrlC5KKaVcyu1PhSmllPIsGixKKaVcSoNFKaWUS2mwKKWUcikNFqWUUi6lwaKUUsqlNFiUUkq51P8Dedkz0kPuhY8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mape = []\n",
    "for i in range(len(time_series_training)):\n",
    "    y_pred = predictor.predict(ts=time_series_training[i], quantiles=[0.10, 0.5, 0.90])\n",
    "    y_true = time_series[i].iloc[-5:]\n",
    "\n",
    "    y_pred['0.5'].plot(ls='--', label='Prediction')\n",
    "    y_true.plot(label='Real')\n",
    "    plt.legend()\n",
    "    plt.savefig('img/test_{}.png'.format(i))\n",
    "    plt.show()\n",
    "    \n",
    "    mape.append(np.mean(np.abs(y_true.values - y_pred['0.5'].values) / y_true.values) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "everyday-seating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 2.29\n"
     ]
    }
   ],
   "source": [
    "plt.boxplot(mape)\n",
    "plt.title('MAPE')\n",
    "plt.savefig('img/mape.png')\n",
    "plt.show()\n",
    "\n",
    "print('MAPE:', round(np.median(mape), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "breathing-operation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>122429.109375</td>\n",
       "      <td>141921.359375</td>\n",
       "      <td>132076.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31</th>\n",
       "      <td>123865.843750</td>\n",
       "      <td>143472.203125</td>\n",
       "      <td>133392.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31</th>\n",
       "      <td>128492.687500</td>\n",
       "      <td>150618.406250</td>\n",
       "      <td>137946.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>123744.898438</td>\n",
       "      <td>157388.984375</td>\n",
       "      <td>139159.734375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31</th>\n",
       "      <td>124980.335938</td>\n",
       "      <td>157654.203125</td>\n",
       "      <td>143928.046875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0.1     Prediction            0.5\n",
       "2020-12-31  122429.109375  141921.359375  132076.312500\n",
       "2021-12-31  123865.843750  143472.203125  133392.250000\n",
       "2022-12-31  128492.687500  150618.406250  137946.156250\n",
       "2023-12-31  123744.898438  157388.984375  139159.734375\n",
       "2024-12-31  124980.335938  157654.203125  143928.046875"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions\n",
    "y_pred = predictor.predict(ts=ts.co2, quantiles=[0.10, 0.5, 0.90])\n",
    "y_pred = y_pred.rename(columns={'0.9': 'Prediction'})\n",
    "y_pred "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-studio",
   "metadata": {},
   "source": [
    "# Deploy predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bronze-singing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>CO2 emissions</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1850-12-31</td>\n",
       "      <td>944.824000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1851-12-31</td>\n",
       "      <td>944.689000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1852-12-31</td>\n",
       "      <td>984.086000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1853-12-31</td>\n",
       "      <td>1025.620000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1854-12-31</td>\n",
       "      <td>1209.253000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>141921.359375</td>\n",
       "      <td>141921.359375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143472.203125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150618.406250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157388.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157654.203125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Year  CO2 emissions     Prediction\n",
       "0   1850-12-31     944.824000            NaN\n",
       "1   1851-12-31     944.689000            NaN\n",
       "2   1852-12-31     984.086000            NaN\n",
       "3   1853-12-31    1025.620000            NaN\n",
       "4   1854-12-31    1209.253000            NaN\n",
       "..         ...            ...            ...\n",
       "170 2020-12-31  141921.359375  141921.359375\n",
       "171 2021-12-31            NaN  143472.203125\n",
       "172 2022-12-31            NaN  150618.406250\n",
       "173 2023-12-31            NaN  157388.984375\n",
       "174 2024-12-31            NaN  157654.203125\n",
       "\n",
       "[175 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data for visualization\n",
    "ts_slice = ts['1850':].rename(columns={'co2': 'CO2 emissions'})\n",
    "\n",
    "viz = ts_slice.merge(y_pred[['Prediction']], how='outer', left_index=True, right_index=True)\n",
    "viz = viz.reset_index().rename(columns={'index': 'Year'})\n",
    "viz.iloc[-5, 1] = viz.iloc[-5].Prediction\n",
    "viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "psychological-niagara",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotly dashboard html file\n",
    "fig = px.line(viz, x='Year', y=viz.columns, title='Global carbon dioxide emission prediction - MAPE: {}%'.format(round(np.median(mape), 2)))\n",
    "\n",
    "fig.update_xaxes(\n",
    "    tickformat='%Y', \n",
    "    rangeslider_visible=True,\n",
    "    rangeselector=dict(\n",
    "        buttons=list([\n",
    "            dict(count=30, label='30 years', step='year', stepmode='backward'),\n",
    "            dict(step='all')\n",
    "        ])\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.write_html('website/file.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-algebra",
   "metadata": {},
   "source": [
    "Link: http://capstone-deploy.s3-website-sa-east-1.amazonaws.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "active-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
