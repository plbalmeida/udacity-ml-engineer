{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "described-insulin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import os\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import plotly.express as px\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.serializers import IdentitySerializer\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-nicaragua",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "recreational-contrast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso_code</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>co2</th>\n",
       "      <th>co2_growth_prct</th>\n",
       "      <th>co2_growth_abs</th>\n",
       "      <th>consumption_co2</th>\n",
       "      <th>trade_co2</th>\n",
       "      <th>trade_co2_share</th>\n",
       "      <th>co2_per_capita</th>\n",
       "      <th>...</th>\n",
       "      <th>ghg_per_capita</th>\n",
       "      <th>methane</th>\n",
       "      <th>methane_per_capita</th>\n",
       "      <th>nitrous_oxide</th>\n",
       "      <th>nitrous_oxide_per_capita</th>\n",
       "      <th>primary_energy_consumption</th>\n",
       "      <th>energy_per_capita</th>\n",
       "      <th>energy_per_gdp</th>\n",
       "      <th>population</th>\n",
       "      <th>gdp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1949</td>\n",
       "      <td>0.015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7663783.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1950</td>\n",
       "      <td>0.084</td>\n",
       "      <td>475.000</td>\n",
       "      <td>0.070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7752000.0</td>\n",
       "      <td>1.949480e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1951</td>\n",
       "      <td>0.092</td>\n",
       "      <td>8.696</td>\n",
       "      <td>0.007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7840000.0</td>\n",
       "      <td>2.006385e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1952</td>\n",
       "      <td>0.092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7936000.0</td>\n",
       "      <td>2.074235e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1953</td>\n",
       "      <td>0.106</td>\n",
       "      <td>16.000</td>\n",
       "      <td>0.015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8040000.0</td>\n",
       "      <td>2.201546e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23703</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2015</td>\n",
       "      <td>12.170</td>\n",
       "      <td>1.653</td>\n",
       "      <td>0.198</td>\n",
       "      <td>13.308</td>\n",
       "      <td>1.138</td>\n",
       "      <td>9.350</td>\n",
       "      <td>0.881</td>\n",
       "      <td>...</td>\n",
       "      <td>4.885</td>\n",
       "      <td>11.87</td>\n",
       "      <td>0.859</td>\n",
       "      <td>6.68</td>\n",
       "      <td>0.484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13815000.0</td>\n",
       "      <td>2.503057e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23704</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2016</td>\n",
       "      <td>10.815</td>\n",
       "      <td>-11.139</td>\n",
       "      <td>-1.356</td>\n",
       "      <td>12.171</td>\n",
       "      <td>1.356</td>\n",
       "      <td>12.542</td>\n",
       "      <td>0.771</td>\n",
       "      <td>...</td>\n",
       "      <td>4.703</td>\n",
       "      <td>11.92</td>\n",
       "      <td>0.850</td>\n",
       "      <td>6.55</td>\n",
       "      <td>0.467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14030000.0</td>\n",
       "      <td>2.515176e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23705</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2017</td>\n",
       "      <td>10.247</td>\n",
       "      <td>-5.251</td>\n",
       "      <td>-0.568</td>\n",
       "      <td>11.774</td>\n",
       "      <td>1.527</td>\n",
       "      <td>14.902</td>\n",
       "      <td>0.720</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14237000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23706</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2018</td>\n",
       "      <td>11.341</td>\n",
       "      <td>10.674</td>\n",
       "      <td>1.094</td>\n",
       "      <td>12.815</td>\n",
       "      <td>1.475</td>\n",
       "      <td>13.006</td>\n",
       "      <td>0.785</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14439000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23707</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2019</td>\n",
       "      <td>10.374</td>\n",
       "      <td>-8.521</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.708</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14645000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23708 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      iso_code      country  year     co2  co2_growth_prct  co2_growth_abs  \\\n",
       "0          AFG  Afghanistan  1949   0.015              NaN             NaN   \n",
       "1          AFG  Afghanistan  1950   0.084          475.000           0.070   \n",
       "2          AFG  Afghanistan  1951   0.092            8.696           0.007   \n",
       "3          AFG  Afghanistan  1952   0.092              NaN             NaN   \n",
       "4          AFG  Afghanistan  1953   0.106           16.000           0.015   \n",
       "...        ...          ...   ...     ...              ...             ...   \n",
       "23703      ZWE     Zimbabwe  2015  12.170            1.653           0.198   \n",
       "23704      ZWE     Zimbabwe  2016  10.815          -11.139          -1.356   \n",
       "23705      ZWE     Zimbabwe  2017  10.247           -5.251          -0.568   \n",
       "23706      ZWE     Zimbabwe  2018  11.341           10.674           1.094   \n",
       "23707      ZWE     Zimbabwe  2019  10.374           -8.521          -0.966   \n",
       "\n",
       "       consumption_co2  trade_co2  trade_co2_share  co2_per_capita  ...  \\\n",
       "0                  NaN        NaN              NaN           0.002  ...   \n",
       "1                  NaN        NaN              NaN           0.011  ...   \n",
       "2                  NaN        NaN              NaN           0.012  ...   \n",
       "3                  NaN        NaN              NaN           0.012  ...   \n",
       "4                  NaN        NaN              NaN           0.013  ...   \n",
       "...                ...        ...              ...             ...  ...   \n",
       "23703           13.308      1.138            9.350           0.881  ...   \n",
       "23704           12.171      1.356           12.542           0.771  ...   \n",
       "23705           11.774      1.527           14.902           0.720  ...   \n",
       "23706           12.815      1.475           13.006           0.785  ...   \n",
       "23707              NaN        NaN              NaN           0.708  ...   \n",
       "\n",
       "       ghg_per_capita  methane  methane_per_capita  nitrous_oxide  \\\n",
       "0                 NaN      NaN                 NaN            NaN   \n",
       "1                 NaN      NaN                 NaN            NaN   \n",
       "2                 NaN      NaN                 NaN            NaN   \n",
       "3                 NaN      NaN                 NaN            NaN   \n",
       "4                 NaN      NaN                 NaN            NaN   \n",
       "...               ...      ...                 ...            ...   \n",
       "23703           4.885    11.87               0.859           6.68   \n",
       "23704           4.703    11.92               0.850           6.55   \n",
       "23705             NaN      NaN                 NaN            NaN   \n",
       "23706             NaN      NaN                 NaN            NaN   \n",
       "23707             NaN      NaN                 NaN            NaN   \n",
       "\n",
       "       nitrous_oxide_per_capita  primary_energy_consumption  \\\n",
       "0                           NaN                         NaN   \n",
       "1                           NaN                         NaN   \n",
       "2                           NaN                         NaN   \n",
       "3                           NaN                         NaN   \n",
       "4                           NaN                         NaN   \n",
       "...                         ...                         ...   \n",
       "23703                     0.484                         NaN   \n",
       "23704                     0.467                         NaN   \n",
       "23705                       NaN                         NaN   \n",
       "23706                       NaN                         NaN   \n",
       "23707                       NaN                         NaN   \n",
       "\n",
       "       energy_per_capita  energy_per_gdp  population           gdp  \n",
       "0                    NaN             NaN   7663783.0           NaN  \n",
       "1                    NaN             NaN   7752000.0  1.949480e+10  \n",
       "2                    NaN             NaN   7840000.0  2.006385e+10  \n",
       "3                    NaN             NaN   7936000.0  2.074235e+10  \n",
       "4                    NaN             NaN   8040000.0  2.201546e+10  \n",
       "...                  ...             ...         ...           ...  \n",
       "23703                NaN             NaN  13815000.0  2.503057e+10  \n",
       "23704                NaN             NaN  14030000.0  2.515176e+10  \n",
       "23705                NaN             NaN  14237000.0           NaN  \n",
       "23706                NaN             NaN  14439000.0           NaN  \n",
       "23707                NaN             NaN  14645000.0           NaN  \n",
       "\n",
       "[23708 rows x 55 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# source: https://github.com/owid/co2-data\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/owid/co2-data/master/owid-co2-data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adult-collapse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23708 entries, 0 to 23707\n",
      "Data columns (total 55 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   iso_code                             20930 non-null  object \n",
      " 1   country                              23708 non-null  object \n",
      " 2   year                                 23708 non-null  int64  \n",
      " 3   co2                                  23170 non-null  float64\n",
      " 4   co2_growth_prct                      21910 non-null  float64\n",
      " 5   co2_growth_abs                       22017 non-null  float64\n",
      " 6   consumption_co2                      3350 non-null   float64\n",
      " 7   trade_co2                            3318 non-null   float64\n",
      " 8   trade_co2_share                      3318 non-null   float64\n",
      " 9   co2_per_capita                       22383 non-null  float64\n",
      " 10  consumption_co2_per_capita           3350 non-null   float64\n",
      " 11  share_global_co2                     23103 non-null  float64\n",
      " 12  cumulative_co2                       23578 non-null  float64\n",
      " 13  share_global_cumulative_co2          23578 non-null  float64\n",
      " 14  co2_per_gdp                          14918 non-null  float64\n",
      " 15  consumption_co2_per_gdp              3088 non-null   float64\n",
      " 16  co2_per_unit_energy                  6743 non-null   float64\n",
      " 17  cement_co2                           12182 non-null  float64\n",
      " 18  coal_co2                             16991 non-null  float64\n",
      " 19  flaring_co2                          4302 non-null   float64\n",
      " 20  gas_co2                              8693 non-null   float64\n",
      " 21  oil_co2                              19711 non-null  float64\n",
      " 22  other_industry_co2                   1563 non-null   float64\n",
      " 23  cement_co2_per_capita                12153 non-null  float64\n",
      " 24  coal_co2_per_capita                  16471 non-null  float64\n",
      " 25  flaring_co2_per_capita               4301 non-null   float64\n",
      " 26  gas_co2_per_capita                   8665 non-null   float64\n",
      " 27  oil_co2_per_capita                   19393 non-null  float64\n",
      " 28  other_co2_per_capita                 1563 non-null   float64\n",
      " 29  share_global_coal_co2                16991 non-null  float64\n",
      " 30  share_global_oil_co2                 19711 non-null  float64\n",
      " 31  share_global_gas_co2                 8693 non-null   float64\n",
      " 32  share_global_flaring_co2             4302 non-null   float64\n",
      " 33  share_global_cement_co2              12182 non-null  float64\n",
      " 34  cumulative_coal_co2                  18552 non-null  float64\n",
      " 35  cumulative_oil_co2                   19963 non-null  float64\n",
      " 36  cumulative_gas_co2                   9187 non-null   float64\n",
      " 37  cumulative_flaring_co2               4933 non-null   float64\n",
      " 38  cumulative_cement_co2                12563 non-null  float64\n",
      " 39  share_global_cumulative_coal_co2     18552 non-null  float64\n",
      " 40  share_global_cumulative_oil_co2      19963 non-null  float64\n",
      " 41  share_global_cumulative_gas_co2      9187 non-null   float64\n",
      " 42  share_global_cumulative_flaring_co2  4933 non-null   float64\n",
      " 43  share_global_cumulative_cement_co2   12563 non-null  float64\n",
      " 44  total_ghg                            5208 non-null   float64\n",
      " 45  ghg_per_capita                       5155 non-null   float64\n",
      " 46  methane                              5211 non-null   float64\n",
      " 47  methane_per_capita                   5157 non-null   float64\n",
      " 48  nitrous_oxide                        5211 non-null   float64\n",
      " 49  nitrous_oxide_per_capita             5157 non-null   float64\n",
      " 50  primary_energy_consumption           6044 non-null   float64\n",
      " 51  energy_per_capita                    6044 non-null   float64\n",
      " 52  energy_per_gdp                       6044 non-null   float64\n",
      " 53  population                           21071 non-null  float64\n",
      " 54  gdp                                  13002 non-null  float64\n",
      "dtypes: float64(52), int64(1), object(2)\n",
      "memory usage: 9.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# data info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "recognized-scheme",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/ipykernel/__main__.py:3: FutureWarning:\n",
      "\n",
      "The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1750-12-31</th>\n",
       "      <td>46.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751-12-31</th>\n",
       "      <td>46.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752-12-31</th>\n",
       "      <td>46.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753-12-31</th>\n",
       "      <td>46.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754-12-31</th>\n",
       "      <td>46.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-31</th>\n",
       "      <td>123813.289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31</th>\n",
       "      <td>123890.716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>125438.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>127746.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>127568.915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   co2\n",
       "1750-12-31      46.755\n",
       "1751-12-31      46.755\n",
       "1752-12-31      46.770\n",
       "1753-12-31      46.770\n",
       "1754-12-31      46.790\n",
       "...                ...\n",
       "2015-12-31  123813.289\n",
       "2016-12-31  123890.716\n",
       "2017-12-31  125438.734\n",
       "2018-12-31  127746.944\n",
       "2019-12-31  127568.915\n",
       "\n",
       "[270 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group co2 feature by year\n",
    "ts = df[['year', 'co2']].groupby('year').sum()\n",
    "ts.index = pd.date_range(start=pd.datetime(ts.index.min(), 1, 1), periods=270, freq='A')\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mathematical-passage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# decompose time series in observed, seasonal, trend and residuals\n",
    "result = seasonal_decompose(ts.co2, model='multiplicative')\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "result.observed.plot(label='$CO^{2}$ emissions - observed')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "concerned-spring",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3AAAAD4CAYAAACt4QT/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAYq0lEQVR4nO3df7BedX0n8PcnEIyKIoTgD0IljmiBBEK4SagOgdVdCkhFZRZ1ZAG7gBYYd3F0wGn9Ra2d3f4YC8vChi1QsPJrLYijLQhb1qqgJCsoFCHRyS63cUoK2yAKYuC7f9wn9BLuzb033Nwnh+f1mjmTc77fc77ne575zn2ed77nOU+11gIAAMCOb1a/OwAAAMDkCHAAAAAdIcABAAB0hAAHAADQEQIcAABAR+zc7w5sac8992z77rtvv7sBAADQF6tXr/6n1tq8sep2uAC37777ZtWqVf3uBgAAQF9U1f8Zr84tlAAAAB0hwAEAAHSEAAcAANARO9x34AAAYHv61a9+leHh4Tz55JP97goDbs6cOZk/f35mz5496WMEOAAABsrw8HBe8YpXZN99901V9bs7DKjWWh555JEMDw9nwYIFkz7OLZQAAAyUJ598MnPnzhXe6Kuqyty5c6c8EyzAAQAwcIQ3dgTbMg4FOAAAgI4Q4AAAADpCgAMAAOgIAQ4AADrkxhtvzOmnn57jjz8+t9xyS7+7wwwT4AAAoE+uv/76LF++PAcddFDe+MY35rOf/WyS5Mtf/nKWL1+egw8+OENDQ7n55pufPeZd73pXLr300lxxxRW59tprt0u/3vKWt8zIMYNk1113nZZ2/A4cAAD0wV/8xV/kwgsvzI033pj58+fn8ccfz8UXX5wvfelLufDCC/OVr3wlr3nNa7JmzZocfvjhueuuu7LPPvs8e/znPve5nHXWWdulb9/5zndm5BimzgwcAADMsMceeywf/ehHc91112X+/PlJRmZozjzzzJx33nm57rrr8prXvCZJst9+++XII4/MbbfdlmTkB6DPPffcHHPMMVmyZMmY7X/xi1/MsmXLsnjx4nzoQx/K008/nXXr1uXXf/3Xc9ppp2XhwoX5wAc+kFtvvTVvfetbs99+++V73/ves8dvni36+c9/nne84x05+OCDs3Dhwlx77bVjlo0+Jkn+9E//NAsXLszChQvzhS98IUmybt267L///jn99NNz4IEH5qijjsoTTzwxbnuTNd7xY70GycgM5qGHHpoDDzwwK1eu3GobU7mOzcZqfzqZgQMAgBl2ww03ZPny5XnDG97wnPJrrrkmS5Ysec5MW5K85CUvycaNG5MkF154YW699dZs3Lgxa9euzYc//OHn7Hv//ffn2muvzbe//e3Mnj07Z555Zv7yL/8yK1asyNq1a3P99ddn5cqVWbp0ab70pS/lW9/6Vm666aZ8/vOfz4033victv7mb/4mr3vd6/K1r30tSbJx48Yxy0ZbvXp1Lr/88nz3u99Nay3Lly/PEUcckd133z1r1qzJ1VdfnUsvvTQnnnhivvzlL+elL33pVtubyFj9Ge81OPnkk3PZZZdljz32yBNPPJGlS5fmhBNOyO233/68NqZ6HSeddFKSjNn+3Llzp3RNWyPAAQAwsD771fvy9+sfm9Y2D3jdK/Pp3zpwq/vcd999Wbx48fPK77333hx88MHPK7/nnntyyimnJEk+8pGP5CMf+ci4bd92221ZvXp1li5dmiR54oknstdee2XFihVZsGBBFi1alCQ58MAD8/a3vz1VlUWLFmXdunXPa2vRokX52Mc+lnPPPTfHHXdcDj/88DHLRvvWt76Vd7/73Xn5y1+eJHnPe96Tv/u7v8s73/nOLFiw4NnrPvTQQ7Nu3bqceOKJW21vImP156qrrhrzNUiSCy64IDfccEOS5KGHHsqaNWvGbGOq17HZWO1PZ4BzCyUAAMywl7/85XnmmWeeV77bbrvlqaeeek7ZHXfckcceeyxHHHHEpNpureWUU07J3XffnbvvvjsPPPBAPvOZzyQZmcnbbNasWc9uz5o1K5s2bXpeW29605uyevXqLFq0KJ/4xCdy/vnnj1m25fnHM/r8O+20UzZt2jRhe0ly0UUXZfHixVm8eHHWr18/YR/Hew1uv/323Hrrrbnjjjtyzz335JBDDsmTTz45bhtTuY4k47Y/nczAAQAwsCaaKdtejj322Lzvfe/LOeeck1e/+tX55S9/mSuvvDLHHXdc3vve9+ajH/1o5s2blwcffDCnnXZaLr/88uy0006Tavvtb397jj/++JxzzjnZa6+98uijj+ZnP/vZNvVz/fr12WOPPXLSSSdl1113zRVXXDFm2WgrVqzIqaeemvPOOy+ttdxwww256qqrpnSOLZ111lnjPrBlrOM///nPj/kabNy4Mbvvvnte9rKX5Uc/+lHuvPPOcdv41Kc+NaXrSDJu+9NJgAMAgBm2dOnSfOYzn8lv/uZv5umnn86mTZty0kknZWhoKJ/85CefvbVxt912yyWXXDKl2woPOOCAfO5zn8tRRx2VZ555JrNnz85FF1307ENRpuKHP/xhPv7xj2fWrFmZPXt2Lr744jHLRluyZElOPfXULFu2LEly2mmn5ZBDDhnzFs3xzvFC+zjea3D00UfnkksuyUEHHZQ3v/nNOeyww8ZtY6rXkWTc9qdTbW1qsB+GhobaqlWr+t0NAABepO6///7sv//+/e4GJBl7PFbV6tba0Fj7+w4cAABARwhwAAAAHSHAAQAAdIQABwDAwNnRngPBYNqWcSjAAQAwUObMmZNHHnlEiKOvWmt55JFHMmfOnCkdN+HPCFTVZUmOS/Jwa23hGPWV5M+SHJvkF0lOba3971H1r0xyf5IbWmtnT6l3AAAwzebPn5/h4eFs2LCh311hwM2ZMyfz58+f0jGT+R24K5L8lyRXjlN/TJL9esvyJBf3/t3s95P8ryn1CgAAtpPZs2dnwYIF/e4GbJMJb6FsrX0zyaNb2eX4JFe2EXcmeVVVvTZJqurQJK9Ocst0dBYAAGCQTcd34PZO8tCo7eEke1fVrCR/kuTjEzVQVWdU1aqqWmUqGwAAYGzTEeBqjLKW5MwkX2+tPTRG/XN3bm1la22otTY0b968aegSAADAi89kvgM3keEk+4zanp9kfZLfSHJ4VZ2ZZNcku1TV462186bhnAAAAANnOgLcTUnOrqprMvLwko2ttZ8m+cDmHarq1CRDwhsAAMC2m8zPCFyd5Mgke1bVcJJPJ5mdJK21S5J8PSM/IbA2Iz8j8MHt1VkAAIBBNmGAa629f4L6luSsCfa5IiM/RwAAAMA2mo6HmAAAADADBDgAAICOEOAAAAA6QoADAADoCAEOAACgIwQ4AACAjhDgAAAAOkKAAwAA6AgBDgAAoCMEOAAAgI4Q4AAAADpCgAMAAOgIAQ4AAKAjBDgAAICOEOAAAAA6QoADAADoCAEOAACgIwQ4AACAjhDgAAAAOkKAAwAA6AgBDgAAoCMEOAAAgI4Q4AAAADpCgAMAAOgIAQ4AAKAjBDgAAICOEOAAAAA6QoADAADoCAEOAACgIwQ4AACAjpgwwFXVZVX1cFXdO059VdUFVbW2qn5QVUt65Yur6o6quq9X/t7p7jwAAMAgmcwM3BVJjt5K/TFJ9ustZyS5uFf+iyQnt9YO7B3/hap61bZ3FQAAYLDtPNEOrbVvVtW+W9nl+CRXttZakjur6lVV9drW2oOj2lhfVQ8nmZfkn19gnwEAAAbSdHwHbu8kD43aHu6VPauqliXZJcmPp+F8AAAAA2k6AlyNUdaerax6bZKrknywtfbMmA1UnVFVq6pq1YYNG6ahSwAAAC8+0xHghpPsM2p7fpL1SVJVr0zytSS/11q7c7wGWmsrW2tDrbWhefPmTUOXAAAAXnymI8DdlOTk3tMoD0uysbX206raJckNGfl+3PXTcB4AAICBNuFDTKrq6iRHJtmzqoaTfDrJ7CRprV2S5OtJjk2yNiNPnvxg79ATk6xIMreqTu2Vndpau3sa+w8AADAwJvMUyvdPUN+SnDVG+ReTfHHbuwYAAMBo03ELJQAAADNAgAMAAOgIAQ4AAKAjBDgAAICOEOAAAAA6QoADAADoCAEOAACgIwQ4AACAjhDgAAAAOkKAAwAA6AgBDgAAoCMEOAAAgI4Q4AAAADpCgAMAAOgIAQ4AAKAjBDgAAICOEOAAAAA6QoADAADoCAEOAACgIwQ4AACAjhDgAAAAOkKAAwAA6AgBDgAAoCMEOAAAgI4Q4AAAADpCgAMAAOgIAQ4AAKAjBDgAAICOEOAAAAA6QoADAADoCAEOAACgIyYMcFV1WVU9XFX3jlNfVXVBVa2tqh9U1ZJRdadU1Zrecsp0dhwAAGDQTGYG7ookR2+l/pgk+/WWM5JcnCRVtUeSTydZnmRZkk9X1e4vpLMAAACDbOeJdmitfbOq9t3KLscnubK11pLcWVWvqqrXJjkyyTdaa48mSVV9IyNB8Oqtne8nG36e9/63OybXewAAgAEyHd+B2zvJQ6O2h3tl45U/T1WdUVWrqmrVr371q2noEgAAwIvPhDNwk1BjlLWtlD+/sLWVSVYmydDQULv2Q78xDd0CAADonus+PH7ddMzADSfZZ9T2/CTrt1IOAADANpiOAHdTkpN7T6M8LMnG1tpPk9yc5Kiq2r338JKjemUAAABsgwlvoayqqzPyQJI9q2o4I0+WnJ0krbVLknw9ybFJ1ib5RZIP9uoerarfT3JXr6nzNz/QBAAAgKmbzFMo3z9BfUty1jh1lyW5bNu6BgAAwGjTcQslAAAAM0CAAwAA6AgBDgAAoCMEOAAAgI4Q4AAAADpCgAMAAOgIAQ4AAKAjBDgAAICOEOAAAAA6QoADAADoCAEOAACgIwQ4AACAjhDgAAAAOkKAAwAA6AgBDgAAoCMEOAAAgI4Q4AAAADpCgAMAAOgIAQ4AAKAjBDgAAICOEOAAAAA6QoADAADoCAEOAACgIwQ4AACAjhDgAAAAOkKAAwAA6AgBDgAAoCMEOAAAgI4Q4AAAADpCgAMAAOiISQW4qjq6qh6oqrVVdd4Y9a+vqtuq6gdVdXtVzR9V95+r6r6qur+qLqiqms4LAAAAGBQTBriq2inJRUmOSXJAkvdX1QFb7PbHSa5srR2U5Pwkf9g79i1J3prkoCQLkyxNcsS09R4AAGCATGYGblmSta21n7TWnkpyTZLjt9jngCS39db/dlR9SzInyS5JXpJkdpJ/fKGdBgAAGESTCXB7J3lo1PZwr2y0e5Kc0Ft/d5JXVNXc1todGQl0P+0tN7fW7n9hXQYAABhMkwlwY31nrW2x/bEkR1TV9zNyi+Q/JNlUVW9Msn+S+RkJfW+rqhXPO0HVGVW1qqpWbdiwYUoXAAAAMCgmE+CGk+wzant+kvWjd2itrW+tvae1dkiS3+2VbczIbNydrbXHW2uPJ/nrJIdteYLW2srW2lBrbWjevHnbeCkAAAAvbpMJcHcl2a+qFlTVLknel+Sm0TtU1Z5VtbmtTyS5rLf+fzMyM7dzVc3OyOycWygBAAC2wYQBrrW2KcnZSW7OSPi6rrV2X1WdX1Xv7O12ZJIHqurBJK9O8ge98v+R5MdJfpiR78nd01r76vReAgAAwGCo1rb8Olt/DQ0NtVWrVvW7GwAAAH1RVatba0Nj1U3qh7wBAADoPwEOAACgIwQ4AACAjhDgAAAAOkKAAwAA6AgBDgAAoCMEOAAAgI4Q4AAAADpCgAMAAOgIAQ4AAKAjBDgAAICOEOAAAAA6QoADAADoCAEOAACgIwQ4AACAjhDgAAAAOkKAAwAA6AgBDgAAoCMEOAAAgI4Q4AAAADpCgAMAAOgIAQ4AAKAjBDgAAICOEOAAAAA6QoADAADoCAEOAACgIwQ4AACAjhDgAAAAOkKAAwAA6AgBDgAAoCMEOAAAgI6YVICrqqOr6oGqWltV541R//qquq2qflBVt1fV/FF1v1ZVt1TV/VX191W17/R1HwAAYHBMGOCqaqckFyU5JskBSd5fVQdssdsfJ7mytXZQkvOT/OGouiuT/FFrbf8ky5I8PB0dBwAAGDSTmYFblmRta+0nrbWnklyT5Pgt9jkgyW299b/dXN8Leju31r6RJK21x1trv5iWngMAAAyYyQS4vZM8NGp7uFc22j1JTuitvzvJK6pqbpI3Jfnnqvqrqvp+Vf1Rb0bvOarqjKpaVVWrNmzYMPWrAAAAGACTCXA1RlnbYvtjSY6oqu8nOSLJPyTZlGTnJIf36pcmeUOSU5/XWGsrW2tDrbWhefPmTb73AAAAA2QyAW44yT6jtucnWT96h9ba+tbae1prhyT53V7Zxt6x3+/dfrkpyY1JlkxLzwEAAAbMZALcXUn2q6oFVbVLkvcluWn0DlW1Z1VtbusTSS4bdezuVbV5Wu1tSf7+hXcbAABg8EwY4HozZ2cnuTnJ/Umua63dV1XnV9U7e7sdmeSBqnowyauT/EHv2KczcvvkbVX1w4zcjnnptF8FAADAAKjWtvw6W38NDQ21VatW9bsbAAAAfVFVq1trQ2PVTeqHvAEAAOg/AQ4AAKAjBDgAAICOEOAAAAA6QoADAADoCAEOAACgIwQ4AACAjhDgAAAAOkKAAwAA6AgBDgAAoCMEOAAAgI4Q4AAAADpCgAMAAOgIAQ4AAKAjBDgAAICOEOAAAAA6QoADAADoCAEOAACgIwQ4AACAjhDgAAAAOkKAAwAA6AgBDgAAoCMEOAAAgI4Q4AAAADqiWmv97sNzVNXGJGv62IXdkmzs07n3TPJPfTp3P6/buWeesTZ45zfenHsQzt3PsZYM7us+qOf2t825t6fXt9bmjVnTWtuhliQrB/X8SVYN6HU798yf21gbsPMbb849IOfu21jbAa7duWf+3P62OXdflh3xFsqvDvj5+6Wf1+3cg2WQX/NBvvZ+GdTXfFDP3W+D+roP6rn7aVBf80E993PscLdQDrKqWtVaG+p3P3jxM9aYScYbM8VYYyYZb/TLjjgDN8hW9rsDDAxjjZlkvDFTjDVmkvFGX5iBAwAA6AgzcAAAAB0hwAEAAHSEALcdVdVlVfVwVd07quzaqrq7t6yrqrt75R8YVX53VT1TVYt7dYdW1Q+ram1VXVBV1a9rYsc1znhbXFV39sbUqqpa1iv/QFX9oLd8p6oOHnXM0VX1QG+8ndePa2HHNsWx9vFRf9furaqnq2qPXp2xxoTGGW8HV9UdvffGr1bVK3vl/6aqVvfKV1fV20Yd472UrZriWPO5jf7p9+8YvJiXJCuSLEly7zj1f5LkU2OUL0ryk1Hb30vyG0kqyV8nOabf12bZ8ZaxxluSWzaPlyTHJrm9t/6WJLv31o9J8t3e+k5JfpzkDUl2SXJPkgP6fW2WHWuZyljb4rjfSvI/e+vGmmVSyzjj7a4kR/TWfzvJ7/fWD0nyut76wiT/MOoY76WWrS5TGWtbHOdzm2VGFzNw21Fr7ZtJHh2rrve/MScmuXqM6vdvLq+q1yZ5ZWvtjtZaS3Jlkndtnx7TZeOMt5bklb313ZKs7+37ndba/+uV35lkfm99WZK1rbWftNaeSnJNkuO3a8fpnKmMtS08+7ctxhqTNM54e3OSb/bWv5HkhN6+32+tbR579yWZU1Uv8V7KZExlrG3B5zZm1M797sAAOzzJP7bW1oxR9978yweZvZMMj6ob7pXBZPzHJDdX1R9n5Jbpt4yxz7/PyP8QJiNj66FRdcNJlm/XHvJisdWxVlUvS3J0krN7RcYaL8S9Sd6Z5CtJ/m2SfcbY54Qk32+t/bKqvJeyrSYz1nxuY0aZgeuf0f8T/ayqWp7kF621zfdfj3XftN9+YLJ+J8k5rbV9kpyT5M9HV1bVv8pIgDt3c9EYbRhvTMZWx1pGbp/8dmtt8/9uG2u8EL+d5KyqWp3kFUmeGl1ZVQcm+U9JPrS5aIw2jDcmY6Kx5nMbM84MXB9U1c5J3pPk0DGq35fnBrvh/Mvtbemtj3VrEozllCT/obd+fZL/vrmiqg7qbR/TWnukVzyc5/7vovHGZI071nrG+ttmrLFNWms/SnJUklTVm5K8Y3NdVc1PckOSk1trP+4Vey9lm2xtrPX43MaMMwPXH/86yY9aa6On2FNVszIyPX/N5rLW2k+T/KyqDut9b+7kjEzjw2SsT3JEb/1tSdYkSVX9WpK/SvLvWmsPjtr/riT7VdWCqtolI29MN81gf+muMcdaklTVbr260X+7jDW2WVXt1ft3VpLfS3JJb/tVSb6W5BOttW9v3t97KdtqvLE2qsznNmacGbjtqKquTnJkkj2rajjJp1trf57n/2/NZiuSDLfWfrJF+e8kuSLJSzPyXaW/DmxhrPGW5PQkf9ab9X0yyRm93T+VZG6S/9p7uvGm1tpQa21TVZ2d5OaMPCXwstbafTN7JezopjjWkuTdSW5prf18c4GxxmSNM952raqzerv8VZLLe+tnJ3ljkk9W1Sd7ZUe11h6O91ImMMWxlvjcRp/UyANyAAAA2NG5hRIAAKAjBDgAAICOEOAAAAA6QoADAADoCAEOAACgIwQ4AACAjhDgAAAAOuL/AyjdyUC0WcycAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "result.seasonal.plot(label='$CO^{2}$ emissions - seasonal')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "young-benefit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4AAAAD4CAYAAAC9rYhmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdd5xU5dn/8c812zuwLHXpvUlbilHRRINYwcSCsRAbRs1jYn4m6pMYU0weTUxMTNQEKxoFW4wYC2JLrDTpILD0pbPLFrbPzP37Y8/iALuwfbZ836/XvObMdd/nnOusR3auvc+5jznnEBERERERkdbPF+4EREREREREpGmoABQREREREWkjVACKiIiIiIi0ESoARURERERE2ggVgCIiIiIiIm1EZLgTaGgdO3Z0vXv3DncaIiIiIiIiYbF06dIDzrm0qtpaXQHYu3dvlixZEu40REREREREwsLMtlXXpktARURERERE2ggVgCIiIiIiIm2ECkAREREREZE2otXdA1iV8vJysrKyKCkpCXcq0oLFxsaSnp5OVFRUuFMREREREamTNlEAZmVlkZSURO/evTGzcKcjLZBzjuzsbLKysujTp0+40xERERERqZM2cQloSUkJqampKv6kzsyM1NRUjSKLiIiISIvWJgpAQMWf1JvOIRERERFp6drEJaAiIiIiIiKt1dur97A9p5DUhBg6JsUct68KQBERERERkRbqxcU7+MkrK2vcXwWgiIiIiIhIC/TfDfu569VVTBqYxkPTR3GwqJwDh0oZf3/166gAbAH+9a9/8cYbb7Bv3z5uueUWJk+eHO6UREREREQkjNbtzufm575gQKdEHv7OaJJio2gXH02fjgnHXa/NTALTXLz00ktMmDCBk046if79+/PLX/4SgFdeeYUJEyYwcuRIMjIymD9//uF1pk2bxmOPPcbTTz/NCy+80Ch5fe1rX2uSdRpCbm4ujzzySKNt/xe/+AUPPPBAo21fRERERKQ+lm0/yIwnF5EYE8lT14wjKbbmz6lWAdiEZs+ezf33388rr7zCypUrWb58OfHx8Tz//PM88MADvPbaa6xYsYI5c+YwY8YMduzYccT69957L7fcckuj5Pbpp582yToNoboC0DlHMBgMQ0YiIiIiIo3POcczn23l0r9/RnSkj9nXjqdrSlyttqECsInk5+fzox/9iBdffJH09HQAEhMTufnmm7nzzjt58cUX6dKlCwADBgzgjDPO4L333gMq/kPfcccdnHPOOYwZM6bK7f/jH/9g/PjxjBo1ihtvvJFAIMDWrVsZPHgw119/PcOHD+eKK67g3Xff5ZRTTmHAgAEsWrTo8PqJiYkAFBYWct555zFy5EiGDx/OCy+8UGUsdB2AP/7xjwwfPpzhw4fzpz/9CYCtW7cyZMgQbrjhBoYNG8bkyZMpLi6udns1deedd7Jp0yZGjRrFJZdcwpAhQ7j55psZM2bM4aK5up9HVfkA/OY3v2HQoEGcddZZrF+/vlb5iIiIiIg0BOccO3OL+eDLffx75S5eWrKDZz7byt//s4k/vbuBG55Zys9fW8NpA9L49/+cyqAuSbXeh+4BbCKvvvoqEyZMoG/fvkfE586dy5gxY+jRo8cR8ZiYGPLy8gD4y1/+wrvvvkteXh6ZmZl873vfO6LvunXreOGFF/jkk0+Iiori5ptv5rnnnmPSpElkZmby0ksvMWvWLMaNG8fzzz/Pxx9/zLx58/jtb3/Lv/71ryO29fbbb9OtWzfeeOMNAPLy8qqMhVq6dClPPfUUCxcuxDnHhAkTOP3002nfvj0bN25kzpw5PPbYY1x66aW88sorxMXFHXd7J3LfffexevVqli9fztatW+nbty9PPfXU4VHB4/08qspnyJAhzJ07l2XLluH3+xkzZgxjx46tVU4iIiIiIrVR5g+yfEcuW7ML2ZZdyIa9h1i+I5f9BaXVrpMQHcHtkwdy8xn98fnq9ozqNlcA/vL1Nazdld+g2xzaLZl7Lhh23D5r1qxh1KhRx8RXr17NyJEjj4mvWLGCGTNmAHDrrbdy6623Vrvt9957j6VLlzJu3DgAiouL6dSpE5MmTaJPnz6MGDECgGHDhnHmmWdiZowYMYKtW7ces60RI0Zw++23c8cdd3D++edz2mmnVRkL9fHHH3PRRReRkFBxw+m3vvUtPvroIy688EL69Olz+LjHjh3L1q1bufTSS4+7vdrq1asXEydOrPHP4+h8Dhw4wEUXXUR8fDwAF154Yb3yERERERE5npzCMq55ahErsioGQiJ8Rq8O8ZzavyOje7ZjWLdkkmOjiI2KIC46grioilddi75Qba4ADJeEhITDlxuGSklJobT0yCr/s88+Iz8/n9NPP71G23bOMWPGDP7v//7viPjWrVuJifnqQZA+n+/wZ5/Ph9/vP2ZbAwcOZOnSpbz55pvcddddTJ48mZ///OdVxkL3X53Q/UdERFBcXFztPkI9/PDDPPbYYwC8+eabdOvWrdp9VBaetf15VOYDYFb//5lERERERE5kV24xVz2xkKyDxfzu4pOY0KcD3drFERXRNHfnnbAANLMngfOBfc654V7s98AFQBmwCbjGOZfrtd0FXAcEgFudc/O9+BTgz0AE8Lhz7j4v3geYC3QAvgCucs6VmVkM8AwwFsgGLnPOba3vAZ9opK6xnHvuuUyfPp3bbruNzp07U1payjPPPMP555/PZZddxo9+9CPS0tLYsGED119/PU899RQRERE12vaZZ57J1KlTue222+jUqRM5OTkUFBTUKc9du3bRoUMHrrzyShITE3n66aerjIWaNGkS3/3ud7nzzjtxzvHqq6/y7LPP1mofR7vllluqnfAmKSnpuMdX259HaP5+v5/XX3+dG2+8sdr+IiIiIiJ1sWn/Ia56fCEFJX6euXY8E/qmNnkONRkBfBr4KxXFWKUFwF3OOb+Z3Q/cBdxhZkOB6cAwoBvwrpkN9NZ5GPgmkAUsNrN5zrm1wP3Ag865uWb2NyqKx0e994POuf5mNt3rd1n9Djd8xo0bxy9+8QvOPvtsAoEAfr+fK6+8koyMDO6+++7Dl2ampKTwt7/9rVaXRQ4dOpR7772XyZMnEwwGiYqK4uGHHz48qUxtrFq1ih//+Mf4fD6ioqJ49NFHq4yFGjNmDN/97ncZP348ANdffz2jR4+u8hLT6vZRG6mpqZxyyikMHz6cIUOGHNNe25/HmDFjuOyyyxg1ahS9evWq9yWpIiIiIiJHK/MHufHZpZT6g8yZOZHh3VPCkocd7/K9w53MegP/rhwBPKrtIuBi59wV3ugfzrn/89rmA7/wuv7COXe2F7/Li90H7Ae6eMXkyZX9Ktd1zn1mZpHAHiDNnSDhjIwMt2TJkiNi69atq7JQEKktnUsiIiIiUhcPf5DJ7+ev56nvjuPrgzs16r7MbKlzLqOqtoa40PRa4C1vuTsQ+vC6LC9WXTwVyHXO+Y+KH7Etrz3P638MM5tpZkvMbMn+/fvrfUAiIiIiIiINZUdOEX95fyNThnVp9OLvROpVAJrZTwE/8FxlqIpurg7x423r2KBzs5xzGc65jLS0tOMnLSIiIiIi0oR++foafGb8/IKh4U6l7gWgmc2gYnKYK0Iuy8wCQh9olw7sOk78ANDOu8QzNH7Etrz2FCCnrvmKiIiIiIg0tXfW7OHddfv44VkD6NYuLtzp1K0A9Gb0vAO40DlXFNI0D5huZjHe7J4DgEXAYmCAmfUxs2gqJoqZ5xWOHwAXe+vPAF4L2dYMb/li4P0T3f93PPVYVQTQOSQiIiIiteOc43fz1zOwcyLXnNIn3OkANSgAzWwO8BkwyMyyzOw6KmYFTQIWmNlyb/ZOnHNrgBeBtcDbwC3OuYB3D9/3gfnAOuBFry9UFJI/MrNMKu7xe8KLPwGkevEfAXfW9SBjY2PJzs7WF3ipM+cc2dnZxMbGhjsVEREREWkhVu/MJ3PfIa45pU+TPefvRGo0C2hLUtUsoOXl5WRlZVFSUhKmrKQ1iI2NJT09naioqHCnIiIiIiItwK//vZZnP9vG4p+eRUp8032HPN4soDV5DmCLFxUVRZ8+zWPIVUREREREWr9A0PH6il2cMSitSYu/E2ke45AiIiIiIiIt2I6cIsoDwcOfP9uUzb6CUqaN7n6ctZqeCkAREREREZF6eGVpFqf//gNufu4LgsGKW+z+tXwnSTGRfCPMz/07mgpAERERERGROnph8XZuf3kFPTrEs2DtXv64YAMl5QHeXr2HKcO7EBsVEe4Uj9Am7gEUERERERFpaP/4fBs/+9dqJg1MY9ZVY/nFvDX89YNMdhws4lCpn6mjmtfln6ACUEREREREpNbe/3IvP/vXas4c3ImHrxhDbFQEv5o6nM37C3lt+S46JcVwcr/UcKd5DF0CKiIiIiIiUgv78ku4/aWVDO6SdLj4A4iO9PHolWMY3CWJa07pQ4TPwpzpsTQCKCIiIiIiUkPBoOP/vbSCojI/f/3OxGPu8UtNjOGtH5yGWfMr/kAjgCIiIiIiIjX2+Meb+WjjAX5+/jD6d0qqsk9zLf5ABaCIiIiIiEiNrN2Vz+/nr2fKsC5cPr5HuNOpExWAIiIiIiIiJxAIOu7650pS4qK479sjmvUo3/GoABQRERERETmBZz/byoqsPO4+fyjt4qPDnU6dqQAUERERERE5jl25xfx+/nomDUzjwpHdwp1OvagAFBEREREROY575q0h4By/mTa8xV76WUkFoIiIiIiISDXeXLWbBWv38sOzBtKjQ3y406k3FYAiIiIiIiJV2Jdfwv++uooR3VO47tQ+4U6nQagAFBEREREROYpzjh+/vJKS8gAPXjaKqIjWUTq1jqMQERERERFpQP9YuJ3/bNjP/547hP6dEsOdToNRASgiIiIiIhJi8/5D/OaNtUwamMZVE3uFO50GpQJQREREREQkxP1vf0mUz8fvLz6pxc/6eTQVgCIiIiIiIp4v9+Qzf81erjmlN52TY8OdToNTASgiIiIiIuL56/uZJERHcG0rmfXzaCcsAM3sSTPbZ2arQ2IdzGyBmW303tt7cTOzh8ws08xWmtmYkHVmeP03mtmMkPhYM1vlrfOQeWOs1e1DRERERESkMWTuO8Qbq3Zz1cm9aRcfHe50GkVNRgCfBqYcFbsTeM85NwB4z/sMcA4wwHvNBB6FimIOuAeYAIwH7gkp6B71+lauN+UE+xAREREREWlwj3yQSUykj+tPa52jf1CDAtA5918g56jwVGC2tzwbmBYSf8ZV+BxoZ2ZdgbOBBc65HOfcQWABMMVrS3bOfeacc8AzR22rqn2IiIiIiIg0qG3Zhby2YhdXTOhFx8SYcKfTaOp6D2Bn59xuAO+9kxfvDuwI6ZflxY4Xz6oifrx9HMPMZprZEjNbsn///joekoiIiIiItFV/+88mInzGjZP6hjuVRtXQk8BUNUeqq0O8Vpxzs5xzGc65jLS0tNquLiIiIiIibdje/BJeWbqTSzPS6dQKZ/4MVdcCcK93+Sbe+z4vngX0COmXDuw6QTy9ivjx9iEiIiIiItJgnvx4C/5gkJmn9Qt3Ko2urgXgPKByJs8ZwGsh8au92UAnAnne5Zvzgclm1t6b/GUyMN9rKzCzid7sn1cfta2q9iEiIiIiItIg8orLeW7hds47qRs9U+PDnU6jizxRBzObA5wBdDSzLCpm87wPeNHMrgO2A5d43d8EzgUygSLgGgDnXI6Z/RpY7PX7lXOucmKZm6iYaTQOeMt7cZx9iIiIiIiINIh/fL6NQ6V+vnd66773r5JVTL7ZemRkZLglS5aEOw0REREREWnmSsoDnHr/+wzrlsLsa8eHO50GY2ZLnXMZVbU19CQwIiIiIiIiLcILi3dw4FAZN53R+u/9q6QCUERERERE2px5K3Zx7xtrGd+nAxP6dAh3Ok1GBaCIiIiIiLQpj3+0mVvnLGN0z/Y8dnUGFfNRtg0nnARGRERERESkNdibX8KDCzYwd/EOzh3RhT9eOorYqIhwp9WkVACKiIiIiEirtiu3mEc/3MQLS3YQCDpuOK0Pd54zhAhf2xn5q6QCUEREREREWq1N+w/xrUc+pajMz8Vje3DT6f3axPP+qqMCUEREREREWqWDhWVc9/RiIn3GO7edTp+OCeFOKexUAIqIiIiISKtT5g9y03NL2ZVbwpyZE1T8eVQAioiIiIhIq1JY6ufu11bz+eYc/nTZKMb2ajuPeTgRFYAiIiIiItJiHCws4/lF28krLqeozE8g6BjQKYmRPdrRo30ccxfv4MlPtpBbVM4PzhzAtNHdw51ys6ICUEREREREWoSS8gDXzl7Msu25xET6SIipKGfmLNpxRL+zhnTi5q/3Z0zP9uFIs1lTASgiIiIiIo2uPBBkxY5cPsnMZvHWHKaO6sYlGT1qvL5zjh+/vJJl23N59IoxnDOi6+G2PXklrMjKJXPfIb4+qBNDuyU3xiG0CioARURERESkUa3fU8BVTyxkX0EpZtA+PppFW3M4Kb0dg7ok1WgbD767kddX7OKOKYOPKP4AuqTE0iWlC2cPa4zsWxdfuBMQEREREZHWa8PeAr7z2OeYwcPfGcMXP/sm79w2ieTYSH4wdxml/sBx1w8GHY9+uImH3tvIpRnpfO/0vk2UeeukAlBERERERBrFRq/4i/AZc26YyHkndaV9QjQdE2P43cUn8eWeAv7wzoZq19+ZW8x3Hv+c+9/+knNHdOHeaSMwsyY8gtZHl4CKiIiIiEiDCgYd81bs4t431mJmzJk5kb5piUf0+cbgzlw5sSez/rsZA/KKy9meU0RxeYCE6EgSYiL4dFM2waDjdxefxCVj01X8NQAVgCIiIiIi0mA+3XSA3765jtU78xnWLZk/Tx9Nv6OKv0o/PXcoCzfn8Pf/bqZjYgw9OsSRGBNJYamf/QWljO3Vnl9dOJyeqfFNfBStlwpAERERERFpEP9atpMfvrCc7u3iePCykUwd2R2fr/pRu7joCP5966kEgo74aJUmTUE/ZRERERERqbetBwr56aurGN+7A89cN57YqIgarRcTWbN+0jA0CYyIiIiIiNRLmT/IrXOXERnh40/TR9W4+JOmpxFAERERERGplwfeWc/KrDz+duVYurWLC3c6chwaARQRERERkTp7c9VuZv13M1dO7MmU4V3CnY6cQL0KQDO7zczWmNlqM5tjZrFm1sfMFprZRjN7wcyivb4x3udMr713yHbu8uLrzezskPgUL5ZpZnfWJ1cREREREWlY/165i/+Zs4yMXu352XlDw52O1ECdC0Az6w7cCmQ454YDEcB04H7gQefcAOAgcJ23ynXAQedcf+BBrx9mNtRbbxgwBXjEzCLMLAJ4GDgHGApc7vUVEREREZEwe235Tm6ds4yxPdvz9LU1n/RFwqu+l4BGAnFmFgnEA7uBbwAve+2zgWne8lTvM177mVbxJMepwFznXKlzbguQCYz3XpnOuc3OuTJgrtdXRERERETC5MChUu5/+0tue2E54/t04Olrx5EYo6lFWoo6/5dyzu00sweA7UAx8A6wFMh1zvm9bllAd2+5O7DDW9dvZnlAqhf/PGTToevsOCo+oapczGwmMBOgZ8+edT0kERERERGpxoFDpfz1/UzmLt5OqT/IhSO7cd+3TiIuWiN/LUmdC0Aza0/FiFwfIBd4iYrLNY/mKleppq26eFWjk66KGM65WcAsgIyMjCr7iIiIiIhI3ZT5g1zz1GLW7c7notHd+d4Z/eiXlhjutKQO6jNWexawxTm3H8DM/gl8DWhnZpHeKGA6sMvrnwX0ALK8S0ZTgJyQeKXQdaqLi4iIiIhIE3nw3Q2s2lnxmAfN9Nmy1ecewO3ARDOL9+7lOxNYC3wAXOz1mQG85i3P8z7jtb/vnHNefLo3S2gfYACwCFgMDPBmFY2mYqKYefXIV0REREREaumzTdn87T+buHx8DxV/rUB97gFcaGYvA18AfmAZFZdhvgHMNbN7vdgT3ipPAM+aWSYVI3/Tve2sMbMXqSge/cAtzrkAgJl9H5hPxQyjTzrn1tQ1XxERERGRtuZgYRlPf7qVuOgIuqbE0is1gZHpKVSM35xYXlE5P3pxOX1SE7j7fE3I3xpYxSBc65GRkeGWLFkS7jRERERERMIqr7ic7zz2OWt25R8R/86Envxm2vATFoEl5QFufHYpn2Qe4NWbT2FEekpjpisNyMyWOucyqmrTfK0iIiIiIq3MoVI/331qERv2FvD0NePI6N2B3bnFzF28gyc+3kJKXBR3TBlc7fp5xeXcMHsJi7flcN+3Rqj4a0VUAIqIiIiItCLFZQGufXoxK7PyeOSKMZwxqBMAAzon8bPzhlBSHuDRDzeRFBvJzWf0P2b9/QWlzHhyERv3FfDQ9NFcMLJbUx+CNCIVgCIiIiIirYRzjp+8spLFW3P48/TRnD3syElbzIxfTx3OoVI/v3t7PZ9mZjOhTwcyencg62AR763bx0cb9xN08PiMcZw+MC1MRyKNRQWgiIiIiEgr8cTHW3h9xS5+fPYgLqxm5M7nMx64ZCTd28Xx/pf7+MOCDYfbuiTHMnV0d66Y0JNh3XTZZ2ukAlBEREREpBX4dNMB/u+tL5kyrAs3n9HvuH2jInz8ZMpgfjJlMLlFZSzbnktaUgzDuiXXeIZQaZlUAIqIiIiItHBZB4v4/vPL6J0azwOXjqxVEdcuPpqvD+7UiNlJc1KfB8GLiIiIiEiYrd6Zx7cf/ZRyf5C/X5VBYozGeKR6KgBFRERERFqod9bs4ZK/fUaEGS9+72T6d0oMd0rSzOnPAyIiIiIiLdArS7O4/eUVnNQ9hcdmZNApKTbcKUkLoAJQRERERKSFySsq51f/Xsu4Xh2Yfe144qIjwp2StBC6BFREREREpIV55MNM8kvKuefCoSr+pFZUAIqIiIiItCBZB4t46tOtXDS6u57VJ7WmAlBEREREpAX5wzsbMOD2yYPCnYq0QLoHUERERESkmckvKWd/QSmJMZHER0fgM8MfcKzfW8Cry3Zy0xn96NYuLtxpSgukAlBEREREpBnJPlTK5Af/S3ZhWZXt7eOjuOmMfk2clbQWKgBFRERERJqR+9/+krzicn5z0XAMo7DUT9A5oiJ8REUYJ/frSHJsVLjTlBZKBaCIiIiISDOxdNtBXlySxY2T+nLFhF7hTkdaIU0CIyIiIiLSDASCjnvmraZzcgz/c+aAcKcjrZQKQBERERGRZuD5RdtZvTOfn543lMQYXagnjUMFoIiIiIhImO3OK+aB+es5uW8qF5zUNdzpSCumAlBEREREJIz8gSA/mLOc8kCwYuIXs3CnJK2YxpZFRERERMLoT+9uZNHWHP502Sj6piWGOx1p5eo1Amhm7czsZTP70szWmdnJZtbBzBaY2Ubvvb3X18zsITPLNLOVZjYmZDszvP4bzWxGSHysma3y1nnI9OcQEREREWlFPtq4n4c/zOTSjHSmje4e7nSkDajvJaB/Bt52zg0GRgLrgDuB95xzA4D3vM8A5wADvNdM4FEAM+sA3ANMAMYD91QWjV6fmSHrTalnviIiIiIizcKevBJue2E5/dMS+cWFw8KdjrQRdS4AzSwZmAQ8AeCcK3PO5QJTgdlet9nANG95KvCMq/A50M7MugJnAwuccznOuYPAAmCK15bsnPvMOeeAZ0K2JSIiIiLSYhWV+blu9mKKywI8fMUY4qN1Z5Y0jfqMAPYF9gNPmdkyM3vczBKAzs653QDeeyevf3dgR8j6WV7sePGsKuLHMLOZZrbEzJbs37+/HockIiIiItK4gkHHD+cuZ93ufP7yndEM7JwU7pSkDalPARgJjAEedc6NBgr56nLPqlR1/56rQ/zYoHOznHMZzrmMtLS042ctIiIiIhJGv5u/nnfW7uWn5w3lG4M7hzsdaWPqUwBmAVnOuYXe55epKAj3epdv4r3vC+nfI2T9dGDXCeLpVcRFRERERFqkjzce4G//2cR3JvTk2lN6hzsdaYPqXAA65/YAO8xskBc6E1gLzAMqZ/KcAbzmLc8DrvZmA50I5HmXiM4HJptZe2/yl8nAfK+twMwmerN/Xh2yLRERERGRFueh9zfSJTmWey4Yquf9SVjU927T/wGeM7NoYDNwDRVF5Ytmdh2wHbjE6/smcC6QCRR5fXHO5ZjZr4HFXr9fOedyvOWbgKeBOOAt7yUiIiIi0uIs3prDoi05/Pz8ocRERoQ7HWmj6lUAOueWAxlVNJ1ZRV8H3FLNdp4EnqwivgQYXp8cRURERESag0c+yKRDQjTTx/c4cWeRRlLf5wCKiIiIiMgJrNmVxwfr93PtKb31yAcJKxWAIiIiIiKN7JEPN5EUE8lVJ/cOdyrSxqkAFBERERFpRJv2H+LNVbu56uRepMRFhTsdaeNUAIqIiIiINBLnHL95Yx3xURFce2qfcKcjogJQRERERKSxLFi7l/e/3McPzxpIx8SYcKcjogJQRERERKQxFJcF+OXraxnYOZHv6qHv0kxoCiIRERERkUbw8AeZ7Mwt5oWZE4mK0LiLNA86E0VEREREGtjm/YeY9d/NfGt0dyb0TQ13OiKHqQAUEREREWlApf4AP5i7nNgoH3edOyTc6YgcQZeAioiIiIg0oF//ey2rduYx66qxpCVp4hdpXjQCKCIiIiLSQF5bvpN/fL6dGyf1ZfKwLuFOR+QYKgBFRERERBrAhr0F3PXPVYzv3YHbzx4U7nREqqQCUERERESknt5ctZtvP/op8dER/OU7ozXrpzRbugdQRERERKSOSsoD/Prfa3lu4XZG9mjHXy8fTefk2HCnJVItFYAiIiIiInWQV1TOjKcWsXxHLjMn9eX2yYOIjtTInzRvKgBFRERERGop+1ApVz6xiE37DvG3K8cwZXjXcKckUiMqAEVEREREamFvfglXPL6QrINFPD4jg0kD08KdkkiNqQAUEREREamhrINFXPH4Qg4UlDL7mvFM6Jsa7pREakUFoIiIiIhIDWw9UMgVjy+koKScf1w/gdE924c7JZFaUwEoIiIiInICG/cWcMXjC/EHHc/fMJHh3VPCnZJInagAFBERERE5jsx9h5g+6x2IMoUAABwySURBVHN8PuOFmRMZ0Dkp3CmJ1JkKQBERERGRauzIKeLKxxdiVlH89U1LDHdKIvVS7weVmFmEmS0zs397n/uY2UIz22hmL5hZtBeP8T5neu29Q7Zxlxdfb2Znh8SneLFMM7uzvrmKiIiIiNRU5WyfxeUB/nH9eBV/0io0xJMqfwCsC/l8P/Cgc24AcBC4zotfBxx0zvUHHvT6YWZDgenAMGAK8IhXVEYADwPnAEOBy72+IiIiIiKNKreojCsfX0j2oVJmXzuewV2Sw52SSIOoVwFoZunAecDj3mcDvgG87HWZDUzzlqd6n/Haz/T6TwXmOudKnXNbgExgvPfKdM5tds6VAXO9viIiIiIijabUH2Dms0vZll3E4zPGMapHu3CnJNJg6jsC+CfgJ0DQ+5wK5Drn/N7nLKC7t9wd2AHgted5/Q/Hj1qnuvgxzGymmS0xsyX79++v5yGJiIiISFsVDDp+8vJKFm3J4feXnMTJ/fScP2ld6lwAmtn5wD7n3NLQcBVd3Qnaahs/NujcLOdchnMuIy0t7ThZi4iIiIhU7w8L1vPa8l38+OxBTB1V5diDSItWn1lATwEuNLNzgVggmYoRwXZmFumN8qUDu7z+WUAPIMvMIoEUICckXil0neriIiIiIiINpqQ8wC9fX8OcRTuYPq4HN5/RL9wpiTSKOo8AOufucs6lO+d6UzGJy/vOuSuAD4CLvW4zgNe85XneZ7z2951zzotP92YJ7QMMABYBi4EB3qyi0d4+5tU1XxERERGRqmTuO8S0hz9hzqId3HRGP+6dNpyKqSpEWp/GeA7gHcBcM7sXWAY84cWfAJ41s0wqRv6mAzjn1pjZi8BawA/c4pwLAJjZ94H5QATwpHNuTSPkKyIiIiJtSKk/wIK1e1m1M481O/NZsi2H+OhInr5mHGcM6hTu9EQalVUMwrUeGRkZbsmSJeFOQ0RERESaoZLyADc8s4SPNh4gOsLHwC6JjExvx/98YwBdUmLDnZ5IgzCzpc65jKraGmMEUERERESk2SkuC3Dd7MV8tjmb3140govHphMd2RCPxRZpOVQAioiIiEirV1jq59qnF7N4aw5/uGQk3xqTHu6URMJCBaCIiIiItGob9xZw83NfsGn/IR68bJQe7yBtmgpAEREREWm1Xlqyg7tfW01iTCSzrx3PaQP0zGhp21QAioiIiEir4g8Eef/LfTz7+TY+2niAiX078ND00XRK1iQvIioARURERKRVKCkP8Oxn23jyky3sziuhc3IMd50zmOtP60uET8/1EwEVgCIiIiLSwjnneH3lbn739pdkHSzma/1SueeCYZw1pBOREZrlUySUCkARERERabEKSsq58dmlfLopmyFdk/nHdSdx6oCO4U5LpNlSASgiIiIiLVJuURlXP7mItbvyuXfacC4f31OXeoqcgApAEREREWlx9heUctUTC9l8oJC/XzWWM4d0DndKIi2CCkARERERaVHyisuZPuszdueV8NR3x3FKf13yKVJTKgBFREREpMUIBh23vbCcbdlFPHvdBE7ulxrulERaFE2LJCIiIiItxp/e28j7X+7j5xcMVfEnUgcqAEVERESkRXhnzR4eem8jF49N56qJvcKdjkiLpEtARURERKTZCgQdn246wEtLsnh79R5OSk/h3mnDMdNsnyJ1oQJQRERERJqdrQcKeXlpFv/8IotdeSUkx0Zy2bge/M+Z/YmNigh3eiItlgpAEREREQm7/JJylm/P5YvtB/kk8wCLtx7EZ3DagDT+97whnDWkswo/kQagAlBEREREwsYfCPKHBRv4+382EXRgBoO7JPPjswfx7THpdEmJDXeKIq2KCkARERERCYv9BaXcOmcZn23O5ttj0pk2uhujerQjKTYq3KmJtFoqAEVERESkya3emcd1sxeTW1TO7y8+iUsyeoQ7JZE2QQWgiIiIiDSpPXklXPv0YiJ9xqs3n8LQbsnhTkmkzVABKCIiIiJNprgswPXPLKaw1M8/bz6FQV2Swp2SSJtS5wfBm1kPM/vAzNaZ2Roz+4EX72BmC8xso/fe3oubmT1kZplmttLMxoRsa4bXf6OZzQiJjzWzVd46D5ke+CIiIiLSYgWDjv/30nLW7MrnoctHq/gTCYP6jAD6gf/nnPvCzJKApWa2APgu8J5z7j4zuxO4E7gDOAcY4L0mAI8CE8ysA3APkAE4bzvznHMHvT4zgc+BN4EpwFv1yFlEREREmsiqrDzue3sdq3fmEx3pw2ewN7+Un547hDOHdA53eiJtUp0LQOfcbmC3t1xgZuuA7sBU4Ayv22zgQyoKwKnAM845B3xuZu3MrKvXd4FzLgfAKyKnmNmHQLJz7jMv/gwwDRWAIiIiIg0qGHTkl5TjHLRPiD5uX+ccJ7ooa09eCb+b/yX//GInqQnRnH9SV4LOUeoPMrRrMted2qch0xeRWmiQewDNrDcwGlgIdPaKQ5xzu82sk9etO7AjZLUsL3a8eFYV8ar2P5OKkUJ69uxZv4MRERERaQNKygP89s11vL5iF7nFFcUfQOfkGIZ3S6FHh3iyDhazLbuQnbnFlAeC+IOOSJ/x+IxxnD4wrcrtbtxbwOWPfU5+sZ/vnd6Pm7/ej2Q91kGk2ah3AWhmicArwA+dc/nH+YtQVQ2uDvFjg87NAmYBZGRkVNlHRERERCrsyCnipueWsnpnPlNHdaNnh3jaxUcTDDrW7s5nza48Pt+cTXr7ePp0TOC0AWnERvmI8Bn//GInv3v7SyYN6HjMSOCm/Ye4/LGFmBlv/uBU+nfSPX4izU29CkAzi6Ki+HvOOfdPL7zXzLp6o39dgX1ePAsIfcBLOrDLi59xVPxDL55eRX8REREROQ7nHF9szyUlLvKIIqw8EOSNlbu5Z94ags7x+NUZnDW0dvfi9UpN4PaXVvDO2r2cPazL4fiWA4VcPutzAObcMJH+nRIb5mBEpEHVuQD0ZuR8AljnnPtjSNM8YAZwn/f+Wkj8+2Y2l4pJYPK8InE+8NvK2UKBycBdzrkcMysws4lUXFp6NfCXuuYrIiIi0hZszy7innmr+WD9fgBG92zHxWPT2V9QyvMLt7OvoJTh3ZN55Dtj6ZkaX+vtTxvVjYc/yOTBBRv45pDO+HzGtuyK4i8QdMyZqeJPpDmrzwjgKcBVwCozW+7F/peKwu9FM7sO2A5c4rW9CZwLZAJFwDUAXqH3a2Cx1+9XlRPCADcBTwNxVEz+oglgREREpEUrKQ/w8tIsUuKiOP+kriecUKWmyvxBHv1wEw9/mEmUz/jfcwdjGC8u2cFPX10NwOkD07jv2704fWAnInx1229khI9bz+zPbS+sYP6aPQzvnsLlsz6n1B/g+RsmMrCzLvsUac7MudZ1y1xGRoZbsmRJuNMQEREROYJzjnfX7ePeN9ayLbsIgHG92/OrqcMZ0jW5Xttev6eA215Yztrd+Zx/Uld+dt5QuqTEHt7v2t35JMVE1WnEryqBoOObD/4HqCg8C0r8PH/DBIZ1S2mQ7YtI/ZjZUudcRlVtDTILqIiIiIgcaXt2EXe9upLsQ2VERhhl/iAb9h6if6dEnrl2PLvzirnvrS85/y8fc92pfbh98iCiI3212kdBSTnPfr6NPy3YSHJcJLOuGsvkkPvyAMyswQuzCJ/xw7MGcuucZSTFRvL89RNV/Im0ECoARUREROqgoKScMn+Q8oDD54NOSbGH277YfpAbZi/BH3RM6NMBf9ARCDqmj+vJVSf3IiqiotA7e1gX7n97PbP+u5mFW3L46+Wj6dHh+KN0waDjg/X7eHXZThas3UupP8g5w7tw77ThpCbGNOoxhzpvRFe2ZxdyxqBODO+u4k+kpdAloCIiItIiFJSU89hHW8g+VMqPzx5Eu/jjP7AcoKjMz+b9hfRoH09KfP2eRbcnr4R5K3aybHsuy7bnsie/5Ij2fmkJTBnehS4pcdz777V0To7lqWvG0S/txBOivLVqNz95eSVm8LuLRzJleJcq+63KyuPu11azfEcu7eOjuGBkN6aN7s7oHu0a7F5CEWn5jncJqApAERERadbK/EGeW7iNv7yfSU5hGRE+IzUhmvu+PYJvDD72EQYrduTy0tIdfLEtl/V7CwgEK77r9E6NZ1SPdtz89f5HTFTiDwT5w4INdIiP5rpT++A7anKUMn+QJz/ZwkPvbaSoLEDPDvGM7tmOIV2TiY+OICrCR2Gpn/fW7WPR1hwCQcfonu14/OqMWo3Ibcsu5PvPL2PVzjzOHdGFey4YRufkilHFTfsP8eTHW3h+0XZSE2K485zBTB3V7fBIoohIKBWAIiIi0mKU+YNkHSxiydaDfLhhHx9tPEBBiZ+v9UvlznMG4zPj/724gvV7CzhneBfG9GxP37QEygNBnvxkK4u25BAfHcGYnu0Z3bMdg7oksS27iBU7clm4JYegczx2dQYT+6ZS6g/ww7nLeWv1HqBilswHLxtFh4RoSsoDvLtuLw8u2MCm/YWcNaQzd58/hF6pCdXmfrCwjDW78sno3Z7YqIg6HftjH23mz+9tJCbCx3kndWXhlhy2HCgkwmfMOLk3P/zmAJJj6zeaKSKtmwpAERERaZYKSspZtj2XJVtzWLLtIFsOFLInv4TKryedk2M4fWAaF4zsxqn9Ox6+zLHUH+DP725kzqLtHCwqP7y97u3iuOaU3lw2rgdJVRRJO3OLmfHkIrZnF3Hft0fw2vJd/GfDfu4+fyjRkT5+/fpaUhOjOW1AR95avYeCEj+9UuP5+flDOXNI7R6YXh9bDxTys3+tZtGWHCb2S+WbQzpx1tDOdE2Ja7IcRKTlUgEoIiIiYVEeCPL3/2xi9mfb6BAfTY8O8XRNiWVnbjHr9xSwM7cYAJ/B0G7JDOqcTHr7ONLbxzG8ewqDuySd8N62g4VlbD5QSGGpn5P7pZ7wssjcojKum72EpdsOYgb3fWsEl43rCVTcY3fL81+wv6CUc4Z34aIx3flav451fmZefQWD7phLUkVETkQFoIiIiDS51Tvz+PHLK1m3O5/TB6YRFeFje04hu/NK6N4ujgGdkxjYKZFRPdsxumd7EmOabnLykvIAv5+/nvF9OnD2UY9NCAYd5cEgMZG1v4RTRKQ50HMARUREpNEVlflZtj2XhZuz+XxLDku3HSQ1IZq/XzX2mCIr3GKjIrj7/KFVtvl8RoxPxZ+ItE4qAEVERKRW9hWUsHl/IXnF5eQXl7P5QCELN2ezMisPf9DhMxjWLYWZk/ryvUn96v34BRERaTgqAEVERKRazjnyS/zsLyjlk8wDvLFqN4u35hB6B0mkzzgpPYUbJvVlfJ8OZPRqX+UELCIiEn4qAEVERNq4Un+AL3cXsCIrl1VZeezJLyH7UBnZhaXkFJZRHviq2hvQKZFbvzGAcb070C4+ipS4KNKSYur0yAMREWl6KgBFRETaoH0FJby3bh8L1u7lk8wDlPqDAHRMjCa9fcVMncO7J5OaGENqQjSpidEM75bCgJAHqIuISMujAlBERKSVKikPsD2niM37C9lyoJCtByreNx8o5MChUgDS28dx+fiejO/TgZE92tEtJfaEj10QEZGWSwWgiIhICxYIOnYeLGbzgUNs8Qq8ytfO3OIj7tVLS4qhT2oCZw7uRL9OCUwamMagzid+zp6IiLQeKgBFRESaAecce/NLWbUzj7W78tlxsIidB4vZnVdMmT9IZR0XE+kjPjqS+OgIDhaVsT2n6Ih79JJiIumblkBGr/ZcPDadPh0T6Nsxkd4d4zUxi4iIqAAUERFpKqX+AFsPFLF8x0GWbc9lw94CisoClPqD5BWXk1NYBoAZdE6KpXv7OEaktyM20nd4G2WBIIWlAQpL/fTvlMjkYV3o0zHh8Cs1IVojeiIiUi0VgCIiIjVQ6g+wJ6+E3Xkl7M4rZlduCXvySigqCxAIBvEHHYGgwx90+ANHfi4o8bM3v+RwgQeQEhfF0K4Vk6zERkWQGBPBoM5JjEhPYUjXZOKj9StaREQann67iIiIUHEJ5v6CUr7YnsuyHQdZuyufvOJyCkr85BaVcbCo/Jh1UuKiSIyJJDLCiPAZkT4jwucjKuRzpM9Ht5RYRvdsR5fkWNLbxzGqRzv6dEzQSJ2IiDQ5FYAiItJiOOfILixj58FiDhwqJbuwjNyiMpJio+icHENaYiz5JeXsyClix8EiCkr8lAcqRuTKA0HKK0fnAu7wcmFZgAMFpew/VEqZ9yiE6Agfg7okkZoYTa/UBJJjI+mcHEvXlFi6tYujS0rFskbpRESkpdFvLhERaRLOOYrLAxSVBSgqDVBU7qewNEBxWYDCMj9FZf6v2soCFJX5OVTq52BRGTmFZRw4VFH4FZcHarS/CJ+RFBtJpDciFxlhREX4iPL5iIwwIiN8RPmM5NhI+nVMIC0phi4psYzs0Y5h3ZKJidSDzUVEpPVRASgiIsco8wc5VOrnUElFEVZU5qewLEBxWUXRVlQeoKjUf7hQq3g/crmw9Mh4cXngiEcSnEhMpI/EmEjaJ0TTIT6a/mmJnD4wjR7t4+jePp60pIoHlLeLjzp8j92+glKSYiPp4T3IPDLCd+IdiYiItCHNvgA0synAn4EI4HHn3H1hTklEpN6ccwQdlAeCR0wc8tWywx+s+FweqJxMJHi4LRB0lAeDBAJe/2CQ0vIg2YWlHDhURvahssPbDt1H5XaO+Oxtr8Qf4FCJn4JS/+FLIWsiLiqChJgI4qIjSPAeTxAfHUlqQnTFckwk8VHee3QECdERxEVHeu8RJMREetv4KhYfHUmEr+b3xyXFRtGtXVxd/lOIiIi0Kc26ADSzCOBh4JtAFrDYzOY559aGNzOR43PO4RyHn9vlnMOBF3NHjIKExqrqj9f+Vd+j2vHaD7d9FTuif232GZLj0Xkfvf3Q7VWVI0dt84gcj/q5UM0+i8oC3mhUOf7gVwdSOYGGHf5cseyAoINg0BF0joB3/AGv4HFe7Ig+QQi6yuWv2gLuyBkdK4qxKgqxkKIttLCqsojzirbGEhPpIzUhmpioiJCJSSoueaxcjorwERv11aQlkT4jJspHUmwkiTFR3nvFKyGmojirLOxC3+OiIvDVolATERGR8GrWBSAwHsh0zm0GMLO5wFSg2gJww94Czvrjf46IuSquOaryq1c138eqCtd4m0AVXXFV9K6yXy2+IzZVTtVtt+q+9d1mPY+pFut/VUAdW1wdLpRqUIxJ82cGPjMizDCruFfMZ4YvdNlX8TnS5/OKp+pneIyJivQ+ewVWhBEVUlhVu26E74jlr4qzqtf9armigAvNofL+ttTEaJJiIjW7pIiIiFSpuReA3YEdIZ+zgAlHdzKzmcBMgORufRnUOenYLVXxXaiqr0fVfWmqum/N+lW33Sr7VrnNanKq8TFVk1MVvavcZrXfI2u4fmPkVF1GNfzSe7z9V44imR01wmRHtldu54hYSP/QtiNilX2smn1yVLvZ4bavtlPLfVYkH5K3heRTk30emSMh/S2kP0dvs7p9HpVj1T/brz7HRUeQFBNFYmwkURF2ZMFdxYgkcLiA+6q4++qziiMRERFpq5p7AVjVt7Rjxlmcc7OAWQAZGRnu4SvGNHZeIiIiIiIiLU5znx4tC+gR8jkd2BWmXERERERERFq05l4ALgYGmFkfM4sGpgPzwpyTiIiIiIhIi9SsLwF1zvnN7PvAfCoeA/Gkc25NmNMSERERERFpkZp1AQjgnHsTeDPceYiIiIiIiLR0zf0SUBEREREREWkgKgBFRERERETaCBWAIiIiIiIibYQKQBERERERkTbCnDvmueotmpnlARvDtPsUIC9M++4IHAjTvsN53OHcd7j3r/NN+24L+26r51q4999W991Wzzftu+mF81yDtvtzb0v77uWcS6uyxTnXql7ArDa67yVt9LjDtu9w71/nm/bdRvbdJs+1cO+/De+7TZ5v2ndY9h22c60ZHLv2HeZXa7wE9PU2uu9wass/87Z87OHSVn/mbXXf4RTu426r/83D/XMPl7b6M2+r+w63tvpzb6v7PkKruwS0rTKzJc65jHDnIW2DzjdpKjrXpCnpfJOmonNNwqk1jgC2VbPCnYC0KTrfpKnoXJOmpPNNmorONQkbjQCKiIiIiIi0ERoBFBERERERaSNUAIqIiIiIiLQRKgCbMTN70sz2mdnqkNgLZrbce201s+Ve/IqQ+HIzC5rZKK9trJmtMrNMM3vIzCxcxyTNUzXn2igz+9w7n5aY2XgvfoWZrfRen5rZyJB1ppjZeu9cuzMcxyLNXy3Ptx+H/Lu22swCZtbBa9P5JsdVzbk20sw+834vvm5myV78m2a21IsvNbNvhKyj36NyQrU83/S9TcIn3M+h0Kv6FzAJGAOsrqb9D8DPq4iPADaHfF4EnAwY8BZwTriPTa/m9arqXAPeqTxXgHOBD73lrwHtveVzgIXecgSwCegLRAMrgKHhPja9mt+rNufbUetdALzvLet80+uEr2rOtcXA6d7ytcCvveXRQDdveTiwM2Qd/R7V64Sv2pxvR62n7216NelLI4DNmHPuv0BOVW3eX4MuBeZU0Xx5ZdzMugLJzrnPnHMOeAaY1jgZS0tVzbnmgGRvOQXY5fX91Dl30It/DqR7y+OBTOfcZudcGTAXmNqoiUuLVJvz7SiH/21D55vUQDXn2iDgv97yAuDbXt9lzrnK824NEGtmMfo9KjVVm/PtKPreJk0qMtwJSJ2dBux1zm2sou0yvvoi1B3ICmnL8mIiJ/JDYL6ZPUDF5eJfq6LPdVT8dRIqzqsdIW1ZwIRGzVBak+Oeb2YWD0wBvu+FdL5JXa0GLgReAy4BelTR59vAMudcqZnp96jUR03ON31vkyalEcCWK/Qv4YeZ2QSgyDlXef15VdeN69kfUhM3Abc553oAtwFPhDaa2depKADvqAxVsQ2da1JTxz3fqLj88xPnXOVf13W+SV1dC9xiZkuBJKAstNHMhgH3AzdWhqrYhs41qakTnW/63iZNTiOALZCZRQLfAsZW0TydIwvDLL66RA9vuapLq0SONgP4gbf8EvB4ZYOZneR9Psc5l+2FszjyL5s616Q2qj3fPFX926bzTWrNOfclMBnAzAYC51W2mVk68CpwtXNukxfW71Gps+Odbx59b5MmpxHAluks4EvnXOglApiZj4rLC+ZWxpxzu4ECM5vo3Td4NRWXIYicyC7gdG/5G8BGADPrCfwTuMo5tyGk/2JggJn1MbNoKn6pzWvCfKVlq/J8AzCzFK8t9N8unW9SJ2bWyXv3AT8D/uZ9bge8AdzlnPuksr9+j0p9VHe+hcT0vU2anEYAmzEzmwOcAXQ0syzgHufcExz716JKk4As59zmo+I3AU8DcVTcr/UWIiGqOteAG4A/eyPOJcBMr/vPgVTgEW9mar9zLsM55zez7wPzqZih8Unn3JqmPRJpCWp5vgFcBLzjnCusDOh8k5qo5lxLNLNbvC7/BJ7ylr8P9AfuNrO7vdhk59w+9HtUaqCW5xvoe5uEiVVMMCQiIiIiIiKtnS4BFRERERERaSNUAIqIiIiIiLQRKgBFRERERETaCBWAIiIiIiIibYQKQBERERERkTbi/7dfBwIAAAAAgvytB7ksEkAAAIAJAQQAAJgIliNjysoZ918AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "result.trend.plot(label='$CO^{2}$ emissions - trend')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "intensive-namibia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "result.resid.plot(label='$CO^{2}$ emissions - residuals')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-wound",
   "metadata": {},
   "source": [
    "Running the plots of the observed, trend, seasonal, and residual time series, we can see that the results doesn't interesting. So let's try another approach to extract some insights about the time series. Next, the amount of carbon dioxide emission will be analyzed every 50 years, since 1850."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "checked-symphony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>co2</th>\n",
       "      <th>period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1850-12-31</td>\n",
       "      <td>944.824</td>\n",
       "      <td>1850 to 1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1851-12-31</td>\n",
       "      <td>944.689</td>\n",
       "      <td>1850 to 1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1852-12-31</td>\n",
       "      <td>984.086</td>\n",
       "      <td>1850 to 1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1853-12-31</td>\n",
       "      <td>1025.620</td>\n",
       "      <td>1850 to 1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1854-12-31</td>\n",
       "      <td>1209.253</td>\n",
       "      <td>1850 to 1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>2015-12-31</td>\n",
       "      <td>123813.289</td>\n",
       "      <td>&gt; 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>123890.716</td>\n",
       "      <td>&gt; 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>125438.734</td>\n",
       "      <td>&gt; 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>127746.944</td>\n",
       "      <td>&gt; 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>127568.915</td>\n",
       "      <td>&gt; 2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     timestamp         co2        period\n",
       "0   1850-12-31     944.824  1850 to 1900\n",
       "1   1851-12-31     944.689  1850 to 1900\n",
       "2   1852-12-31     984.086  1850 to 1900\n",
       "3   1853-12-31    1025.620  1850 to 1900\n",
       "4   1854-12-31    1209.253  1850 to 1900\n",
       "..         ...         ...           ...\n",
       "165 2015-12-31  123813.289        > 2000\n",
       "166 2016-12-31  123890.716        > 2000\n",
       "167 2017-12-31  125438.734        > 2000\n",
       "168 2018-12-31  127746.944        > 2000\n",
       "169 2019-12-31  127568.915        > 2000\n",
       "\n",
       "[170 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts50 = ts['1850':].reset_index().rename(columns={'index':'timestamp'})\n",
    "\n",
    "def classify_period(x):\n",
    "    if x.year >= 1850 and x.year <= 1900:\n",
    "        return '1850 to 1900'\n",
    "    if x.year > 1900 and x.year <= 1950:\n",
    "        return '1900 to 1950'\n",
    "    if x.year > 1950 and x.year <= 2000:\n",
    "        return '1950 to 2000'\n",
    "    if x.year > 2000:\n",
    "        return '> 2000'\n",
    "    \n",
    "ts50['period'] = ts50['timestamp'].apply(classify_period)\n",
    "ts50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "explicit-corps",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning:\n",
      "\n",
      "Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# source: https://stackoverflow.com/questions/52273543/creating-multiple-boxplots-on-the-same-graph-from-a-dictionary/52274064\n",
    "d = {\n",
    "    '1850 to 1900': list(ts50[ts50.period == '1850 to 1900'].co2.values),\n",
    "    '1900 to 1950': list(ts50[ts50.period == '1900 to 1950'].co2.values),\n",
    "    '1950 to 2000': list(ts50[ts50.period == '1950 to 2000'].co2.values),\n",
    "    '> 2000': list(ts50[ts50.period == '> 2000'].co2.values),\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.boxplot(d.values())\n",
    "ax.set_xticklabels(d.keys())\n",
    "plt.title('$CO^{2}$ emissions by period')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "average-roman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co2</th>\n",
       "      <th>percetual_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>period</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1850 to 1900</th>\n",
       "      <td>3511.905941</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900 to 1950</th>\n",
       "      <td>14672.126920</td>\n",
       "      <td>317.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950 to 2000</th>\n",
       "      <td>62801.521540</td>\n",
       "      <td>1688.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt; 2000</th>\n",
       "      <td>115070.215526</td>\n",
       "      <td>3176.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        co2  percetual_change\n",
       "period                                       \n",
       "1850 to 1900    3511.905941              0.00\n",
       "1900 to 1950   14672.126920            317.78\n",
       "1950 to 2000   62801.521540           1688.25\n",
       "> 2000        115070.215526           3176.57"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = ts50.groupby('period').mean()\n",
    "grouped['percetual_change'] = round((grouped.co2 - grouped.iloc[0].co2) / grouped.iloc[0].co2 * 100, 2)\n",
    "grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-cleveland",
   "metadata": {},
   "source": [
    "In the boxplot it is possible to observe the variation in the quartiles of carbon dioxide emission in the periods from 1850 to 1900, 1900 to 1950, 1950 to 2000, and 2000 to 2019. The annual averages of global carbon dioxide emissions in the period from 1950 to 2000 increased by 1,688% compared to the period from 1850 to 1900, and in the period from 2000 to 2019 emissions increased by 3,176%.\n",
    "\n",
    "Another interesting approach could be check the percentual variation year by year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cloudy-registrar",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co2</th>\n",
       "      <th>percetual_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1850-12-31</th>\n",
       "      <td>944.824</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851-12-31</th>\n",
       "      <td>944.689</td>\n",
       "      <td>-0.014288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852-12-31</th>\n",
       "      <td>984.086</td>\n",
       "      <td>4.170367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853-12-31</th>\n",
       "      <td>1025.620</td>\n",
       "      <td>4.220566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854-12-31</th>\n",
       "      <td>1209.253</td>\n",
       "      <td>17.904585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-31</th>\n",
       "      <td>123813.289</td>\n",
       "      <td>0.066294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31</th>\n",
       "      <td>123890.716</td>\n",
       "      <td>0.062535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>125438.734</td>\n",
       "      <td>1.249503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>127746.944</td>\n",
       "      <td>1.840109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>127568.915</td>\n",
       "      <td>-0.139361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   co2  percetual_change\n",
       "1850-12-31     944.824               NaN\n",
       "1851-12-31     944.689         -0.014288\n",
       "1852-12-31     984.086          4.170367\n",
       "1853-12-31    1025.620          4.220566\n",
       "1854-12-31    1209.253         17.904585\n",
       "...                ...               ...\n",
       "2015-12-31  123813.289          0.066294\n",
       "2016-12-31  123890.716          0.062535\n",
       "2017-12-31  125438.734          1.249503\n",
       "2018-12-31  127746.944          1.840109\n",
       "2019-12-31  127568.915         -0.139361\n",
       "\n",
       "[170 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsbar = ts['1850':]\n",
    "tsbar['percetual_change'] = tsbar.pct_change() * 100\n",
    "tsbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "municipal-mercy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "plt.plot(tsbar.percetual_change, label='$CO^{2}$ emissions - percentual change')\n",
    "plt.ylabel('%')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "still-pakistan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    169.000000\n",
       "mean       3.066116\n",
       "std        4.923850\n",
       "min      -20.324288\n",
       "25%        0.835550\n",
       "50%        3.084643\n",
       "75%        5.701284\n",
       "max       17.904585\n",
       "Name: percetual_change, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsbar.percetual_change.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-colleague",
   "metadata": {},
   "source": [
    "We can conclude so far that, on average, the percentage change from year to year is approximately 3%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-forum",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "rocky-mortgage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1750-12-31       46.755\n",
       "1751-12-31       46.755\n",
       "1752-12-31       46.770\n",
       "1753-12-31       46.770\n",
       "1754-12-31       46.790\n",
       "                ...    \n",
       "1995-12-31    87252.937\n",
       "1996-12-31    89621.706\n",
       "1997-12-31    89708.397\n",
       "1998-12-31    89286.496\n",
       "1999-12-31    90256.260\n",
       "Freq: A-DEC, Name: co2, Length: 250, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series = make_time_series(ts.co2)\n",
    "time_series[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "loving-review",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1750-12-31       46.755\n",
       "1751-12-31       46.755\n",
       "1752-12-31       46.770\n",
       "1753-12-31       46.770\n",
       "1754-12-31       46.790\n",
       "                ...    \n",
       "1990-12-31    88010.112\n",
       "1991-12-31    88534.589\n",
       "1992-12-31    85683.429\n",
       "1993-12-31    85945.146\n",
       "1994-12-31    85845.104\n",
       "Freq: A-DEC, Name: co2, Length: 245, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series_training = create_training_series(time_series, 5)\n",
    "time_series_training[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "excited-general",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display train/test time series\n",
    "time_series_idx = 0\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "time_series[time_series_idx].plot(label='Test', lw=3) # test data is the whole time series\n",
    "time_series_training[time_series_idx].plot(label='Train', ls=':', lw=3, color='yellow') # train data is all but the last prediction pts\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "earlier-coupon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data to a local directory\n",
    "data_dir = 'json_data'\n",
    "\n",
    "# make data dir, if it does not exist\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "hollywood-niagara",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json_data/train.json saved.\n",
      "json_data/test.json saved.\n"
     ]
    }
   ],
   "source": [
    "# directories to save train/test data\n",
    "train_key = os.path.join(data_dir, 'train.json')\n",
    "test_key = os.path.join(data_dir, 'test.json')\n",
    "\n",
    "# write train/test JSON files\n",
    "write_json_dataset(time_series_training, train_key)        \n",
    "write_json_dataset(time_series, test_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-camera",
   "metadata": {},
   "source": [
    "# Uploading data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ceramic-annual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data is stored in: s3://sagemaker-sa-east-1-072590943848/co2-emission/train/train.json\n",
      "Test data is stored in: s3://sagemaker-sa-east-1-072590943848/co2-emission/test/test.json\n"
     ]
    }
   ],
   "source": [
    "# session, role, bucket\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "# general prefix\n",
    "prefix = 'co2-emission'\n",
    "\n",
    "# *unique* train/test prefixes\n",
    "train_prefix = '{}/{}'.format(prefix, 'train')\n",
    "test_prefix = '{}/{}'.format(prefix, 'test')\n",
    "\n",
    "# uploading data to S3, and saving locations\n",
    "train_path = sagemaker_session.upload_data(train_key, bucket=bucket, key_prefix=train_prefix)\n",
    "test_path = sagemaker_session.upload_data(test_key,  bucket=bucket, key_prefix=test_prefix)\n",
    "\n",
    "# check locations\n",
    "print('Training data is stored in: '+ train_path)\n",
    "print('Test data is stored in: '+ test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-taxation",
   "metadata": {},
   "source": [
    "# Training a DeepAR Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "mobile-highway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sa-east-1'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region = sagemaker_session.boto_region_name\n",
    "region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "competent-distinction",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: latest.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'855470959533.dkr.ecr.sa-east-1.amazonaws.com/forecasting-deepar:1'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_name = sagemaker.amazon.amazon_estimator.get_image_uri(region, 'forecasting-deepar', 'latest')\n",
    "image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "competitive-covering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-sa-east-1-072590943848/co2-emission/output'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dir to save model artifacts\n",
    "s3_output_path = \"s3://{}/{}/output\".format(bucket, prefix)\n",
    "s3_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "union-delta",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=image_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c4.2xlarge',\n",
    "    base_job_name='deepar-co2-emission',\n",
    "    output_path=s3_output_path\n",
    ")\n",
    "\n",
    "freq = '12M'\n",
    "\n",
    "hyperparameters = {\n",
    "    'time_freq': freq,\n",
    "    'epochs': '400',\n",
    "    'early_stopping_patience': '40',\n",
    "    'mini_batch_size': '64',\n",
    "    'learning_rate': '5E-4',\n",
    "    'context_length': '5',\n",
    "    'prediction_length': '5'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "determined-canada",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "southwest-fever",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-22 18:50:42 Starting - Starting the training job...\n",
      "2021-02-22 18:50:46 Starting - Launching requested ML instancesProfilerReport-1614019842: InProgress\n",
      "......\n",
      "2021-02-22 18:52:13 Starting - Preparing the instances for training......\n",
      "2021-02-22 18:53:07 Downloading - Downloading input data...\n",
      "2021-02-22 18:53:25 Training - Downloading the training image...\n",
      "2021-02-22 18:54:05 Training - Training image download completed. Training in progress.\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:00 INFO 140707827689280] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:00 INFO 140707827689280] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'5E-4', u'prediction_length': u'5', u'epochs': u'400', u'time_freq': u'12M', u'context_length': u'5', u'mini_batch_size': u'64', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:00 INFO 140707827689280] Final configuration: {u'dropout_rate': u'0.10', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'num_eval_samples': u'100', u'learning_rate': u'5E-4', u'num_layers': u'2', u'epochs': u'400', u'embedding_dimension': u'10', u'num_cells': u'40', u'_num_kv_servers': u'auto', u'mini_batch_size': u'64', u'likelihood': u'student-t', u'num_dynamic_feat': u'auto', u'cardinality': u'auto', u'_num_gpus': u'auto', u'prediction_length': u'5', u'time_freq': u'12M', u'context_length': u'5', u'_kvstore': u'auto', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:00 INFO 140707827689280] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] Using early stopping with patience 40\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] [num_dynamic_feat=auto] `dynamic_feat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] Training set statistics:\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] Real time series\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] number of time series: 4\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] number of observations: 1010\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] mean target length: 252\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] min/mean/max target: 46.7550010681/16842.5960396/114658.898438\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] mean abs(target): 16842.5960396\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] contains missing values: no\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] Small number of time series. Doing 160 passes over dataset with prob 1.0 per epoch.\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] Test set statistics:\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] Real time series\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] number of time series: 4\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] number of observations: 1030\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] mean target length: 257\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] min/mean/max target: 46.7550010681/18551.134466/123731.265625\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] mean abs(target): 18551.134466\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] contains missing values: no\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] nvidia-smi took: 0.025171995163 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 28.156042098999023, \"sum\": 28.156042098999023, \"min\": 28.156042098999023}}, \"EndTime\": 1614020041.091806, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020041.062887}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 75.8969783782959, \"sum\": 75.8969783782959, \"min\": 75.8969783782959}}, \"EndTime\": 1614020041.138892, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020041.091875}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] Epoch[0] Batch[0] avg_epoch_loss=9.176332\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=9.17633152008\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] Epoch[0] Batch[5] avg_epoch_loss=9.356293\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=9.35629288356\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] Epoch[0] Batch [5]#011Speed: 4077.31 samples/sec#011loss=9.356293\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] Epoch[0] Batch[10] avg_epoch_loss=9.423302\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=9.50371227264\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] Epoch[0] Batch [10]#011Speed: 3976.48 samples/sec#011loss=9.503712\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 400, \"sum\": 400.0, \"min\": 400}, \"update.time\": {\"count\": 1, \"max\": 454.00500297546387, \"sum\": 454.00500297546387, \"min\": 454.00500297546387}}, \"EndTime\": 1614020041.593072, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020041.138973}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1431.3114285 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] #quality_metric: host=algo-1, epoch=0, train loss <loss>=9.42330169678\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] Saved checkpoint to \"/opt/ml/model/state_5afdb8dc-9437-4b93-a9c0-0b669d855894-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 12.299060821533203, \"sum\": 12.299060821533203, \"min\": 12.299060821533203}}, \"EndTime\": 1614020041.606009, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020041.593159}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] Epoch[1] Batch[0] avg_epoch_loss=8.672832\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=8.67283248901\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] Epoch[1] Batch[5] avg_epoch_loss=8.674664\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=8.67466417948\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] Epoch[1] Batch [5]#011Speed: 4291.27 samples/sec#011loss=8.674664\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 319.3371295928955, \"sum\": 319.3371295928955, \"min\": 319.3371295928955}}, \"EndTime\": 1614020041.925454, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020041.606069}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1931.57789425 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] #quality_metric: host=algo-1, epoch=1, train loss <loss>=8.4585796833\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:01 INFO 140707827689280] Saved checkpoint to \"/opt/ml/model/state_8941b20a-a00c-40a2-a437-b02a228a7301-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 7.762908935546875, \"sum\": 7.762908935546875, \"min\": 7.762908935546875}}, \"EndTime\": 1614020041.933846, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020041.925514}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] Epoch[2] Batch[0] avg_epoch_loss=8.790515\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=8.79051494598\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] Epoch[2] Batch[5] avg_epoch_loss=8.430982\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=8.43098187447\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] Epoch[2] Batch [5]#011Speed: 4366.04 samples/sec#011loss=8.430982\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] Epoch[2] Batch[10] avg_epoch_loss=8.459177\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=8.49301128387\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] Epoch[2] Batch [10]#011Speed: 5591.47 samples/sec#011loss=8.493011\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] processed a total of 705 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 331.48884773254395, \"sum\": 331.48884773254395, \"min\": 331.48884773254395}}, \"EndTime\": 1614020042.265455, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020041.933912}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2126.01758917 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] #quality_metric: host=algo-1, epoch=2, train loss <loss>=8.30599415302\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] Saved checkpoint to \"/opt/ml/model/state_0c8d48a7-ca9f-4e87-9e0d-e2de5b0b7901-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.092020034790039, \"sum\": 10.092020034790039, \"min\": 10.092020034790039}}, \"EndTime\": 1614020042.276113, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020042.265539}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] Epoch[3] Batch[0] avg_epoch_loss=7.880038\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=7.88003826141\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] Epoch[3] Batch[5] avg_epoch_loss=7.982010\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=7.98201028506\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] Epoch[3] Batch [5]#011Speed: 5096.92 samples/sec#011loss=7.982010\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 292.8810119628906, \"sum\": 292.8810119628906, \"min\": 292.8810119628906}}, \"EndTime\": 1614020042.569101, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020042.27617}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2180.9158941 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] #quality_metric: host=algo-1, epoch=3, train loss <loss>=7.90087971687\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] Saved checkpoint to \"/opt/ml/model/state_703a2718-a6c8-46a8-b0d0-85d95b383906-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.635137557983398, \"sum\": 10.635137557983398, \"min\": 10.635137557983398}}, \"EndTime\": 1614020042.580304, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020042.569182}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] Epoch[4] Batch[0] avg_epoch_loss=8.125753\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=8.12575340271\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] Epoch[4] Batch[5] avg_epoch_loss=7.687179\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=7.68717869123\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] Epoch[4] Batch [5]#011Speed: 4928.69 samples/sec#011loss=7.687179\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 304.8880100250244, \"sum\": 304.8880100250244, \"min\": 304.8880100250244}}, \"EndTime\": 1614020042.885311, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020042.580366}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2058.99662856 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] #quality_metric: host=algo-1, epoch=4, train loss <loss>=7.5480275631\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:02 INFO 140707827689280] Saved checkpoint to \"/opt/ml/model/state_a511ba85-5fa4-457e-b38b-00b1c6c327ee-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 7.602214813232422, \"sum\": 7.602214813232422, \"min\": 7.602214813232422}}, \"EndTime\": 1614020042.893529, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020042.885386}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] Epoch[5] Batch[0] avg_epoch_loss=7.756991\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=7.75699090958\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] Epoch[5] Batch[5] avg_epoch_loss=7.377396\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=7.37739562988\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] Epoch[5] Batch [5]#011Speed: 5510.01 samples/sec#011loss=7.377396\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] processed a total of 606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 285.95590591430664, \"sum\": 285.95590591430664, \"min\": 285.95590591430664}}, \"EndTime\": 1614020043.1796, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020042.893589}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2118.43598931 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] #quality_metric: host=algo-1, epoch=5, train loss <loss>=7.51564974785\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] Saved checkpoint to \"/opt/ml/model/state_2a7c5747-dc22-4db8-a046-93074c6ef7f7-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.65206527709961, \"sum\": 10.65206527709961, \"min\": 10.65206527709961}}, \"EndTime\": 1614020043.190799, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020043.179669}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] Epoch[6] Batch[0] avg_epoch_loss=7.097783\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=7.09778261185\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] Epoch[6] Batch[5] avg_epoch_loss=7.123069\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=7.12306857109\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] Epoch[6] Batch [5]#011Speed: 3946.28 samples/sec#011loss=7.123069\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 380.4798126220703, \"sum\": 380.4798126220703, \"min\": 380.4798126220703}}, \"EndTime\": 1614020043.571408, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020043.190867}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1597.4727658 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] #quality_metric: host=algo-1, epoch=6, train loss <loss>=6.96601133347\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] Saved checkpoint to \"/opt/ml/model/state_7c07e627-4f3c-4eb0-9188-a7ccab193f5d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.374069213867188, \"sum\": 10.374069213867188, \"min\": 10.374069213867188}}, \"EndTime\": 1614020043.582423, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020043.571489}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] Epoch[7] Batch[0] avg_epoch_loss=6.323324\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=6.32332420349\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] Epoch[7] Batch[5] avg_epoch_loss=6.931955\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=6.93195486069\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] Epoch[7] Batch [5]#011Speed: 2478.08 samples/sec#011loss=6.931955\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 411.4720821380615, \"sum\": 411.4720821380615, \"min\": 411.4720821380615}}, \"EndTime\": 1614020043.994027, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020043.582496}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1545.26426815 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] #quality_metric: host=algo-1, epoch=7, train loss <loss>=6.90654964447\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:03 INFO 140707827689280] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:04 INFO 140707827689280] Saved checkpoint to \"/opt/ml/model/state_49f83764-7515-41cf-adb9-2ae48d07c9c9-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 11.407852172851562, \"sum\": 11.407852172851562, \"min\": 11.407852172851562}}, \"EndTime\": 1614020044.00598, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020043.994098}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:04 INFO 140707827689280] Epoch[8] Batch[0] avg_epoch_loss=7.142762\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:04 INFO 140707827689280] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=7.14276170731\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:04 INFO 140707827689280] Epoch[8] Batch[5] avg_epoch_loss=7.008084\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:04 INFO 140707827689280] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=7.0080836614\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:04 INFO 140707827689280] Epoch[8] Batch [5]#011Speed: 4238.87 samples/sec#011loss=7.008084\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:04 INFO 140707827689280] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 358.7028980255127, \"sum\": 358.7028980255127, \"min\": 358.7028980255127}}, \"EndTime\": 1614020044.365026, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020044.006257}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:04 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1727.86766387 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:04 INFO 140707827689280] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:04 INFO 140707827689280] #quality_metric: host=algo-1, epoch=8, train loss <loss>=7.11887731552\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:04 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:04 INFO 140707827689280] Epoch[9] Batch[0] avg_epoch_loss=6.412824\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:04 INFO 140707827689280] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=6.4128241539\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:04 INFO 140707827689280] Epoch[9] Batch[5] avg_epoch_loss=6.799971\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:04 INFO 140707827689280] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=6.79997134209\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:04 INFO 140707827689280] Epoch[9] Batch [5]#011Speed: 4647.04 samples/sec#011loss=6.799971\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:04 INFO 140707827689280] Epoch[9] Batch[10] avg_epoch_loss=6.743303\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:04 INFO 140707827689280] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=6.67530202866\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:04 INFO 140707827689280] Epoch[9] Batch [10]#011Speed: 5052.66 samples/sec#011loss=6.675302\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:04 INFO 140707827689280] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 361.569881439209, \"sum\": 361.569881439209, \"min\": 361.569881439209}}, \"EndTime\": 1614020044.727107, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020044.36511}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:04 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1808.23884186 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:04 INFO 140707827689280] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:04 INFO 140707827689280] #quality_metric: host=algo-1, epoch=9, train loss <loss>=6.74330347235\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:04 INFO 140707827689280] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:04 INFO 140707827689280] Saved checkpoint to \"/opt/ml/model/state_31f0c6ef-e9fc-4222-8f3e-df858ed35f91-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 11.027097702026367, \"sum\": 11.027097702026367, \"min\": 11.027097702026367}}, \"EndTime\": 1614020044.738715, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020044.72718}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:04 INFO 140707827689280] Epoch[10] Batch[0] avg_epoch_loss=7.009385\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:04 INFO 140707827689280] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=7.00938463211\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:04 INFO 140707827689280] Epoch[10] Batch[5] avg_epoch_loss=6.786370\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:04 INFO 140707827689280] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=6.78636995951\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:04 INFO 140707827689280] Epoch[10] Batch [5]#011Speed: 4268.89 samples/sec#011loss=6.786370\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:05 INFO 140707827689280] processed a total of 598 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 302.28209495544434, \"sum\": 302.28209495544434, \"min\": 302.28209495544434}}, \"EndTime\": 1614020045.041105, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020044.738767}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:05 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1977.62475656 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:05 INFO 140707827689280] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:05 INFO 140707827689280] #quality_metric: host=algo-1, epoch=10, train loss <loss>=6.62587375641\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:05 INFO 140707827689280] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:05 INFO 140707827689280] Saved checkpoint to \"/opt/ml/model/state_7c13362a-514d-414a-bc98-a19c7524d610-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 9.037017822265625, \"sum\": 9.037017822265625, \"min\": 9.037017822265625}}, \"EndTime\": 1614020045.050726, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020045.041169}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:05 INFO 140707827689280] Epoch[11] Batch[0] avg_epoch_loss=7.134227\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:05 INFO 140707827689280] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=7.13422679901\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:05 INFO 140707827689280] Epoch[11] Batch[5] avg_epoch_loss=6.942232\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:05 INFO 140707827689280] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=6.94223165512\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:05 INFO 140707827689280] Epoch[11] Batch [5]#011Speed: 4211.08 samples/sec#011loss=6.942232\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:05 INFO 140707827689280] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 310.1470470428467, \"sum\": 310.1470470428467, \"min\": 310.1470470428467}}, \"EndTime\": 1614020045.36097, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020045.050767}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:05 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1998.27294257 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:05 INFO 140707827689280] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:05 INFO 140707827689280] #quality_metric: host=algo-1, epoch=11, train loss <loss>=6.85535736084\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:05 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:05 INFO 140707827689280] Epoch[12] Batch[0] avg_epoch_loss=6.639839\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:05 INFO 140707827689280] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=6.63983917236\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:05 INFO 140707827689280] Epoch[12] Batch[5] avg_epoch_loss=6.730620\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:05 INFO 140707827689280] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=6.73061951001\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:05 INFO 140707827689280] Epoch[12] Batch [5]#011Speed: 4242.35 samples/sec#011loss=6.730620\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:05 INFO 140707827689280] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 364.2451763153076, \"sum\": 364.2451763153076, \"min\": 364.2451763153076}}, \"EndTime\": 1614020045.725779, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020045.361053}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:05 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1742.84869956 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:05 INFO 140707827689280] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:05 INFO 140707827689280] #quality_metric: host=algo-1, epoch=12, train loss <loss>=6.79318823814\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:05 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:05 INFO 140707827689280] Epoch[13] Batch[0] avg_epoch_loss=7.108858\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:05 INFO 140707827689280] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=7.10885763168\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] Epoch[13] Batch[5] avg_epoch_loss=6.630859\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=6.63085897764\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] Epoch[13] Batch [5]#011Speed: 3893.56 samples/sec#011loss=6.630859\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 355.56483268737793, \"sum\": 355.56483268737793, \"min\": 355.56483268737793}}, \"EndTime\": 1614020046.081873, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020045.725842}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1759.95478445 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] #quality_metric: host=algo-1, epoch=13, train loss <loss>=6.68021039963\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] Epoch[14] Batch[0] avg_epoch_loss=7.340814\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=7.34081411362\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] Epoch[14] Batch[5] avg_epoch_loss=6.816944\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=6.81694428126\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] Epoch[14] Batch [5]#011Speed: 3848.56 samples/sec#011loss=6.816944\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] Epoch[14] Batch[10] avg_epoch_loss=6.765245\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=6.70320615768\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] Epoch[14] Batch [10]#011Speed: 4315.24 samples/sec#011loss=6.703206\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 390.2089595794678, \"sum\": 390.2089595794678, \"min\": 390.2089595794678}}, \"EndTime\": 1614020046.472691, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020046.081963}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1719.12825149 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] #quality_metric: host=algo-1, epoch=14, train loss <loss>=6.76524513418\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] Epoch[15] Batch[0] avg_epoch_loss=6.498451\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=6.49845123291\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] Epoch[15] Batch[5] avg_epoch_loss=6.712370\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=6.71237007777\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] Epoch[15] Batch [5]#011Speed: 4046.48 samples/sec#011loss=6.712370\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] Epoch[15] Batch[10] avg_epoch_loss=6.639677\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=6.55244598389\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] Epoch[15] Batch [10]#011Speed: 4348.88 samples/sec#011loss=6.552446\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] processed a total of 689 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 391.87002182006836, \"sum\": 391.87002182006836, \"min\": 391.87002182006836}}, \"EndTime\": 1614020046.865203, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020046.472762}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1757.72486832 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] #quality_metric: host=algo-1, epoch=15, train loss <loss>=6.63967730782\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:06 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] Epoch[16] Batch[0] avg_epoch_loss=6.158398\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=6.15839767456\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] Epoch[16] Batch[5] avg_epoch_loss=6.346193\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=6.34619315465\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] Epoch[16] Batch [5]#011Speed: 4318.08 samples/sec#011loss=6.346193\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] processed a total of 612 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 300.5189895629883, \"sum\": 300.5189895629883, \"min\": 300.5189895629883}}, \"EndTime\": 1614020047.166254, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020046.865278}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2035.71789255 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] #quality_metric: host=algo-1, epoch=16, train loss <loss>=6.39819717407\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] Saved checkpoint to \"/opt/ml/model/state_1976bada-2354-4a06-aca8-4e83c6f2db37-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.581016540527344, \"sum\": 10.581016540527344, \"min\": 10.581016540527344}}, \"EndTime\": 1614020047.177418, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020047.166329}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] Epoch[17] Batch[0] avg_epoch_loss=6.418223\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=6.41822290421\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] Epoch[17] Batch[5] avg_epoch_loss=6.418961\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=6.41896104813\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] Epoch[17] Batch [5]#011Speed: 4668.48 samples/sec#011loss=6.418961\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] Epoch[17] Batch[10] avg_epoch_loss=6.219697\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=5.98058028221\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] Epoch[17] Batch [10]#011Speed: 4295.89 samples/sec#011loss=5.980580\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 338.3350372314453, \"sum\": 338.3350372314453, \"min\": 338.3350372314453}}, \"EndTime\": 1614020047.51587, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020047.17748}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1956.08075599 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] #quality_metric: host=algo-1, epoch=17, train loss <loss>=6.21969706362\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] Saved checkpoint to \"/opt/ml/model/state_2c2d39c6-a8e0-427a-8272-479fe4bb57ed-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 7.048845291137695, \"sum\": 7.048845291137695, \"min\": 7.048845291137695}}, \"EndTime\": 1614020047.523515, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020047.51593}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] Epoch[18] Batch[0] avg_epoch_loss=6.866034\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=6.86603355408\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] Epoch[18] Batch[5] avg_epoch_loss=6.710612\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=6.71061174075\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] Epoch[18] Batch [5]#011Speed: 4460.50 samples/sec#011loss=6.710612\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 289.16287422180176, \"sum\": 289.16287422180176, \"min\": 289.16287422180176}}, \"EndTime\": 1614020047.812782, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020047.523573}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2171.05785151 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] #quality_metric: host=algo-1, epoch=18, train loss <loss>=6.63360676765\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] Epoch[19] Batch[0] avg_epoch_loss=6.419738\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:07 INFO 140707827689280] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=6.41973781586\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] Epoch[19] Batch[5] avg_epoch_loss=6.705640\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=6.70563968023\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] Epoch[19] Batch [5]#011Speed: 4476.03 samples/sec#011loss=6.705640\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] Epoch[19] Batch[10] avg_epoch_loss=6.786247\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=6.88297624588\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] Epoch[19] Batch [10]#011Speed: 4967.16 samples/sec#011loss=6.882976\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 310.97912788391113, \"sum\": 310.97912788391113, \"min\": 310.97912788391113}}, \"EndTime\": 1614020048.124313, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020047.812847}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2092.642051 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] #quality_metric: host=algo-1, epoch=19, train loss <loss>=6.78624721007\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] Epoch[20] Batch[0] avg_epoch_loss=6.651667\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=6.65166711807\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] Epoch[20] Batch[5] avg_epoch_loss=6.697845\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=6.69784466426\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] Epoch[20] Batch [5]#011Speed: 5306.26 samples/sec#011loss=6.697845\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] Epoch[20] Batch[10] avg_epoch_loss=6.792590\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] #quality_metric: host=algo-1, epoch=20, batch=10 train loss <loss>=6.90628461838\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] Epoch[20] Batch [10]#011Speed: 5353.57 samples/sec#011loss=6.906285\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 312.33716011047363, \"sum\": 312.33716011047363, \"min\": 312.33716011047363}}, \"EndTime\": 1614020048.43715, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020048.124388}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2070.78391151 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] #quality_metric: host=algo-1, epoch=20, train loss <loss>=6.79259009795\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] Epoch[21] Batch[0] avg_epoch_loss=6.050921\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=6.05092144012\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] Epoch[21] Batch[5] avg_epoch_loss=6.571401\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=6.57140119871\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] Epoch[21] Batch [5]#011Speed: 4528.16 samples/sec#011loss=6.571401\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] Epoch[21] Batch[10] avg_epoch_loss=6.480556\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=6.37154245377\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] Epoch[21] Batch [10]#011Speed: 5012.61 samples/sec#011loss=6.371542\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 332.69596099853516, \"sum\": 332.69596099853516, \"min\": 332.69596099853516}}, \"EndTime\": 1614020048.770344, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020048.43722}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1983.13808619 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] #quality_metric: host=algo-1, epoch=21, train loss <loss>=6.48055631464\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:08 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] Epoch[22] Batch[0] avg_epoch_loss=6.668583\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=6.6685833931\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] Epoch[22] Batch[5] avg_epoch_loss=6.606335\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=6.60633460681\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] Epoch[22] Batch [5]#011Speed: 4441.35 samples/sec#011loss=6.606335\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] Epoch[22] Batch[10] avg_epoch_loss=6.543818\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] #quality_metric: host=algo-1, epoch=22, batch=10 train loss <loss>=6.46879787445\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] Epoch[22] Batch [10]#011Speed: 4617.34 samples/sec#011loss=6.468798\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 376.6210079193115, \"sum\": 376.6210079193115, \"min\": 376.6210079193115}}, \"EndTime\": 1614020049.147469, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020048.770419}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1786.38249593 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] #quality_metric: host=algo-1, epoch=22, train loss <loss>=6.54381791028\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] Epoch[23] Batch[0] avg_epoch_loss=6.373825\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=6.37382507324\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] Epoch[23] Batch[5] avg_epoch_loss=6.361511\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=6.36151130994\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] Epoch[23] Batch [5]#011Speed: 5299.25 samples/sec#011loss=6.361511\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] Epoch[23] Batch[10] avg_epoch_loss=6.337153\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=6.30792207718\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] Epoch[23] Batch [10]#011Speed: 5136.03 samples/sec#011loss=6.307922\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] processed a total of 679 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 295.57108879089355, \"sum\": 295.57108879089355, \"min\": 295.57108879089355}}, \"EndTime\": 1614020049.44357, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020049.14755}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2296.40115726 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] #quality_metric: host=algo-1, epoch=23, train loss <loss>=6.33715256778\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] Epoch[24] Batch[0] avg_epoch_loss=6.721425\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=6.72142505646\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] Epoch[24] Batch[5] avg_epoch_loss=6.463372\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=6.46337199211\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] Epoch[24] Batch [5]#011Speed: 5335.20 samples/sec#011loss=6.463372\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] Epoch[24] Batch[10] avg_epoch_loss=6.638594\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=6.84885959625\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] Epoch[24] Batch [10]#011Speed: 5171.63 samples/sec#011loss=6.848860\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 290.94696044921875, \"sum\": 290.94696044921875, \"min\": 290.94696044921875}}, \"EndTime\": 1614020049.735071, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020049.443638}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2274.53851749 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] #quality_metric: host=algo-1, epoch=24, train loss <loss>=6.63859363036\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] Epoch[25] Batch[0] avg_epoch_loss=6.349058\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=6.34905767441\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] Epoch[25] Batch[5] avg_epoch_loss=6.499065\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=6.49906476339\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:09 INFO 140707827689280] Epoch[25] Batch [5]#011Speed: 5330.78 samples/sec#011loss=6.499065\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] processed a total of 598 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 280.2140712738037, \"sum\": 280.2140712738037, \"min\": 280.2140712738037}}, \"EndTime\": 1614020050.015868, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020049.735134}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2133.19152164 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] #quality_metric: host=algo-1, epoch=25, train loss <loss>=6.50368275642\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] Epoch[26] Batch[0] avg_epoch_loss=6.473732\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=6.47373199463\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] Epoch[26] Batch[5] avg_epoch_loss=6.463427\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=6.46342658997\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] Epoch[26] Batch [5]#011Speed: 4374.04 samples/sec#011loss=6.463427\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] Epoch[26] Batch[10] avg_epoch_loss=6.563402\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=6.68337287903\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] Epoch[26] Batch [10]#011Speed: 4655.29 samples/sec#011loss=6.683373\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 315.5679702758789, \"sum\": 315.5679702758789, \"min\": 315.5679702758789}}, \"EndTime\": 1614020050.332015, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020050.015946}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2138.19424252 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] #quality_metric: host=algo-1, epoch=26, train loss <loss>=6.5634021759\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] Epoch[27] Batch[0] avg_epoch_loss=6.541888\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=6.541888237\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] Epoch[27] Batch[5] avg_epoch_loss=6.431290\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=6.43129007022\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] Epoch[27] Batch [5]#011Speed: 5268.52 samples/sec#011loss=6.431290\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] Epoch[27] Batch[10] avg_epoch_loss=6.059658\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=5.61369900703\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] Epoch[27] Batch [10]#011Speed: 4368.17 samples/sec#011loss=5.613699\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 303.01904678344727, \"sum\": 303.01904678344727, \"min\": 303.01904678344727}}, \"EndTime\": 1614020050.635596, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020050.332094}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2134.34972409 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] #quality_metric: host=algo-1, epoch=27, train loss <loss>=6.05965776877\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] Saved checkpoint to \"/opt/ml/model/state_18faaf82-a54b-4f7a-a26a-378de4deb513-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 7.220983505249023, \"sum\": 7.220983505249023, \"min\": 7.220983505249023}}, \"EndTime\": 1614020050.643404, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020050.635671}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] Epoch[28] Batch[0] avg_epoch_loss=6.170867\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=6.17086696625\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] Epoch[28] Batch[5] avg_epoch_loss=6.450559\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=6.45055850347\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] Epoch[28] Batch [5]#011Speed: 4398.32 samples/sec#011loss=6.450559\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 299.37291145324707, \"sum\": 299.37291145324707, \"min\": 299.37291145324707}}, \"EndTime\": 1614020050.942899, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020050.643462}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2126.91376745 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] #quality_metric: host=algo-1, epoch=28, train loss <loss>=6.4507147789\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:10 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] Epoch[29] Batch[0] avg_epoch_loss=6.339468\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=6.33946800232\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] Epoch[29] Batch[5] avg_epoch_loss=6.508405\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=6.50840481122\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] Epoch[29] Batch [5]#011Speed: 4887.13 samples/sec#011loss=6.508405\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] Epoch[29] Batch[10] avg_epoch_loss=6.601705\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=6.71366615295\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] Epoch[29] Batch [10]#011Speed: 4939.80 samples/sec#011loss=6.713666\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 320.0380802154541, \"sum\": 320.0380802154541, \"min\": 320.0380802154541}}, \"EndTime\": 1614020051.263496, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020050.942976}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2102.17942613 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] #quality_metric: host=algo-1, epoch=29, train loss <loss>=6.6017054211\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] Epoch[30] Batch[0] avg_epoch_loss=5.978431\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=5.97843122482\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] Epoch[30] Batch[5] avg_epoch_loss=6.479757\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=6.4797569116\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] Epoch[30] Batch [5]#011Speed: 4627.16 samples/sec#011loss=6.479757\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] Epoch[30] Batch[10] avg_epoch_loss=6.195318\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] #quality_metric: host=algo-1, epoch=30, batch=10 train loss <loss>=5.8539917469\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] Epoch[30] Batch [10]#011Speed: 4214.35 samples/sec#011loss=5.853992\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 333.6300849914551, \"sum\": 333.6300849914551, \"min\": 333.6300849914551}}, \"EndTime\": 1614020051.597644, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020051.263566}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1953.59986398 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] #quality_metric: host=algo-1, epoch=30, train loss <loss>=6.19531820037\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] Epoch[31] Batch[0] avg_epoch_loss=6.798455\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=6.79845523834\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] Epoch[31] Batch[5] avg_epoch_loss=6.485101\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=6.48510074615\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] Epoch[31] Batch [5]#011Speed: 5496.96 samples/sec#011loss=6.485101\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 283.60986709594727, \"sum\": 283.60986709594727, \"min\": 283.60986709594727}}, \"EndTime\": 1614020051.881774, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020051.59772}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2252.19765718 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] #quality_metric: host=algo-1, epoch=31, train loss <loss>=6.40802726746\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:11 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] Epoch[32] Batch[0] avg_epoch_loss=6.394259\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=6.39425897598\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] Epoch[32] Batch[5] avg_epoch_loss=6.337483\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=6.33748269081\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] Epoch[32] Batch [5]#011Speed: 4362.78 samples/sec#011loss=6.337483\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] Epoch[32] Batch[10] avg_epoch_loss=6.452775\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=6.59112596512\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] Epoch[32] Batch [10]#011Speed: 5275.29 samples/sec#011loss=6.591126\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] processed a total of 677 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 337.80598640441895, \"sum\": 337.80598640441895, \"min\": 337.80598640441895}}, \"EndTime\": 1614020052.22011, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020051.881851}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2003.50939155 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] #quality_metric: host=algo-1, epoch=32, train loss <loss>=6.45277508822\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] Epoch[33] Batch[0] avg_epoch_loss=6.104002\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=6.10400247574\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] Epoch[33] Batch[5] avg_epoch_loss=6.286122\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=6.28612216314\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] Epoch[33] Batch [5]#011Speed: 4362.53 samples/sec#011loss=6.286122\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 293.20597648620605, \"sum\": 293.20597648620605, \"min\": 293.20597648620605}}, \"EndTime\": 1614020052.513843, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020052.220173}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2178.42002141 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] #quality_metric: host=algo-1, epoch=33, train loss <loss>=6.35400409698\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] Epoch[34] Batch[0] avg_epoch_loss=6.458384\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=6.45838403702\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] Epoch[34] Batch[5] avg_epoch_loss=6.646688\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=6.64668806394\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] Epoch[34] Batch [5]#011Speed: 5326.31 samples/sec#011loss=6.646688\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] Epoch[34] Batch[10] avg_epoch_loss=6.845970\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] #quality_metric: host=algo-1, epoch=34, batch=10 train loss <loss>=7.08510828018\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] Epoch[34] Batch [10]#011Speed: 5471.86 samples/sec#011loss=7.085108\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 297.53708839416504, \"sum\": 297.53708839416504, \"min\": 297.53708839416504}}, \"EndTime\": 1614020052.81191, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020052.513931}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2170.4065819 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] #quality_metric: host=algo-1, epoch=34, train loss <loss>=6.84596998041\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] Epoch[35] Batch[0] avg_epoch_loss=6.504647\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:12 INFO 140707827689280] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=6.50464677811\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] Epoch[35] Batch[5] avg_epoch_loss=6.334711\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=6.33471091588\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] Epoch[35] Batch [5]#011Speed: 4862.49 samples/sec#011loss=6.334711\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] Epoch[35] Batch[10] avg_epoch_loss=6.573684\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] #quality_metric: host=algo-1, epoch=35, batch=10 train loss <loss>=6.86045179367\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] Epoch[35] Batch [10]#011Speed: 5274.42 samples/sec#011loss=6.860452\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 302.0951747894287, \"sum\": 302.0951747894287, \"min\": 302.0951747894287}}, \"EndTime\": 1614020053.114476, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020052.81198}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2177.33621136 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] #quality_metric: host=algo-1, epoch=35, train loss <loss>=6.57368404215\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] Epoch[36] Batch[0] avg_epoch_loss=6.871578\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=6.87157821655\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] Epoch[36] Batch[5] avg_epoch_loss=6.777007\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=6.77700718244\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] Epoch[36] Batch [5]#011Speed: 4541.21 samples/sec#011loss=6.777007\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] Epoch[36] Batch[10] avg_epoch_loss=6.897846\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=7.04285202026\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] Epoch[36] Batch [10]#011Speed: 4879.24 samples/sec#011loss=7.042852\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 335.3559970855713, \"sum\": 335.3559970855713, \"min\": 335.3559970855713}}, \"EndTime\": 1614020053.450315, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020053.114551}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1913.75495488 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] #quality_metric: host=algo-1, epoch=36, train loss <loss>=6.89784574509\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] Epoch[37] Batch[0] avg_epoch_loss=6.441980\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=6.4419798851\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] Epoch[37] Batch[5] avg_epoch_loss=6.478071\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=6.47807089488\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] Epoch[37] Batch [5]#011Speed: 4714.95 samples/sec#011loss=6.478071\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] Epoch[37] Batch[10] avg_epoch_loss=6.647798\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=6.85147018433\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] Epoch[37] Batch [10]#011Speed: 4230.67 samples/sec#011loss=6.851470\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 349.4739532470703, \"sum\": 349.4739532470703, \"min\": 349.4739532470703}}, \"EndTime\": 1614020053.800288, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020053.450389}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1862.15059697 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] #quality_metric: host=algo-1, epoch=37, train loss <loss>=6.64779784463\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] Epoch[38] Batch[0] avg_epoch_loss=6.108956\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:13 INFO 140707827689280] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=6.10895633698\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] Epoch[38] Batch[5] avg_epoch_loss=6.247016\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=6.24701587359\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] Epoch[38] Batch [5]#011Speed: 3645.31 samples/sec#011loss=6.247016\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 328.99999618530273, \"sum\": 328.99999618530273, \"min\": 328.99999618530273}}, \"EndTime\": 1614020054.12984, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020053.800371}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1926.39696319 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] #quality_metric: host=algo-1, epoch=38, train loss <loss>=6.33846125603\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] Epoch[39] Batch[0] avg_epoch_loss=6.276767\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=6.27676725388\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] Epoch[39] Batch[5] avg_epoch_loss=6.367019\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=6.3670194149\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] Epoch[39] Batch [5]#011Speed: 4423.12 samples/sec#011loss=6.367019\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 307.3430061340332, \"sum\": 307.3430061340332, \"min\": 307.3430061340332}}, \"EndTime\": 1614020054.437723, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020054.129916}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2058.79115904 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] #quality_metric: host=algo-1, epoch=39, train loss <loss>=6.46202635765\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] Epoch[40] Batch[0] avg_epoch_loss=6.644360\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=6.64436006546\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] Epoch[40] Batch[5] avg_epoch_loss=6.697550\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=6.69754958153\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] Epoch[40] Batch [5]#011Speed: 5322.34 samples/sec#011loss=6.697550\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] Epoch[40] Batch[10] avg_epoch_loss=6.320125\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] #quality_metric: host=algo-1, epoch=40, batch=10 train loss <loss>=5.86721458435\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] Epoch[40] Batch [10]#011Speed: 5173.14 samples/sec#011loss=5.867215\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 301.61404609680176, \"sum\": 301.61404609680176, \"min\": 301.61404609680176}}, \"EndTime\": 1614020054.739898, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020054.437806}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2137.65982514 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] #quality_metric: host=algo-1, epoch=40, train loss <loss>=6.32012458281\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] Epoch[41] Batch[0] avg_epoch_loss=6.478294\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=6.47829389572\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] Epoch[41] Batch[5] avg_epoch_loss=6.305764\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=6.30576356252\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:14 INFO 140707827689280] Epoch[41] Batch [5]#011Speed: 4415.38 samples/sec#011loss=6.305764\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] Epoch[41] Batch[10] avg_epoch_loss=6.328649\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] #quality_metric: host=algo-1, epoch=41, batch=10 train loss <loss>=6.35611228943\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] Epoch[41] Batch [10]#011Speed: 4591.43 samples/sec#011loss=6.356112\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 308.1250190734863, \"sum\": 308.1250190734863, \"min\": 308.1250190734863}}, \"EndTime\": 1614020055.048552, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020054.739976}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2089.33645416 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] #quality_metric: host=algo-1, epoch=41, train loss <loss>=6.32864934748\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] Epoch[42] Batch[0] avg_epoch_loss=6.153475\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=6.15347480774\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] Epoch[42] Batch[5] avg_epoch_loss=6.536354\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=6.53635446231\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] Epoch[42] Batch [5]#011Speed: 5033.42 samples/sec#011loss=6.536354\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] Epoch[42] Batch[10] avg_epoch_loss=6.371590\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] #quality_metric: host=algo-1, epoch=42, batch=10 train loss <loss>=6.17387294769\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] Epoch[42] Batch [10]#011Speed: 4580.14 samples/sec#011loss=6.173873\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 335.71410179138184, \"sum\": 335.71410179138184, \"min\": 335.71410179138184}}, \"EndTime\": 1614020055.384766, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020055.048626}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1917.66564245 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] #quality_metric: host=algo-1, epoch=42, train loss <loss>=6.37159013748\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] Epoch[43] Batch[0] avg_epoch_loss=6.079700\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=6.0796995163\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] Epoch[43] Batch[5] avg_epoch_loss=6.344125\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=6.34412479401\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] Epoch[43] Batch [5]#011Speed: 4378.10 samples/sec#011loss=6.344125\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 304.86583709716797, \"sum\": 304.86583709716797, \"min\": 304.86583709716797}}, \"EndTime\": 1614020055.690152, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020055.384841}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2042.69755225 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] #quality_metric: host=algo-1, epoch=43, train loss <loss>=6.40036168098\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] Epoch[44] Batch[0] avg_epoch_loss=6.441219\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=6.44121932983\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] Epoch[44] Batch[5] avg_epoch_loss=6.397105\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=6.39710505803\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:15 INFO 140707827689280] Epoch[44] Batch [5]#011Speed: 4639.57 samples/sec#011loss=6.397105\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 324.0659236907959, \"sum\": 324.0659236907959, \"min\": 324.0659236907959}}, \"EndTime\": 1614020056.014738, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020055.690228}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1875.50191401 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] #quality_metric: host=algo-1, epoch=44, train loss <loss>=6.15128736496\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] Epoch[45] Batch[0] avg_epoch_loss=5.852003\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=5.8520026207\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] Epoch[45] Batch[5] avg_epoch_loss=6.229095\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=6.22909498215\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] Epoch[45] Batch [5]#011Speed: 4391.14 samples/sec#011loss=6.229095\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] Epoch[45] Batch[10] avg_epoch_loss=6.406953\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] #quality_metric: host=algo-1, epoch=45, batch=10 train loss <loss>=6.6203827858\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] Epoch[45] Batch [10]#011Speed: 5353.33 samples/sec#011loss=6.620383\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 351.8998622894287, \"sum\": 351.8998622894287, \"min\": 351.8998622894287}}, \"EndTime\": 1614020056.367165, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020056.014816}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1880.65507824 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] #quality_metric: host=algo-1, epoch=45, train loss <loss>=6.40695307472\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] Epoch[46] Batch[0] avg_epoch_loss=6.217442\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=6.21744203568\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] Epoch[46] Batch[5] avg_epoch_loss=6.109358\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=6.10935759544\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] Epoch[46] Batch [5]#011Speed: 4918.69 samples/sec#011loss=6.109358\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 290.0388240814209, \"sum\": 290.0388240814209, \"min\": 290.0388240814209}}, \"EndTime\": 1614020056.657763, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020056.367236}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2174.72881604 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] #quality_metric: host=algo-1, epoch=46, train loss <loss>=6.22721219063\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] Epoch[47] Batch[0] avg_epoch_loss=6.430549\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=6.43054866791\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] Epoch[47] Batch[5] avg_epoch_loss=6.263418\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=6.26341811816\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] Epoch[47] Batch [5]#011Speed: 4754.69 samples/sec#011loss=6.263418\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 291.60499572753906, \"sum\": 291.60499572753906, \"min\": 291.60499572753906}}, \"EndTime\": 1614020056.949871, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020056.657829}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2186.99892038 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] #quality_metric: host=algo-1, epoch=47, train loss <loss>=6.30374894142\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:16 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] Epoch[48] Batch[0] avg_epoch_loss=6.527660\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=6.52766036987\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] Epoch[48] Batch[5] avg_epoch_loss=6.495530\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=6.49553004901\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] Epoch[48] Batch [5]#011Speed: 5223.72 samples/sec#011loss=6.495530\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 296.6158390045166, \"sum\": 296.6158390045166, \"min\": 296.6158390045166}}, \"EndTime\": 1614020057.247007, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020056.949956}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2065.83090308 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] #quality_metric: host=algo-1, epoch=48, train loss <loss>=6.54199461937\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] Epoch[49] Batch[0] avg_epoch_loss=5.934072\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=5.93407201767\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] Epoch[49] Batch[5] avg_epoch_loss=6.251813\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=6.25181309382\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] Epoch[49] Batch [5]#011Speed: 4452.48 samples/sec#011loss=6.251813\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] Epoch[49] Batch[10] avg_epoch_loss=6.068413\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] #quality_metric: host=algo-1, epoch=49, batch=10 train loss <loss>=5.84833307266\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] Epoch[49] Batch [10]#011Speed: 5279.59 samples/sec#011loss=5.848333\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] processed a total of 679 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 306.81300163269043, \"sum\": 306.81300163269043, \"min\": 306.81300163269043}}, \"EndTime\": 1614020057.554444, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020057.247092}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2212.23205063 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] #quality_metric: host=algo-1, epoch=49, train loss <loss>=6.0684130842\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] Epoch[50] Batch[0] avg_epoch_loss=6.423767\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=6.42376708984\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] Epoch[50] Batch[5] avg_epoch_loss=6.288660\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=6.28866020838\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] Epoch[50] Batch [5]#011Speed: 5284.81 samples/sec#011loss=6.288660\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 294.82197761535645, \"sum\": 294.82197761535645, \"min\": 294.82197761535645}}, \"EndTime\": 1614020057.849778, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020057.554519}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2153.00293035 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] #quality_metric: host=algo-1, epoch=50, train loss <loss>=6.3115003109\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:17 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] Epoch[51] Batch[0] avg_epoch_loss=6.342576\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=6.34257555008\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] Epoch[51] Batch[5] avg_epoch_loss=6.089700\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=6.08969958623\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] Epoch[51] Batch [5]#011Speed: 4824.57 samples/sec#011loss=6.089700\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] Epoch[51] Batch[10] avg_epoch_loss=6.432695\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=6.84428853989\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] Epoch[51] Batch [10]#011Speed: 4278.29 samples/sec#011loss=6.844289\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 313.3668899536133, \"sum\": 313.3668899536133, \"min\": 313.3668899536133}}, \"EndTime\": 1614020058.163731, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020057.849848}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2073.52498036 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] #quality_metric: host=algo-1, epoch=51, train loss <loss>=6.43269456517\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] Epoch[52] Batch[0] avg_epoch_loss=6.447702\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=6.447701931\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] Epoch[52] Batch[5] avg_epoch_loss=6.534427\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=6.53442676862\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] Epoch[52] Batch [5]#011Speed: 4990.03 samples/sec#011loss=6.534427\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] Epoch[52] Batch[10] avg_epoch_loss=6.719362\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] #quality_metric: host=algo-1, epoch=52, batch=10 train loss <loss>=6.94128437042\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] Epoch[52] Batch [10]#011Speed: 4408.14 samples/sec#011loss=6.941284\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 310.0440502166748, \"sum\": 310.0440502166748, \"min\": 310.0440502166748}}, \"EndTime\": 1614020058.474319, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020058.163801}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2134.53374774 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] #quality_metric: host=algo-1, epoch=52, train loss <loss>=6.71936204217\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] Epoch[53] Batch[0] avg_epoch_loss=6.889134\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=6.88913440704\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] Epoch[53] Batch[5] avg_epoch_loss=6.519682\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=6.51968153318\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] Epoch[53] Batch [5]#011Speed: 4968.95 samples/sec#011loss=6.519682\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 277.0271301269531, \"sum\": 277.0271301269531, \"min\": 277.0271301269531}}, \"EndTime\": 1614020058.751879, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020058.474379}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2269.54544524 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] #quality_metric: host=algo-1, epoch=53, train loss <loss>=6.35681300163\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] Epoch[54] Batch[0] avg_epoch_loss=6.587355\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:18 INFO 140707827689280] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=6.58735466003\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] Epoch[54] Batch[5] avg_epoch_loss=6.434339\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=6.4343392849\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] Epoch[54] Batch [5]#011Speed: 5351.78 samples/sec#011loss=6.434339\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] Epoch[54] Batch[10] avg_epoch_loss=6.329521\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] #quality_metric: host=algo-1, epoch=54, batch=10 train loss <loss>=6.2037399292\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] Epoch[54] Batch [10]#011Speed: 4766.95 samples/sec#011loss=6.203740\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] processed a total of 705 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 341.22514724731445, \"sum\": 341.22514724731445, \"min\": 341.22514724731445}}, \"EndTime\": 1614020059.093649, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020058.751954}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2065.3341361 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] #quality_metric: host=algo-1, epoch=54, train loss <loss>=6.19602251053\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] Epoch[55] Batch[0] avg_epoch_loss=6.178566\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=6.17856550217\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] Epoch[55] Batch[5] avg_epoch_loss=6.380952\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=6.38095235825\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] Epoch[55] Batch [5]#011Speed: 4624.00 samples/sec#011loss=6.380952\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] Epoch[55] Batch[10] avg_epoch_loss=6.020219\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=5.58733859062\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] Epoch[55] Batch [10]#011Speed: 5116.16 samples/sec#011loss=5.587339\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 330.1680088043213, \"sum\": 330.1680088043213, \"min\": 330.1680088043213}}, \"EndTime\": 1614020059.424417, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020059.093725}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1980.10336681 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] #quality_metric: host=algo-1, epoch=55, train loss <loss>=6.02021882751\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] Saved checkpoint to \"/opt/ml/model/state_d80560b9-2506-4d4b-b355-9791b8557990-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 8.780956268310547, \"sum\": 8.780956268310547, \"min\": 8.780956268310547}}, \"EndTime\": 1614020059.433777, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020059.424497}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] Epoch[56] Batch[0] avg_epoch_loss=6.107656\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=6.10765647888\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] Epoch[56] Batch[5] avg_epoch_loss=6.160377\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=6.16037742297\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] Epoch[56] Batch [5]#011Speed: 4969.02 samples/sec#011loss=6.160377\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] Epoch[56] Batch[10] avg_epoch_loss=6.058217\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] #quality_metric: host=algo-1, epoch=56, batch=10 train loss <loss>=5.93562383652\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] Epoch[56] Batch [10]#011Speed: 5209.85 samples/sec#011loss=5.935624\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 293.83301734924316, \"sum\": 293.83301734924316, \"min\": 293.83301734924316}}, \"EndTime\": 1614020059.727709, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020059.433822}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2228.33095138 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] #quality_metric: host=algo-1, epoch=56, train loss <loss>=6.05821670185\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] Epoch[57] Batch[0] avg_epoch_loss=6.788212\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=6.78821182251\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] Epoch[57] Batch[5] avg_epoch_loss=6.403042\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=6.40304199855\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:19 INFO 140707827689280] Epoch[57] Batch [5]#011Speed: 4726.59 samples/sec#011loss=6.403042\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] Epoch[57] Batch[10] avg_epoch_loss=6.452898\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] #quality_metric: host=algo-1, epoch=57, batch=10 train loss <loss>=6.51272554398\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] Epoch[57] Batch [10]#011Speed: 5162.96 samples/sec#011loss=6.512726\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] processed a total of 682 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 314.8009777069092, \"sum\": 314.8009777069092, \"min\": 314.8009777069092}}, \"EndTime\": 1614020060.043077, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020059.727784}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2165.70514164 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] #quality_metric: host=algo-1, epoch=57, train loss <loss>=6.45289815556\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] Epoch[58] Batch[0] avg_epoch_loss=6.591250\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=6.59124994278\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] Epoch[58] Batch[5] avg_epoch_loss=6.005949\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=6.00594854355\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] Epoch[58] Batch [5]#011Speed: 5267.57 samples/sec#011loss=6.005949\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] Epoch[58] Batch[10] avg_epoch_loss=6.062308\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=6.12993888855\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] Epoch[58] Batch [10]#011Speed: 5119.59 samples/sec#011loss=6.129939\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 295.5141067504883, \"sum\": 295.5141067504883, \"min\": 295.5141067504883}}, \"EndTime\": 1614020060.339153, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020060.043147}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2175.01622792 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] #quality_metric: host=algo-1, epoch=58, train loss <loss>=6.06230779128\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] Epoch[59] Batch[0] avg_epoch_loss=6.634580\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=6.63457965851\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] Epoch[59] Batch[5] avg_epoch_loss=6.431477\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=6.43147659302\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] Epoch[59] Batch [5]#011Speed: 4907.36 samples/sec#011loss=6.431477\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 285.58802604675293, \"sum\": 285.58802604675293, \"min\": 285.58802604675293}}, \"EndTime\": 1614020060.625331, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020060.33923}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2170.03362946 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] #quality_metric: host=algo-1, epoch=59, train loss <loss>=6.35187287331\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] Epoch[60] Batch[0] avg_epoch_loss=5.582794\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=5.58279418945\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] Epoch[60] Batch[5] avg_epoch_loss=6.165873\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=6.16587297122\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] Epoch[60] Batch [5]#011Speed: 4508.37 samples/sec#011loss=6.165873\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] Epoch[60] Batch[10] avg_epoch_loss=6.005717\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=5.81353082657\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] Epoch[60] Batch [10]#011Speed: 5277.64 samples/sec#011loss=5.813531\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 320.767879486084, \"sum\": 320.767879486084, \"min\": 320.767879486084}}, \"EndTime\": 1614020060.946635, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020060.625407}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2078.67918015 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] #quality_metric: host=algo-1, epoch=60, train loss <loss>=6.00571745092\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:20 INFO 140707827689280] Saved checkpoint to \"/opt/ml/model/state_3d4d93ce-a74b-4e58-8c0c-c6d92c1c79a2-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.613203048706055, \"sum\": 10.613203048706055, \"min\": 10.613203048706055}}, \"EndTime\": 1614020060.957792, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020060.946708}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] Epoch[61] Batch[0] avg_epoch_loss=5.845958\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=5.84595823288\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] Epoch[61] Batch[5] avg_epoch_loss=6.072231\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=6.07223073641\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] Epoch[61] Batch [5]#011Speed: 4336.11 samples/sec#011loss=6.072231\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] Epoch[61] Batch[10] avg_epoch_loss=6.243040\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] #quality_metric: host=algo-1, epoch=61, batch=10 train loss <loss>=6.44801111221\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] Epoch[61] Batch [10]#011Speed: 4418.01 samples/sec#011loss=6.448011\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 340.7869338989258, \"sum\": 340.7869338989258, \"min\": 340.7869338989258}}, \"EndTime\": 1614020061.298692, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020060.957852}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1900.95735922 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] #quality_metric: host=algo-1, epoch=61, train loss <loss>=6.24303999814\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] Epoch[62] Batch[0] avg_epoch_loss=6.612156\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=6.61215639114\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] Epoch[62] Batch[5] avg_epoch_loss=6.237658\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=6.237657547\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] Epoch[62] Batch [5]#011Speed: 4955.63 samples/sec#011loss=6.237658\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] Epoch[62] Batch[10] avg_epoch_loss=6.096262\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] #quality_metric: host=algo-1, epoch=62, batch=10 train loss <loss>=5.92658653259\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] Epoch[62] Batch [10]#011Speed: 5281.23 samples/sec#011loss=5.926587\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 298.53296279907227, \"sum\": 298.53296279907227, \"min\": 298.53296279907227}}, \"EndTime\": 1614020061.597725, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020061.298751}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2233.44220164 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] #quality_metric: host=algo-1, epoch=62, train loss <loss>=6.09626163136\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] Epoch[63] Batch[0] avg_epoch_loss=6.266148\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=6.26614761353\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] Epoch[63] Batch[5] avg_epoch_loss=6.053405\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=6.05340488752\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] Epoch[63] Batch [5]#011Speed: 4816.82 samples/sec#011loss=6.053405\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] processed a total of 603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 305.31787872314453, \"sum\": 305.31787872314453, \"min\": 305.31787872314453}}, \"EndTime\": 1614020061.903545, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020061.597799}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1974.31706443 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] #quality_metric: host=algo-1, epoch=63, train loss <loss>=6.23392629623\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:21 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] Epoch[64] Batch[0] avg_epoch_loss=5.977039\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=5.97703933716\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] Epoch[64] Batch[5] avg_epoch_loss=6.124017\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=6.12401660283\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] Epoch[64] Batch [5]#011Speed: 4177.66 samples/sec#011loss=6.124017\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 318.42589378356934, \"sum\": 318.42589378356934, \"min\": 318.42589378356934}}, \"EndTime\": 1614020062.22254, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020061.903609}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1984.00857432 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] #quality_metric: host=algo-1, epoch=64, train loss <loss>=6.09134554863\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] Epoch[65] Batch[0] avg_epoch_loss=6.306595\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=6.30659484863\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] Epoch[65] Batch[5] avg_epoch_loss=6.442894\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=6.44289398193\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] Epoch[65] Batch [5]#011Speed: 4696.08 samples/sec#011loss=6.442894\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] Epoch[65] Batch[10] avg_epoch_loss=6.226640\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=5.96713600159\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] Epoch[65] Batch [10]#011Speed: 5161.70 samples/sec#011loss=5.967136\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] processed a total of 680 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 327.4078369140625, \"sum\": 327.4078369140625, \"min\": 327.4078369140625}}, \"EndTime\": 1614020062.550511, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020062.222623}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2076.24603442 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] #quality_metric: host=algo-1, epoch=65, train loss <loss>=6.2266403545\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] Epoch[66] Batch[0] avg_epoch_loss=5.716024\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=5.7160243988\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] Epoch[66] Batch[5] avg_epoch_loss=6.044304\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=6.04430365562\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] Epoch[66] Batch [5]#011Speed: 5398.57 samples/sec#011loss=6.044304\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 271.46100997924805, \"sum\": 271.46100997924805, \"min\": 271.46100997924805}}, \"EndTime\": 1614020062.82248, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020062.550578}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2297.64953819 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] #quality_metric: host=algo-1, epoch=66, train loss <loss>=6.17081823349\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] Epoch[67] Batch[0] avg_epoch_loss=6.178199\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:22 INFO 140707827689280] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=6.17819929123\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] Epoch[67] Batch[5] avg_epoch_loss=6.081112\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=6.08111182849\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] Epoch[67] Batch [5]#011Speed: 4566.86 samples/sec#011loss=6.081112\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] Epoch[67] Batch[10] avg_epoch_loss=6.270847\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] #quality_metric: host=algo-1, epoch=67, batch=10 train loss <loss>=6.498528862\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] Epoch[67] Batch [10]#011Speed: 5052.03 samples/sec#011loss=6.498529\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 299.8180389404297, \"sum\": 299.8180389404297, \"min\": 299.8180389404297}}, \"EndTime\": 1614020063.122861, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020062.822561}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2243.87223736 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] #quality_metric: host=algo-1, epoch=67, train loss <loss>=6.27084684372\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] Epoch[68] Batch[0] avg_epoch_loss=5.838400\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=5.83840036392\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] Epoch[68] Batch[5] avg_epoch_loss=6.162188\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=6.16218765577\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] Epoch[68] Batch [5]#011Speed: 5122.36 samples/sec#011loss=6.162188\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] Epoch[68] Batch[10] avg_epoch_loss=6.395887\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=6.67632722855\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] Epoch[68] Batch [10]#011Speed: 5226.87 samples/sec#011loss=6.676327\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 301.5730381011963, \"sum\": 301.5730381011963, \"min\": 301.5730381011963}}, \"EndTime\": 1614020063.424967, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020063.122935}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2154.56451489 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] #quality_metric: host=algo-1, epoch=68, train loss <loss>=6.39588746158\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] Epoch[69] Batch[0] avg_epoch_loss=6.157568\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=6.15756797791\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] Epoch[69] Batch[5] avg_epoch_loss=6.272915\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=6.27291488647\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] Epoch[69] Batch [5]#011Speed: 4258.72 samples/sec#011loss=6.272915\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] processed a total of 612 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 281.278133392334, \"sum\": 281.278133392334, \"min\": 281.278133392334}}, \"EndTime\": 1614020063.706781, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020063.425048}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2174.84772421 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] #quality_metric: host=algo-1, epoch=69, train loss <loss>=6.41395578384\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] Epoch[70] Batch[0] avg_epoch_loss=6.023664\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=6.02366399765\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] Epoch[70] Batch[5] avg_epoch_loss=6.368773\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=6.36877290408\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:23 INFO 140707827689280] Epoch[70] Batch [5]#011Speed: 4485.32 samples/sec#011loss=6.368773\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 320.1761245727539, \"sum\": 320.1761245727539, \"min\": 320.1761245727539}}, \"EndTime\": 1614020064.027495, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020063.706866}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1995.06047798 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] #quality_metric: host=algo-1, epoch=70, train loss <loss>=6.35963430405\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] Epoch[71] Batch[0] avg_epoch_loss=6.350320\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=6.35031986237\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] Epoch[71] Batch[5] avg_epoch_loss=6.108597\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=6.10859704018\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] Epoch[71] Batch [5]#011Speed: 3895.51 samples/sec#011loss=6.108597\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] processed a total of 609 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 297.35422134399414, \"sum\": 297.35422134399414, \"min\": 297.35422134399414}}, \"EndTime\": 1614020064.325424, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020064.027575}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2047.27939978 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] #quality_metric: host=algo-1, epoch=71, train loss <loss>=6.20445399284\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] Epoch[72] Batch[0] avg_epoch_loss=6.213268\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=6.21326780319\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] Epoch[72] Batch[5] avg_epoch_loss=6.249129\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=6.24912850062\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] Epoch[72] Batch [5]#011Speed: 5330.65 samples/sec#011loss=6.249129\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] Epoch[72] Batch[10] avg_epoch_loss=6.226335\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] #quality_metric: host=algo-1, epoch=72, batch=10 train loss <loss>=6.19898204803\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] Epoch[72] Batch [10]#011Speed: 5158.87 samples/sec#011loss=6.198982\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] processed a total of 694 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 314.18299674987793, \"sum\": 314.18299674987793, \"min\": 314.18299674987793}}, \"EndTime\": 1614020064.640143, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020064.3255}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2208.11620263 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] #quality_metric: host=algo-1, epoch=72, train loss <loss>=6.22633465854\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] Epoch[73] Batch[0] avg_epoch_loss=6.808400\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=6.80840015411\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] Epoch[73] Batch[5] avg_epoch_loss=6.278097\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=6.2780965964\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] Epoch[73] Batch [5]#011Speed: 5323.12 samples/sec#011loss=6.278097\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 271.65889739990234, \"sum\": 271.65889739990234, \"min\": 271.65889739990234}}, \"EndTime\": 1614020064.912332, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020064.640218}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2266.65432374 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] #quality_metric: host=algo-1, epoch=73, train loss <loss>=6.12132620811\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:24 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] Epoch[74] Batch[0] avg_epoch_loss=6.160058\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=6.16005802155\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] Epoch[74] Batch[5] avg_epoch_loss=6.192396\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=6.19239600499\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] Epoch[74] Batch [5]#011Speed: 5307.75 samples/sec#011loss=6.192396\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] Epoch[74] Batch[10] avg_epoch_loss=6.038022\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] #quality_metric: host=algo-1, epoch=74, batch=10 train loss <loss>=5.85277423859\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] Epoch[74] Batch [10]#011Speed: 4223.87 samples/sec#011loss=5.852774\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 305.448055267334, \"sum\": 305.448055267334, \"min\": 305.448055267334}}, \"EndTime\": 1614020065.218383, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020064.912407}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2182.49848888 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] #quality_metric: host=algo-1, epoch=74, train loss <loss>=6.03802247481\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] Epoch[75] Batch[0] avg_epoch_loss=6.687899\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=6.68789863586\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] Epoch[75] Batch[5] avg_epoch_loss=6.444905\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=6.44490512212\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] Epoch[75] Batch [5]#011Speed: 4716.43 samples/sec#011loss=6.444905\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] Epoch[75] Batch[10] avg_epoch_loss=6.575684\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] #quality_metric: host=algo-1, epoch=75, batch=10 train loss <loss>=6.73261795044\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] Epoch[75] Batch [10]#011Speed: 4409.11 samples/sec#011loss=6.732618\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 319.0901279449463, \"sum\": 319.0901279449463, \"min\": 319.0901279449463}}, \"EndTime\": 1614020065.538038, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020065.218514}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2092.60184404 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] #quality_metric: host=algo-1, epoch=75, train loss <loss>=6.57568368045\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] Epoch[76] Batch[0] avg_epoch_loss=6.069207\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=6.06920671463\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] Epoch[76] Batch[5] avg_epoch_loss=6.103916\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=6.10391640663\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] Epoch[76] Batch [5]#011Speed: 5336.63 samples/sec#011loss=6.103916\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 292.25802421569824, \"sum\": 292.25802421569824, \"min\": 292.25802421569824}}, \"EndTime\": 1614020065.830797, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020065.538112}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2182.18006476 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] #quality_metric: host=algo-1, epoch=76, train loss <loss>=6.16521091461\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:25 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] Epoch[77] Batch[0] avg_epoch_loss=6.384731\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=6.38473129272\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] Epoch[77] Batch[5] avg_epoch_loss=6.218577\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=6.21857651075\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] Epoch[77] Batch [5]#011Speed: 5551.30 samples/sec#011loss=6.218577\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 281.59499168395996, \"sum\": 281.59499168395996, \"min\": 281.59499168395996}}, \"EndTime\": 1614020066.113011, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020065.830877}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2239.81129636 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] #quality_metric: host=algo-1, epoch=77, train loss <loss>=6.16843233109\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] Epoch[78] Batch[0] avg_epoch_loss=6.419582\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=6.41958236694\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] Epoch[78] Batch[5] avg_epoch_loss=6.329189\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=6.32918938001\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] Epoch[78] Batch [5]#011Speed: 4776.33 samples/sec#011loss=6.329189\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] Epoch[78] Batch[10] avg_epoch_loss=6.431757\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] #quality_metric: host=algo-1, epoch=78, batch=10 train loss <loss>=6.55483732224\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] Epoch[78] Batch [10]#011Speed: 4622.35 samples/sec#011loss=6.554837\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 324.6910572052002, \"sum\": 324.6910572052002, \"min\": 324.6910572052002}}, \"EndTime\": 1614020066.438229, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020066.113098}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2044.33488413 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] #quality_metric: host=algo-1, epoch=78, train loss <loss>=6.43175662648\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] Epoch[79] Batch[0] avg_epoch_loss=6.230338\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=6.23033809662\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] Epoch[79] Batch[5] avg_epoch_loss=6.305021\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=6.30502120654\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] Epoch[79] Batch [5]#011Speed: 4428.27 samples/sec#011loss=6.305021\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] Epoch[79] Batch[10] avg_epoch_loss=6.464819\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] #quality_metric: host=algo-1, epoch=79, batch=10 train loss <loss>=6.65657625198\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] Epoch[79] Batch [10]#011Speed: 5002.97 samples/sec#011loss=6.656576\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 317.1088695526123, \"sum\": 317.1088695526123, \"min\": 317.1088695526123}}, \"EndTime\": 1614020066.755842, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020066.438303}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2090.0323348 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] #quality_metric: host=algo-1, epoch=79, train loss <loss>=6.46481895447\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] Epoch[80] Batch[0] avg_epoch_loss=5.976779\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:26 INFO 140707827689280] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=5.97677946091\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] Epoch[80] Batch[5] avg_epoch_loss=6.295464\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=6.29546372096\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] Epoch[80] Batch [5]#011Speed: 4532.13 samples/sec#011loss=6.295464\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] Epoch[80] Batch[10] avg_epoch_loss=6.097739\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] #quality_metric: host=algo-1, epoch=80, batch=10 train loss <loss>=5.86046876907\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] Epoch[80] Batch [10]#011Speed: 4500.31 samples/sec#011loss=5.860469\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 339.9989604949951, \"sum\": 339.9989604949951, \"min\": 339.9989604949951}}, \"EndTime\": 1614020067.096367, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020066.755917}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1984.70452237 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] #quality_metric: host=algo-1, epoch=80, train loss <loss>=6.09773874283\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] Epoch[81] Batch[0] avg_epoch_loss=6.254539\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=6.25453948975\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] Epoch[81] Batch[5] avg_epoch_loss=6.111188\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=6.1111878554\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] Epoch[81] Batch [5]#011Speed: 5412.09 samples/sec#011loss=6.111188\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] Epoch[81] Batch[10] avg_epoch_loss=6.288726\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] #quality_metric: host=algo-1, epoch=81, batch=10 train loss <loss>=6.50177106857\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] Epoch[81] Batch [10]#011Speed: 4864.32 samples/sec#011loss=6.501771\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 298.2940673828125, \"sum\": 298.2940673828125, \"min\": 298.2940673828125}}, \"EndTime\": 1614020067.39518, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020067.096432}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2188.31562017 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] #quality_metric: host=algo-1, epoch=81, train loss <loss>=6.28872567957\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] Epoch[82] Batch[0] avg_epoch_loss=5.651549\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=5.65154886246\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] Epoch[82] Batch[5] avg_epoch_loss=6.230668\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=6.23066759109\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] Epoch[82] Batch [5]#011Speed: 5235.25 samples/sec#011loss=6.230668\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] processed a total of 605 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 281.9080352783203, \"sum\": 281.9080352783203, \"min\": 281.9080352783203}}, \"EndTime\": 1614020067.677606, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020067.395256}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2145.17012634 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] #quality_metric: host=algo-1, epoch=82, train loss <loss>=6.12094650269\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] Epoch[83] Batch[0] avg_epoch_loss=6.505732\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=6.50573205948\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] Epoch[83] Batch[5] avg_epoch_loss=6.325739\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=6.3257393837\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] Epoch[83] Batch [5]#011Speed: 4482.55 samples/sec#011loss=6.325739\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 295.2251434326172, \"sum\": 295.2251434326172, \"min\": 295.2251434326172}}, \"EndTime\": 1614020067.973378, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020067.677692}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2156.77828572 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] #quality_metric: host=algo-1, epoch=83, train loss <loss>=6.28788552284\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:27 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] Epoch[84] Batch[0] avg_epoch_loss=5.855673\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=5.85567331314\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] Epoch[84] Batch[5] avg_epoch_loss=6.113808\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=6.11380823453\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] Epoch[84] Batch [5]#011Speed: 5279.05 samples/sec#011loss=6.113808\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] Epoch[84] Batch[10] avg_epoch_loss=5.980542\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=5.82062234879\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] Epoch[84] Batch [10]#011Speed: 4547.07 samples/sec#011loss=5.820622\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 310.7569217681885, \"sum\": 310.7569217681885, \"min\": 310.7569217681885}}, \"EndTime\": 1614020068.284663, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020067.973454}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2152.03038316 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] #quality_metric: host=algo-1, epoch=84, train loss <loss>=5.98054192283\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] Saved checkpoint to \"/opt/ml/model/state_7d7b7738-83ef-4eaa-92d5-27d1b950347d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.807037353515625, \"sum\": 10.807037353515625, \"min\": 10.807037353515625}}, \"EndTime\": 1614020068.29602, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020068.284737}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] Epoch[85] Batch[0] avg_epoch_loss=6.761728\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=6.76172780991\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] Epoch[85] Batch[5] avg_epoch_loss=6.503081\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=6.50308076541\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] Epoch[85] Batch [5]#011Speed: 5101.07 samples/sec#011loss=6.503081\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] Epoch[85] Batch[10] avg_epoch_loss=6.656778\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] #quality_metric: host=algo-1, epoch=85, batch=10 train loss <loss>=6.84121494293\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] Epoch[85] Batch [10]#011Speed: 5031.76 samples/sec#011loss=6.841215\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 317.4021244049072, \"sum\": 317.4021244049072, \"min\": 317.4021244049072}}, \"EndTime\": 1614020068.613534, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020068.296081}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2025.13985353 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] #quality_metric: host=algo-1, epoch=85, train loss <loss>=6.65677811883\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] Epoch[86] Batch[0] avg_epoch_loss=5.877064\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=5.87706375122\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] Epoch[86] Batch[5] avg_epoch_loss=6.375448\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=6.37544838587\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] Epoch[86] Batch [5]#011Speed: 4372.48 samples/sec#011loss=6.375448\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] Epoch[86] Batch[10] avg_epoch_loss=5.928212\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] #quality_metric: host=algo-1, epoch=86, batch=10 train loss <loss>=5.39152817726\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] Epoch[86] Batch [10]#011Speed: 5192.62 samples/sec#011loss=5.391528\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 311.3529682159424, \"sum\": 311.3529682159424, \"min\": 311.3529682159424}}, \"EndTime\": 1614020068.925384, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020068.613607}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2096.56444825 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] #quality_metric: host=algo-1, epoch=86, train loss <loss>=5.92821192741\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:28 INFO 140707827689280] Saved checkpoint to \"/opt/ml/model/state_283ae9ad-51c5-4be2-9bf5-289801b23fe4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 11.232852935791016, \"sum\": 11.232852935791016, \"min\": 11.232852935791016}}, \"EndTime\": 1614020068.937183, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020068.925459}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] Epoch[87] Batch[0] avg_epoch_loss=5.867886\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=5.8678855896\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] Epoch[87] Batch[5] avg_epoch_loss=6.156774\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=6.15677412351\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] Epoch[87] Batch [5]#011Speed: 4592.28 samples/sec#011loss=6.156774\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] Epoch[87] Batch[10] avg_epoch_loss=5.949185\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=5.70007781982\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] Epoch[87] Batch [10]#011Speed: 4756.66 samples/sec#011loss=5.700078\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 335.5369567871094, \"sum\": 335.5369567871094, \"min\": 335.5369567871094}}, \"EndTime\": 1614020069.272839, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020068.937248}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1993.16056084 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] #quality_metric: host=algo-1, epoch=87, train loss <loss>=5.94918489456\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] Epoch[88] Batch[0] avg_epoch_loss=6.206326\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=6.20632600784\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] Epoch[88] Batch[5] avg_epoch_loss=6.532198\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=6.53219827016\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] Epoch[88] Batch [5]#011Speed: 5634.48 samples/sec#011loss=6.532198\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] processed a total of 607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 345.23797035217285, \"sum\": 345.23797035217285, \"min\": 345.23797035217285}}, \"EndTime\": 1614020069.618578, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020069.272915}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1757.60670695 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] #quality_metric: host=algo-1, epoch=88, train loss <loss>=6.56722106934\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] Epoch[89] Batch[0] avg_epoch_loss=6.254489\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=6.25448894501\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] Epoch[89] Batch[5] avg_epoch_loss=6.223511\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=6.22351050377\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] Epoch[89] Batch [5]#011Speed: 4554.91 samples/sec#011loss=6.223511\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 303.7440776824951, \"sum\": 303.7440776824951, \"min\": 303.7440776824951}}, \"EndTime\": 1614020069.922837, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020069.618661}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2093.02682841 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] #quality_metric: host=algo-1, epoch=89, train loss <loss>=6.21841936111\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:29 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] Epoch[90] Batch[0] avg_epoch_loss=6.050471\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=6.05047082901\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] Epoch[90] Batch[5] avg_epoch_loss=6.189586\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=6.18958608309\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] Epoch[90] Batch [5]#011Speed: 4369.31 samples/sec#011loss=6.189586\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] Epoch[90] Batch[10] avg_epoch_loss=6.359291\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] #quality_metric: host=algo-1, epoch=90, batch=10 train loss <loss>=6.56293621063\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] Epoch[90] Batch [10]#011Speed: 4990.10 samples/sec#011loss=6.562936\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 324.13315773010254, \"sum\": 324.13315773010254, \"min\": 324.13315773010254}}, \"EndTime\": 1614020070.247537, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020069.922923}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2004.65564643 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] #quality_metric: host=algo-1, epoch=90, train loss <loss>=6.35929068652\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] Epoch[91] Batch[0] avg_epoch_loss=6.199314\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=6.19931364059\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] Epoch[91] Batch[5] avg_epoch_loss=6.491569\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=6.4915693601\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] Epoch[91] Batch [5]#011Speed: 5536.42 samples/sec#011loss=6.491569\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 322.1101760864258, \"sum\": 322.1101760864258, \"min\": 322.1101760864258}}, \"EndTime\": 1614020070.570149, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020070.247614}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1927.1771479 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] #quality_metric: host=algo-1, epoch=91, train loss <loss>=6.37404985428\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] Epoch[92] Batch[0] avg_epoch_loss=6.089184\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=6.08918428421\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] Epoch[92] Batch[5] avg_epoch_loss=6.152953\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=6.15295346578\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] Epoch[92] Batch [5]#011Speed: 4187.06 samples/sec#011loss=6.152953\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] Epoch[92] Batch[10] avg_epoch_loss=6.137735\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] #quality_metric: host=algo-1, epoch=92, batch=10 train loss <loss>=6.11947307587\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] Epoch[92] Batch [10]#011Speed: 4163.69 samples/sec#011loss=6.119473\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 343.83416175842285, \"sum\": 343.83416175842285, \"min\": 343.83416175842285}}, \"EndTime\": 1614020070.914525, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020070.570235}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1892.72859003 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] #quality_metric: host=algo-1, epoch=92, train loss <loss>=6.13773510673\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:30 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] Epoch[93] Batch[0] avg_epoch_loss=6.052159\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=6.05215930939\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] Epoch[93] Batch[5] avg_epoch_loss=6.212034\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=6.2120338281\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] Epoch[93] Batch [5]#011Speed: 5275.31 samples/sec#011loss=6.212034\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] Epoch[93] Batch[10] avg_epoch_loss=6.084960\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] #quality_metric: host=algo-1, epoch=93, batch=10 train loss <loss>=5.93247079849\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] Epoch[93] Batch [10]#011Speed: 5167.05 samples/sec#011loss=5.932471\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 294.48699951171875, \"sum\": 294.48699951171875, \"min\": 294.48699951171875}}, \"EndTime\": 1614020071.209565, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020070.914603}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2179.23305046 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] #quality_metric: host=algo-1, epoch=93, train loss <loss>=6.08495972373\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] Epoch[94] Batch[0] avg_epoch_loss=6.406599\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=6.40659856796\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] Epoch[94] Batch[5] avg_epoch_loss=6.109415\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=6.10941489538\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] Epoch[94] Batch [5]#011Speed: 5485.28 samples/sec#011loss=6.109415\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] Epoch[94] Batch[10] avg_epoch_loss=5.725032\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] #quality_metric: host=algo-1, epoch=94, batch=10 train loss <loss>=5.2637732029\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] Epoch[94] Batch [10]#011Speed: 5381.50 samples/sec#011loss=5.263773\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 310.75215339660645, \"sum\": 310.75215339660645, \"min\": 310.75215339660645}}, \"EndTime\": 1614020071.520837, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020071.209641}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2071.65202239 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] #quality_metric: host=algo-1, epoch=94, train loss <loss>=5.72503230788\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] Saved checkpoint to \"/opt/ml/model/state_093e401e-b14d-41c2-810f-13badeadd9e9-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.740041732788086, \"sum\": 10.740041732788086, \"min\": 10.740041732788086}}, \"EndTime\": 1614020071.532116, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020071.520911}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] Epoch[95] Batch[0] avg_epoch_loss=5.980852\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=5.98085212708\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] Epoch[95] Batch[5] avg_epoch_loss=6.156814\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=6.15681378047\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] Epoch[95] Batch [5]#011Speed: 4566.08 samples/sec#011loss=6.156814\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] processed a total of 598 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 290.54999351501465, \"sum\": 290.54999351501465, \"min\": 290.54999351501465}}, \"EndTime\": 1614020071.82278, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020071.532176}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2057.36537479 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] #quality_metric: host=algo-1, epoch=95, train loss <loss>=6.30890789032\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:31 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] Epoch[96] Batch[0] avg_epoch_loss=6.390532\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=6.39053201675\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] Epoch[96] Batch[5] avg_epoch_loss=6.188637\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=6.18863654137\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] Epoch[96] Batch [5]#011Speed: 5157.62 samples/sec#011loss=6.188637\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 294.70205307006836, \"sum\": 294.70205307006836, \"min\": 294.70205307006836}}, \"EndTime\": 1614020072.11801, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020071.822857}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2130.15584777 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] #quality_metric: host=algo-1, epoch=96, train loss <loss>=6.21130189896\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] Epoch[97] Batch[0] avg_epoch_loss=5.565979\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=5.56597900391\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] Epoch[97] Batch[5] avg_epoch_loss=5.942387\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=5.94238734245\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] Epoch[97] Batch [5]#011Speed: 4216.47 samples/sec#011loss=5.942387\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] processed a total of 604 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 324.77498054504395, \"sum\": 324.77498054504395, \"min\": 324.77498054504395}}, \"EndTime\": 1614020072.443331, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020072.118086}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1858.9481124 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] #quality_metric: host=algo-1, epoch=97, train loss <loss>=6.10030150414\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] Epoch[98] Batch[0] avg_epoch_loss=6.269691\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=6.26969146729\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] Epoch[98] Batch[5] avg_epoch_loss=6.076321\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=6.07632104556\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] Epoch[98] Batch [5]#011Speed: 4437.92 samples/sec#011loss=6.076321\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 291.2881374359131, \"sum\": 291.2881374359131, \"min\": 291.2881374359131}}, \"EndTime\": 1614020072.735192, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020072.443411}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2144.78861301 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] #quality_metric: host=algo-1, epoch=98, train loss <loss>=5.97925338745\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] Epoch[99] Batch[0] avg_epoch_loss=6.456399\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:32 INFO 140707827689280] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=6.45639944077\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] Epoch[99] Batch[5] avg_epoch_loss=6.099703\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=6.09970339139\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] Epoch[99] Batch [5]#011Speed: 4434.36 samples/sec#011loss=6.099703\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 346.59504890441895, \"sum\": 346.59504890441895, \"min\": 346.59504890441895}}, \"EndTime\": 1614020073.082348, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020072.735269}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1834.33832951 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] #quality_metric: host=algo-1, epoch=99, train loss <loss>=6.13193149567\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] Epoch[100] Batch[0] avg_epoch_loss=6.069439\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=6.06943893433\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] Epoch[100] Batch[5] avg_epoch_loss=6.032930\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=6.03293037415\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] Epoch[100] Batch [5]#011Speed: 4893.71 samples/sec#011loss=6.032930\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 295.2461242675781, \"sum\": 295.2461242675781, \"min\": 295.2461242675781}}, \"EndTime\": 1614020073.37813, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020073.082435}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2146.51161004 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] #quality_metric: host=algo-1, epoch=100, train loss <loss>=6.03120417595\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] Epoch[101] Batch[0] avg_epoch_loss=6.202487\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=6.20248699188\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] Epoch[101] Batch[5] avg_epoch_loss=6.158147\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=6.15814741453\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] Epoch[101] Batch [5]#011Speed: 5262.20 samples/sec#011loss=6.158147\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] Epoch[101] Batch[10] avg_epoch_loss=6.189767\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] #quality_metric: host=algo-1, epoch=101, batch=10 train loss <loss>=6.22771129608\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] Epoch[101] Batch [10]#011Speed: 5115.49 samples/sec#011loss=6.227711\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 301.13697052001953, \"sum\": 301.13697052001953, \"min\": 301.13697052001953}}, \"EndTime\": 1614020073.679819, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020073.378207}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2151.0442902 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] #quality_metric: host=algo-1, epoch=101, train loss <loss>=6.18976736069\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] Epoch[102] Batch[0] avg_epoch_loss=6.091304\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=6.09130430222\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] Epoch[102] Batch[5] avg_epoch_loss=6.162171\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=6.16217128436\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] Epoch[102] Batch [5]#011Speed: 5124.59 samples/sec#011loss=6.162171\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] processed a total of 566 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 255.08403778076172, \"sum\": 255.08403778076172, \"min\": 255.08403778076172}}, \"EndTime\": 1614020073.935443, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020073.679893}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2217.87741573 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] #quality_metric: host=algo-1, epoch=102, train loss <loss>=6.1572616895\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:33 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] Epoch[103] Batch[0] avg_epoch_loss=5.718746\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=5.71874570847\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] Epoch[103] Batch[5] avg_epoch_loss=5.878650\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=5.87865010897\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] Epoch[103] Batch [5]#011Speed: 5212.32 samples/sec#011loss=5.878650\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 275.8049964904785, \"sum\": 275.8049964904785, \"min\": 275.8049964904785}}, \"EndTime\": 1614020074.211798, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020073.935524}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2304.9748374 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] #quality_metric: host=algo-1, epoch=103, train loss <loss>=5.94362301826\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] Epoch[104] Batch[0] avg_epoch_loss=6.236854\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=6.23685407639\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] Epoch[104] Batch[5] avg_epoch_loss=6.073549\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=6.07354927063\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] Epoch[104] Batch [5]#011Speed: 4174.55 samples/sec#011loss=6.073549\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 395.0932025909424, \"sum\": 395.0932025909424, \"min\": 395.0932025909424}}, \"EndTime\": 1614020074.607447, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020074.21188}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1576.33706527 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] #quality_metric: host=algo-1, epoch=104, train loss <loss>=6.11782178879\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] Epoch[105] Batch[0] avg_epoch_loss=6.342225\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=6.34222459793\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] Epoch[105] Batch[5] avg_epoch_loss=6.417869\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=6.41786932945\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] Epoch[105] Batch [5]#011Speed: 4803.58 samples/sec#011loss=6.417869\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] Epoch[105] Batch[10] avg_epoch_loss=6.280364\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] #quality_metric: host=algo-1, epoch=105, batch=10 train loss <loss>=6.11535816193\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] Epoch[105] Batch [10]#011Speed: 5056.08 samples/sec#011loss=6.115358\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 311.9838237762451, \"sum\": 311.9838237762451, \"min\": 311.9838237762451}}, \"EndTime\": 1614020074.919991, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020074.607536}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2111.53543332 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] #quality_metric: host=algo-1, epoch=105, train loss <loss>=6.2803642533\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:34 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:35 INFO 140707827689280] Epoch[106] Batch[0] avg_epoch_loss=5.893061\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:35 INFO 140707827689280] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=5.89306116104\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:35 INFO 140707827689280] Epoch[106] Batch[5] avg_epoch_loss=6.058831\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:35 INFO 140707827689280] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=6.05883113543\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:35 INFO 140707827689280] Epoch[106] Batch [5]#011Speed: 4589.66 samples/sec#011loss=6.058831\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:35 INFO 140707827689280] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 313.8868808746338, \"sum\": 313.8868808746338, \"min\": 313.8868808746338}}, \"EndTime\": 1614020075.234376, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020074.920067}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:35 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1942.58290726 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:35 INFO 140707827689280] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:35 INFO 140707827689280] #quality_metric: host=algo-1, epoch=106, train loss <loss>=6.16980314255\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:35 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:35 INFO 140707827689280] Epoch[107] Batch[0] avg_epoch_loss=6.311841\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:35 INFO 140707827689280] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=6.31184148788\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:35 INFO 140707827689280] Epoch[107] Batch[5] avg_epoch_loss=6.423310\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:35 INFO 140707827689280] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=6.42330956459\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:35 INFO 140707827689280] Epoch[107] Batch [5]#011Speed: 4114.70 samples/sec#011loss=6.423310\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:35 INFO 140707827689280] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 305.29189109802246, \"sum\": 305.29189109802246, \"min\": 305.29189109802246}}, \"EndTime\": 1614020075.540295, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020075.234467}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:35 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2072.59033117 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:35 INFO 140707827689280] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:35 INFO 140707827689280] #quality_metric: host=algo-1, epoch=107, train loss <loss>=6.26651721001\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:35 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:35 INFO 140707827689280] Epoch[108] Batch[0] avg_epoch_loss=5.968183\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:35 INFO 140707827689280] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=5.96818256378\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:35 INFO 140707827689280] Epoch[108] Batch[5] avg_epoch_loss=6.031000\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:35 INFO 140707827689280] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=6.03099989891\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:35 INFO 140707827689280] Epoch[108] Batch [5]#011Speed: 4756.04 samples/sec#011loss=6.031000\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:35 INFO 140707827689280] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 306.30993843078613, \"sum\": 306.30993843078613, \"min\": 306.30993843078613}}, \"EndTime\": 1614020075.847151, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020075.540378}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:35 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2062.46858836 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:35 INFO 140707827689280] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:35 INFO 140707827689280] #quality_metric: host=algo-1, epoch=108, train loss <loss>=5.98072624207\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:35 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] Epoch[109] Batch[0] avg_epoch_loss=6.244701\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=6.2447013855\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] Epoch[109] Batch[5] avg_epoch_loss=6.220580\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=6.22058025996\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] Epoch[109] Batch [5]#011Speed: 4329.76 samples/sec#011loss=6.220580\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 307.7809810638428, \"sum\": 307.7809810638428, \"min\": 307.7809810638428}}, \"EndTime\": 1614020076.155472, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020075.847235}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2072.14176851 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] #quality_metric: host=algo-1, epoch=109, train loss <loss>=6.08919901848\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] Epoch[110] Batch[0] avg_epoch_loss=6.610213\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=6.61021327972\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] Epoch[110] Batch[5] avg_epoch_loss=6.376198\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=6.37619781494\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] Epoch[110] Batch [5]#011Speed: 4064.94 samples/sec#011loss=6.376198\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 346.04907035827637, \"sum\": 346.04907035827637, \"min\": 346.04907035827637}}, \"EndTime\": 1614020076.502075, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020076.155548}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1825.71925608 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] #quality_metric: host=algo-1, epoch=110, train loss <loss>=6.15999321938\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] Epoch[111] Batch[0] avg_epoch_loss=6.270781\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=6.27078056335\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] Epoch[111] Batch[5] avg_epoch_loss=6.195984\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=6.19598444303\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] Epoch[111] Batch [5]#011Speed: 5060.10 samples/sec#011loss=6.195984\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] Epoch[111] Batch[10] avg_epoch_loss=6.284551\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] #quality_metric: host=algo-1, epoch=111, batch=10 train loss <loss>=6.39083137512\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] Epoch[111] Batch [10]#011Speed: 4416.10 samples/sec#011loss=6.390831\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 309.9391460418701, \"sum\": 309.9391460418701, \"min\": 309.9391460418701}}, \"EndTime\": 1614020076.812557, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020076.502154}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2144.86970658 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] #quality_metric: host=algo-1, epoch=111, train loss <loss>=6.28455123034\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] Epoch[112] Batch[0] avg_epoch_loss=6.283384\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:36 INFO 140707827689280] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=6.28338432312\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] Epoch[112] Batch[5] avg_epoch_loss=6.244082\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=6.24408245087\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] Epoch[112] Batch [5]#011Speed: 4319.77 samples/sec#011loss=6.244082\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] Epoch[112] Batch[10] avg_epoch_loss=5.802388\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] #quality_metric: host=algo-1, epoch=112, batch=10 train loss <loss>=5.27235450745\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] Epoch[112] Batch [10]#011Speed: 5231.50 samples/sec#011loss=5.272355\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 304.86607551574707, \"sum\": 304.86607551574707, \"min\": 304.86607551574707}}, \"EndTime\": 1614020077.118002, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020076.812626}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2111.6416654 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] #quality_metric: host=algo-1, epoch=112, train loss <loss>=5.80238793113\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] Epoch[113] Batch[0] avg_epoch_loss=5.919963\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=5.919962883\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] Epoch[113] Batch[5] avg_epoch_loss=6.136333\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=6.13633275032\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] Epoch[113] Batch [5]#011Speed: 4654.13 samples/sec#011loss=6.136333\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] Epoch[113] Batch[10] avg_epoch_loss=6.369482\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] #quality_metric: host=algo-1, epoch=113, batch=10 train loss <loss>=6.64926176071\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] Epoch[113] Batch [10]#011Speed: 4972.81 samples/sec#011loss=6.649262\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 340.3940200805664, \"sum\": 340.3940200805664, \"min\": 340.3940200805664}}, \"EndTime\": 1614020077.458893, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020077.118076}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1932.43537863 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] #quality_metric: host=algo-1, epoch=113, train loss <loss>=6.3694823005\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] Epoch[114] Batch[0] avg_epoch_loss=5.890595\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=5.89059495926\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] Epoch[114] Batch[5] avg_epoch_loss=6.218909\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=6.21890942256\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] Epoch[114] Batch [5]#011Speed: 5353.51 samples/sec#011loss=6.218909\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 285.5839729309082, \"sum\": 285.5839729309082, \"min\": 285.5839729309082}}, \"EndTime\": 1614020077.745011, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020077.458967}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2236.70450978 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] #quality_metric: host=algo-1, epoch=114, train loss <loss>=6.23571324348\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] Epoch[115] Batch[0] avg_epoch_loss=5.684273\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=5.68427276611\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] Epoch[115] Batch[5] avg_epoch_loss=5.898348\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=5.89834801356\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:37 INFO 140707827689280] Epoch[115] Batch [5]#011Speed: 5519.34 samples/sec#011loss=5.898348\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 280.32612800598145, \"sum\": 280.32612800598145, \"min\": 280.32612800598145}}, \"EndTime\": 1614020078.025935, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020077.745079}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2200.16949876 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] #quality_metric: host=algo-1, epoch=115, train loss <loss>=5.76057815552\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] Epoch[116] Batch[0] avg_epoch_loss=6.387208\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=6.38720798492\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] Epoch[116] Batch[5] avg_epoch_loss=6.099309\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=6.09930896759\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] Epoch[116] Batch [5]#011Speed: 5028.35 samples/sec#011loss=6.099309\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] Epoch[116] Batch[10] avg_epoch_loss=5.971527\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] #quality_metric: host=algo-1, epoch=116, batch=10 train loss <loss>=5.81818904877\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] Epoch[116] Batch [10]#011Speed: 4588.40 samples/sec#011loss=5.818189\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 313.9669895172119, \"sum\": 313.9669895172119, \"min\": 313.9669895172119}}, \"EndTime\": 1614020078.340395, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020078.026007}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2085.49551287 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] #quality_metric: host=algo-1, epoch=116, train loss <loss>=5.97152718631\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] Epoch[117] Batch[0] avg_epoch_loss=6.410622\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=6.4106221199\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] Epoch[117] Batch[5] avg_epoch_loss=6.021322\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=6.02132153511\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] Epoch[117] Batch [5]#011Speed: 4451.56 samples/sec#011loss=6.021322\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 335.3438377380371, \"sum\": 335.3438377380371, \"min\": 335.3438377380371}}, \"EndTime\": 1614020078.676239, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020078.340469}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1886.97757584 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] #quality_metric: host=algo-1, epoch=117, train loss <loss>=6.21620635986\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] Epoch[118] Batch[0] avg_epoch_loss=6.689032\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=6.68903160095\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] Epoch[118] Batch[5] avg_epoch_loss=6.149685\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=6.14968482653\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] Epoch[118] Batch [5]#011Speed: 4445.99 samples/sec#011loss=6.149685\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 322.4470615386963, \"sum\": 322.4470615386963, \"min\": 322.4470615386963}}, \"EndTime\": 1614020078.999231, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020078.676316}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1915.66165669 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] #quality_metric: host=algo-1, epoch=118, train loss <loss>=6.11987276077\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:38 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] Epoch[119] Batch[0] avg_epoch_loss=6.346152\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=6.3461523056\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] Epoch[119] Batch[5] avg_epoch_loss=6.095331\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=6.09533119202\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] Epoch[119] Batch [5]#011Speed: 4349.95 samples/sec#011loss=6.095331\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] Epoch[119] Batch[10] avg_epoch_loss=5.929955\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] #quality_metric: host=algo-1, epoch=119, batch=10 train loss <loss>=5.73150248528\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] Epoch[119] Batch [10]#011Speed: 4844.01 samples/sec#011loss=5.731502\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 315.17601013183594, \"sum\": 315.17601013183594, \"min\": 315.17601013183594}}, \"EndTime\": 1614020079.315033, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020078.999348}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2106.023306 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] #quality_metric: host=algo-1, epoch=119, train loss <loss>=5.92995450713\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] Epoch[120] Batch[0] avg_epoch_loss=5.900447\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=5.90044689178\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] Epoch[120] Batch[5] avg_epoch_loss=5.952566\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=5.95256574949\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] Epoch[120] Batch [5]#011Speed: 4126.06 samples/sec#011loss=5.952566\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] Epoch[120] Batch[10] avg_epoch_loss=5.745670\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] #quality_metric: host=algo-1, epoch=120, batch=10 train loss <loss>=5.49739451408\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] Epoch[120] Batch [10]#011Speed: 4998.20 samples/sec#011loss=5.497395\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 329.9670219421387, \"sum\": 329.9670219421387, \"min\": 329.9670219421387}}, \"EndTime\": 1614020079.645534, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020079.315107}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1960.14767517 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] #quality_metric: host=algo-1, epoch=120, train loss <loss>=5.74566973339\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] Epoch[121] Batch[0] avg_epoch_loss=6.244730\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=6.24472951889\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] Epoch[121] Batch[5] avg_epoch_loss=6.148066\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=6.14806588491\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] Epoch[121] Batch [5]#011Speed: 4556.33 samples/sec#011loss=6.148066\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] Epoch[121] Batch[10] avg_epoch_loss=5.772417\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] #quality_metric: host=algo-1, epoch=121, batch=10 train loss <loss>=5.32163896561\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] Epoch[121] Batch [10]#011Speed: 4541.66 samples/sec#011loss=5.321639\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 325.4220485687256, \"sum\": 325.4220485687256, \"min\": 325.4220485687256}}, \"EndTime\": 1614020079.971462, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020079.64561}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1990.58796233 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] #quality_metric: host=algo-1, epoch=121, train loss <loss>=5.77241728523\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:39 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] Epoch[122] Batch[0] avg_epoch_loss=6.413390\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=6.41339015961\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] Epoch[122] Batch[5] avg_epoch_loss=6.254176\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=6.25417598089\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] Epoch[122] Batch [5]#011Speed: 5346.81 samples/sec#011loss=6.254176\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] Epoch[122] Batch[10] avg_epoch_loss=6.177438\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] #quality_metric: host=algo-1, epoch=122, batch=10 train loss <loss>=6.08535146713\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] Epoch[122] Batch [10]#011Speed: 4242.40 samples/sec#011loss=6.085351\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 305.3591251373291, \"sum\": 305.3591251373291, \"min\": 305.3591251373291}}, \"EndTime\": 1614020080.277355, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020079.971535}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2154.08465382 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] #quality_metric: host=algo-1, epoch=122, train loss <loss>=6.17743756554\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] Epoch[123] Batch[0] avg_epoch_loss=5.450893\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=5.45089292526\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] Epoch[123] Batch[5] avg_epoch_loss=6.023377\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=6.02337670326\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] Epoch[123] Batch [5]#011Speed: 4377.45 samples/sec#011loss=6.023377\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] Epoch[123] Batch[10] avg_epoch_loss=5.628660\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] #quality_metric: host=algo-1, epoch=123, batch=10 train loss <loss>=5.15499944687\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] Epoch[123] Batch [10]#011Speed: 4356.66 samples/sec#011loss=5.154999\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 348.128080368042, \"sum\": 348.128080368042, \"min\": 348.128080368042}}, \"EndTime\": 1614020080.625985, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020080.277428}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1840.70024346 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] #quality_metric: host=algo-1, epoch=123, train loss <loss>=5.62865976854\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] Saved checkpoint to \"/opt/ml/model/state_81dfe1bb-8c23-4617-88d1-e57e16c24aea-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.683774948120117, \"sum\": 10.683774948120117, \"min\": 10.683774948120117}}, \"EndTime\": 1614020080.637229, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020080.62606}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] Epoch[124] Batch[0] avg_epoch_loss=6.352661\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=6.35266065598\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] Epoch[124] Batch[5] avg_epoch_loss=6.015652\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=6.01565178235\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] Epoch[124] Batch [5]#011Speed: 4485.20 samples/sec#011loss=6.015652\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] Epoch[124] Batch[10] avg_epoch_loss=6.286393\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] #quality_metric: host=algo-1, epoch=124, batch=10 train loss <loss>=6.61128225327\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] Epoch[124] Batch [10]#011Speed: 4555.75 samples/sec#011loss=6.611282\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 330.69896697998047, \"sum\": 330.69896697998047, \"min\": 330.69896697998047}}, \"EndTime\": 1614020080.968041, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020080.637289}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1973.91814405 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] #quality_metric: host=algo-1, epoch=124, train loss <loss>=6.2863929055\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:40 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] Epoch[125] Batch[0] avg_epoch_loss=6.633548\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=6.63354825974\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] Epoch[125] Batch[5] avg_epoch_loss=6.169347\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=6.16934672991\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] Epoch[125] Batch [5]#011Speed: 4412.88 samples/sec#011loss=6.169347\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 303.47418785095215, \"sum\": 303.47418785095215, \"min\": 303.47418785095215}}, \"EndTime\": 1614020081.272055, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020080.968122}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2088.50151895 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] #quality_metric: host=algo-1, epoch=125, train loss <loss>=6.0598212719\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] Epoch[126] Batch[0] avg_epoch_loss=6.007981\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=6.00798082352\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] Epoch[126] Batch[5] avg_epoch_loss=6.236928\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=6.23692822456\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] Epoch[126] Batch [5]#011Speed: 5173.38 samples/sec#011loss=6.236928\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] Epoch[126] Batch[10] avg_epoch_loss=6.264811\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] #quality_metric: host=algo-1, epoch=126, batch=10 train loss <loss>=6.29826946259\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] Epoch[126] Batch [10]#011Speed: 4319.18 samples/sec#011loss=6.298269\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 313.42101097106934, \"sum\": 313.42101097106934, \"min\": 313.42101097106934}}, \"EndTime\": 1614020081.586031, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020081.272112}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2152.84367379 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] #quality_metric: host=algo-1, epoch=126, train loss <loss>=6.26481060548\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] Epoch[127] Batch[0] avg_epoch_loss=5.538443\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=5.53844261169\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] Epoch[127] Batch[5] avg_epoch_loss=5.906924\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=5.90692424774\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] Epoch[127] Batch [5]#011Speed: 5313.68 samples/sec#011loss=5.906924\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 275.040864944458, \"sum\": 275.040864944458, \"min\": 275.040864944458}}, \"EndTime\": 1614020081.861666, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020081.586109}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2227.85204774 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] #quality_metric: host=algo-1, epoch=127, train loss <loss>=6.04628772736\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:41 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] Epoch[128] Batch[0] avg_epoch_loss=6.011402\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=6.01140213013\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] Epoch[128] Batch[5] avg_epoch_loss=6.048188\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=6.04818836848\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] Epoch[128] Batch [5]#011Speed: 5290.47 samples/sec#011loss=6.048188\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] Epoch[128] Batch[10] avg_epoch_loss=6.023033\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] #quality_metric: host=algo-1, epoch=128, batch=10 train loss <loss>=5.99284734726\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] Epoch[128] Batch [10]#011Speed: 4673.79 samples/sec#011loss=5.992847\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 300.20785331726074, \"sum\": 300.20785331726074, \"min\": 300.20785331726074}}, \"EndTime\": 1614020082.162439, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020081.861747}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2244.30195528 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] #quality_metric: host=algo-1, epoch=128, train loss <loss>=6.02303335883\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] Epoch[129] Batch[0] avg_epoch_loss=6.443991\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=6.44399118423\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] Epoch[129] Batch[5] avg_epoch_loss=6.322398\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=6.32239794731\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] Epoch[129] Batch [5]#011Speed: 5169.80 samples/sec#011loss=6.322398\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] Epoch[129] Batch[10] avg_epoch_loss=6.367369\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] #quality_metric: host=algo-1, epoch=129, batch=10 train loss <loss>=6.42133483887\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] Epoch[129] Batch [10]#011Speed: 4795.31 samples/sec#011loss=6.421335\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 308.243989944458, \"sum\": 308.243989944458, \"min\": 308.243989944458}}, \"EndTime\": 1614020082.471151, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020082.162514}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2123.95600046 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] #quality_metric: host=algo-1, epoch=129, train loss <loss>=6.36736926165\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] Epoch[130] Batch[0] avg_epoch_loss=6.062847\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=6.06284713745\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] Epoch[130] Batch[5] avg_epoch_loss=6.035003\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=6.03500318527\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] Epoch[130] Batch [5]#011Speed: 5255.28 samples/sec#011loss=6.035003\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 296.8471050262451, \"sum\": 296.8471050262451, \"min\": 296.8471050262451}}, \"EndTime\": 1614020082.769277, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020082.471258}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2091.20503046 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] #quality_metric: host=algo-1, epoch=130, train loss <loss>=6.16492977142\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] Epoch[131] Batch[0] avg_epoch_loss=5.134704\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:42 INFO 140707827689280] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=5.13470411301\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] Epoch[131] Batch[5] avg_epoch_loss=5.926140\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=5.92613959312\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] Epoch[131] Batch [5]#011Speed: 4797.96 samples/sec#011loss=5.926140\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] Epoch[131] Batch[10] avg_epoch_loss=5.922270\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] #quality_metric: host=algo-1, epoch=131, batch=10 train loss <loss>=5.91762704849\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] Epoch[131] Batch [10]#011Speed: 4366.39 samples/sec#011loss=5.917627\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 330.54208755493164, \"sum\": 330.54208755493164, \"min\": 330.54208755493164}}, \"EndTime\": 1614020083.100334, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020082.769352}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1959.78272363 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] #quality_metric: host=algo-1, epoch=131, train loss <loss>=5.92227025466\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] Epoch[132] Batch[0] avg_epoch_loss=6.489739\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=6.48973894119\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] Epoch[132] Batch[5] avg_epoch_loss=6.054868\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=6.05486822128\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] Epoch[132] Batch [5]#011Speed: 4642.12 samples/sec#011loss=6.054868\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] processed a total of 599 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 302.7811050415039, \"sum\": 302.7811050415039, \"min\": 302.7811050415039}}, \"EndTime\": 1614020083.403617, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020083.100406}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1977.60277577 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] #quality_metric: host=algo-1, epoch=132, train loss <loss>=6.19737000465\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] Epoch[133] Batch[0] avg_epoch_loss=6.316989\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=6.31698894501\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] Epoch[133] Batch[5] avg_epoch_loss=6.159595\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=6.15959501266\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] Epoch[133] Batch [5]#011Speed: 4309.00 samples/sec#011loss=6.159595\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 345.67999839782715, \"sum\": 345.67999839782715, \"min\": 345.67999839782715}}, \"EndTime\": 1614020083.749837, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020083.403691}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1830.60139829 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] #quality_metric: host=algo-1, epoch=133, train loss <loss>=6.29904961586\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] Epoch[134] Batch[0] avg_epoch_loss=5.980198\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=5.98019838333\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] Epoch[134] Batch[5] avg_epoch_loss=6.148048\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=6.14804792404\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:43 INFO 140707827689280] Epoch[134] Batch [5]#011Speed: 4893.19 samples/sec#011loss=6.148048\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] Epoch[134] Batch[10] avg_epoch_loss=6.251949\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] #quality_metric: host=algo-1, epoch=134, batch=10 train loss <loss>=6.37663002014\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] Epoch[134] Batch [10]#011Speed: 5099.36 samples/sec#011loss=6.376630\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 307.1298599243164, \"sum\": 307.1298599243164, \"min\": 307.1298599243164}}, \"EndTime\": 1614020084.057532, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020083.749913}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2141.6215676 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] #quality_metric: host=algo-1, epoch=134, train loss <loss>=6.25194887681\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] Epoch[135] Batch[0] avg_epoch_loss=5.844888\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=5.84488773346\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] Epoch[135] Batch[5] avg_epoch_loss=6.066031\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=6.06603097916\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] Epoch[135] Batch [5]#011Speed: 5058.08 samples/sec#011loss=6.066031\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] Epoch[135] Batch[10] avg_epoch_loss=5.822034\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] #quality_metric: host=algo-1, epoch=135, batch=10 train loss <loss>=5.52923870087\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] Epoch[135] Batch [10]#011Speed: 4615.48 samples/sec#011loss=5.529239\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 302.2639751434326, \"sum\": 302.2639751434326, \"min\": 302.2639751434326}}, \"EndTime\": 1614020084.360337, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020084.057602}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2149.69043421 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] #quality_metric: host=algo-1, epoch=135, train loss <loss>=5.82203448902\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] Epoch[136] Batch[0] avg_epoch_loss=6.080378\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] #quality_metric: host=algo-1, epoch=136, batch=0 train loss <loss>=6.08037757874\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] Epoch[136] Batch[5] avg_epoch_loss=6.053332\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] #quality_metric: host=algo-1, epoch=136, batch=5 train loss <loss>=6.05333153407\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] Epoch[136] Batch [5]#011Speed: 4350.66 samples/sec#011loss=6.053332\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 306.34498596191406, \"sum\": 306.34498596191406, \"min\": 306.34498596191406}}, \"EndTime\": 1614020084.667226, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020084.360403}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2081.66836796 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] #quality_metric: host=algo-1, epoch=136, train loss <loss>=6.13817424774\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] Epoch[137] Batch[0] avg_epoch_loss=6.393214\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] #quality_metric: host=algo-1, epoch=137, batch=0 train loss <loss>=6.39321374893\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] Epoch[137] Batch[5] avg_epoch_loss=5.842005\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] #quality_metric: host=algo-1, epoch=137, batch=5 train loss <loss>=5.84200453758\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] Epoch[137] Batch [5]#011Speed: 4677.00 samples/sec#011loss=5.842005\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] processed a total of 594 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 310.15992164611816, \"sum\": 310.15992164611816, \"min\": 310.15992164611816}}, \"EndTime\": 1614020084.977962, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020084.66733}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1914.41849829 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] #quality_metric: host=algo-1, epoch=137, train loss <loss>=6.10017671585\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:44 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] Epoch[138] Batch[0] avg_epoch_loss=6.133175\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] #quality_metric: host=algo-1, epoch=138, batch=0 train loss <loss>=6.13317489624\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] Epoch[138] Batch[5] avg_epoch_loss=5.567365\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] #quality_metric: host=algo-1, epoch=138, batch=5 train loss <loss>=5.56736532847\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] Epoch[138] Batch [5]#011Speed: 4428.46 samples/sec#011loss=5.567365\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 309.1549873352051, \"sum\": 309.1549873352051, \"min\": 309.1549873352051}}, \"EndTime\": 1614020085.287647, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020084.978043}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2030.62009078 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] #quality_metric: host=algo-1, epoch=138, train loss <loss>=5.72754254341\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] Epoch[139] Batch[0] avg_epoch_loss=5.795132\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] #quality_metric: host=algo-1, epoch=139, batch=0 train loss <loss>=5.79513168335\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] Epoch[139] Batch[5] avg_epoch_loss=6.140770\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] #quality_metric: host=algo-1, epoch=139, batch=5 train loss <loss>=6.14077035586\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] Epoch[139] Batch [5]#011Speed: 4911.36 samples/sec#011loss=6.140770\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] Epoch[139] Batch[10] avg_epoch_loss=5.853104\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] #quality_metric: host=algo-1, epoch=139, batch=10 train loss <loss>=5.50790438652\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] Epoch[139] Batch [10]#011Speed: 5127.63 samples/sec#011loss=5.507904\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 336.58313751220703, \"sum\": 336.58313751220703, \"min\": 336.58313751220703}}, \"EndTime\": 1614020085.624767, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020085.287721}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1989.93180149 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] #quality_metric: host=algo-1, epoch=139, train loss <loss>=5.85310400616\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] Epoch[140] Batch[0] avg_epoch_loss=6.527460\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] #quality_metric: host=algo-1, epoch=140, batch=0 train loss <loss>=6.52746009827\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] Epoch[140] Batch[5] avg_epoch_loss=6.160395\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] #quality_metric: host=algo-1, epoch=140, batch=5 train loss <loss>=6.16039522489\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] Epoch[140] Batch [5]#011Speed: 5329.25 samples/sec#011loss=6.160395\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 274.8720645904541, \"sum\": 274.8720645904541, \"min\": 274.8720645904541}}, \"EndTime\": 1614020085.900192, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020085.624843}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2327.4757247 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] #quality_metric: host=algo-1, epoch=140, train loss <loss>=6.10035171509\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:45 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] Epoch[141] Batch[0] avg_epoch_loss=5.749382\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] #quality_metric: host=algo-1, epoch=141, batch=0 train loss <loss>=5.74938154221\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] Epoch[141] Batch[5] avg_epoch_loss=6.078465\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] #quality_metric: host=algo-1, epoch=141, batch=5 train loss <loss>=6.07846530279\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] Epoch[141] Batch [5]#011Speed: 4750.45 samples/sec#011loss=6.078465\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] Epoch[141] Batch[10] avg_epoch_loss=6.072966\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] #quality_metric: host=algo-1, epoch=141, batch=10 train loss <loss>=6.06636791229\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] Epoch[141] Batch [10]#011Speed: 4596.77 samples/sec#011loss=6.066368\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 309.981107711792, \"sum\": 309.981107711792, \"min\": 309.981107711792}}, \"EndTime\": 1614020086.210734, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020085.900258}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2131.6321989 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] #quality_metric: host=algo-1, epoch=141, train loss <loss>=6.07296648892\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] Epoch[142] Batch[0] avg_epoch_loss=5.635201\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] #quality_metric: host=algo-1, epoch=142, batch=0 train loss <loss>=5.63520050049\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] Epoch[142] Batch[5] avg_epoch_loss=6.183088\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] #quality_metric: host=algo-1, epoch=142, batch=5 train loss <loss>=6.18308838209\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] Epoch[142] Batch [5]#011Speed: 4224.97 samples/sec#011loss=6.183088\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] Epoch[142] Batch[10] avg_epoch_loss=6.358060\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] #quality_metric: host=algo-1, epoch=142, batch=10 train loss <loss>=6.56802511215\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] Epoch[142] Batch [10]#011Speed: 4031.10 samples/sec#011loss=6.568025\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 343.43910217285156, \"sum\": 343.43910217285156, \"min\": 343.43910217285156}}, \"EndTime\": 1614020086.554667, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020086.210808}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1883.29340896 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] #quality_metric: host=algo-1, epoch=142, train loss <loss>=6.35805962302\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] Epoch[143] Batch[0] avg_epoch_loss=5.794345\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] #quality_metric: host=algo-1, epoch=143, batch=0 train loss <loss>=5.79434490204\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] Epoch[143] Batch[5] avg_epoch_loss=5.973161\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] #quality_metric: host=algo-1, epoch=143, batch=5 train loss <loss>=5.97316114108\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] Epoch[143] Batch [5]#011Speed: 4955.70 samples/sec#011loss=5.973161\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] processed a total of 600 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 348.7999439239502, \"sum\": 348.7999439239502, \"min\": 348.7999439239502}}, \"EndTime\": 1614020086.904003, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020086.554742}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1719.61603219 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] #quality_metric: host=algo-1, epoch=143, train loss <loss>=6.04534993172\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:46 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] Epoch[144] Batch[0] avg_epoch_loss=5.759854\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] #quality_metric: host=algo-1, epoch=144, batch=0 train loss <loss>=5.75985383987\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] Epoch[144] Batch[5] avg_epoch_loss=5.980262\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] #quality_metric: host=algo-1, epoch=144, batch=5 train loss <loss>=5.98026243846\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] Epoch[144] Batch [5]#011Speed: 4658.69 samples/sec#011loss=5.980262\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 311.86890602111816, \"sum\": 311.86890602111816, \"min\": 311.86890602111816}}, \"EndTime\": 1614020087.216413, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020086.904081}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2006.38395892 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] #quality_metric: host=algo-1, epoch=144, train loss <loss>=6.14571752548\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] Epoch[145] Batch[0] avg_epoch_loss=6.137956\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] #quality_metric: host=algo-1, epoch=145, batch=0 train loss <loss>=6.13795614243\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] Epoch[145] Batch[5] avg_epoch_loss=5.957183\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] #quality_metric: host=algo-1, epoch=145, batch=5 train loss <loss>=5.95718344053\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] Epoch[145] Batch [5]#011Speed: 4356.76 samples/sec#011loss=5.957183\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] processed a total of 601 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 313.8608932495117, \"sum\": 313.8608932495117, \"min\": 313.8608932495117}}, \"EndTime\": 1614020087.530824, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020087.216511}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1914.13548663 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] #quality_metric: host=algo-1, epoch=145, train loss <loss>=6.03851518631\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] Epoch[146] Batch[0] avg_epoch_loss=5.830691\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] #quality_metric: host=algo-1, epoch=146, batch=0 train loss <loss>=5.83069133759\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] Epoch[146] Batch[5] avg_epoch_loss=6.024139\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] #quality_metric: host=algo-1, epoch=146, batch=5 train loss <loss>=6.0241394043\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] Epoch[146] Batch [5]#011Speed: 5522.39 samples/sec#011loss=6.024139\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] Epoch[146] Batch[10] avg_epoch_loss=5.667549\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] #quality_metric: host=algo-1, epoch=146, batch=10 train loss <loss>=5.23963947296\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] Epoch[146] Batch [10]#011Speed: 4522.91 samples/sec#011loss=5.239639\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 360.24999618530273, \"sum\": 360.24999618530273, \"min\": 360.24999618530273}}, \"EndTime\": 1614020087.891654, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020087.530905}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1864.68884477 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] #quality_metric: host=algo-1, epoch=146, train loss <loss>=5.66754852642\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:47 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] Epoch[147] Batch[0] avg_epoch_loss=6.190938\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] #quality_metric: host=algo-1, epoch=147, batch=0 train loss <loss>=6.19093847275\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] Epoch[147] Batch[5] avg_epoch_loss=6.164735\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] #quality_metric: host=algo-1, epoch=147, batch=5 train loss <loss>=6.16473507881\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] Epoch[147] Batch [5]#011Speed: 5346.06 samples/sec#011loss=6.164735\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 322.7519989013672, \"sum\": 322.7519989013672, \"min\": 322.7519989013672}}, \"EndTime\": 1614020088.214913, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020087.891729}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1954.32953559 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] #quality_metric: host=algo-1, epoch=147, train loss <loss>=6.14627847672\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] Epoch[148] Batch[0] avg_epoch_loss=5.982225\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] #quality_metric: host=algo-1, epoch=148, batch=0 train loss <loss>=5.98222494125\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] Epoch[148] Batch[5] avg_epoch_loss=5.921848\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] #quality_metric: host=algo-1, epoch=148, batch=5 train loss <loss>=5.92184821765\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] Epoch[148] Batch [5]#011Speed: 5541.90 samples/sec#011loss=5.921848\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 326.71499252319336, \"sum\": 326.71499252319336, \"min\": 326.71499252319336}}, \"EndTime\": 1614020088.542182, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020088.214998}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1912.29154159 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] #quality_metric: host=algo-1, epoch=148, train loss <loss>=5.87623081207\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] Epoch[149] Batch[0] avg_epoch_loss=6.450641\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] #quality_metric: host=algo-1, epoch=149, batch=0 train loss <loss>=6.45064115524\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] Epoch[149] Batch[5] avg_epoch_loss=6.087960\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] #quality_metric: host=algo-1, epoch=149, batch=5 train loss <loss>=6.08795968692\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] Epoch[149] Batch [5]#011Speed: 5300.48 samples/sec#011loss=6.087960\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] Epoch[149] Batch[10] avg_epoch_loss=5.827414\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] #quality_metric: host=algo-1, epoch=149, batch=10 train loss <loss>=5.51475977898\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] Epoch[149] Batch [10]#011Speed: 5027.58 samples/sec#011loss=5.514760\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 333.7380886077881, \"sum\": 333.7380886077881, \"min\": 333.7380886077881}}, \"EndTime\": 1614020088.876439, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020088.542265}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2006.90134689 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] #quality_metric: host=algo-1, epoch=149, train loss <loss>=5.82741427422\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:48 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] Epoch[150] Batch[0] avg_epoch_loss=6.238601\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] #quality_metric: host=algo-1, epoch=150, batch=0 train loss <loss>=6.23860120773\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] Epoch[150] Batch[5] avg_epoch_loss=5.954921\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] #quality_metric: host=algo-1, epoch=150, batch=5 train loss <loss>=5.95492092768\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] Epoch[150] Batch [5]#011Speed: 4553.47 samples/sec#011loss=5.954921\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 284.50703620910645, \"sum\": 284.50703620910645, \"min\": 284.50703620910645}}, \"EndTime\": 1614020089.161525, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020088.876511}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2213.21399585 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] #quality_metric: host=algo-1, epoch=150, train loss <loss>=6.06361379623\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] Epoch[151] Batch[0] avg_epoch_loss=6.071357\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] #quality_metric: host=algo-1, epoch=151, batch=0 train loss <loss>=6.07135725021\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] Epoch[151] Batch[5] avg_epoch_loss=6.242751\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] #quality_metric: host=algo-1, epoch=151, batch=5 train loss <loss>=6.24275120099\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] Epoch[151] Batch [5]#011Speed: 5071.96 samples/sec#011loss=6.242751\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 303.3449649810791, \"sum\": 303.3449649810791, \"min\": 303.3449649810791}}, \"EndTime\": 1614020089.465383, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020089.161603}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2102.43940443 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] #quality_metric: host=algo-1, epoch=151, train loss <loss>=6.02913379669\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] Epoch[152] Batch[0] avg_epoch_loss=6.386819\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] #quality_metric: host=algo-1, epoch=152, batch=0 train loss <loss>=6.38681936264\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] Epoch[152] Batch[5] avg_epoch_loss=5.877057\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] #quality_metric: host=algo-1, epoch=152, batch=5 train loss <loss>=5.87705715497\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] Epoch[152] Batch [5]#011Speed: 4139.12 samples/sec#011loss=5.877057\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] processed a total of 580 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 313.7929439544678, \"sum\": 313.7929439544678, \"min\": 313.7929439544678}}, \"EndTime\": 1614020089.779758, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020089.465464}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1847.68154237 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] #quality_metric: host=algo-1, epoch=152, train loss <loss>=6.05475893021\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] Epoch[153] Batch[0] avg_epoch_loss=6.249680\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:49 INFO 140707827689280] #quality_metric: host=algo-1, epoch=153, batch=0 train loss <loss>=6.24967956543\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] Epoch[153] Batch[5] avg_epoch_loss=5.867147\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] #quality_metric: host=algo-1, epoch=153, batch=5 train loss <loss>=5.86714736621\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] Epoch[153] Batch [5]#011Speed: 5285.41 samples/sec#011loss=5.867147\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] Epoch[153] Batch[10] avg_epoch_loss=5.643303\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] #quality_metric: host=algo-1, epoch=153, batch=10 train loss <loss>=5.37469067574\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] Epoch[153] Batch [10]#011Speed: 5038.98 samples/sec#011loss=5.374691\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 322.4501609802246, \"sum\": 322.4501609802246, \"min\": 322.4501609802246}}, \"EndTime\": 1614020090.102741, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020089.779834}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2012.03426981 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] #quality_metric: host=algo-1, epoch=153, train loss <loss>=5.64330341599\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] Epoch[154] Batch[0] avg_epoch_loss=6.293897\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] #quality_metric: host=algo-1, epoch=154, batch=0 train loss <loss>=6.29389667511\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] Epoch[154] Batch[5] avg_epoch_loss=6.242687\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] #quality_metric: host=algo-1, epoch=154, batch=5 train loss <loss>=6.24268698692\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] Epoch[154] Batch [5]#011Speed: 4893.87 samples/sec#011loss=6.242687\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] Epoch[154] Batch[10] avg_epoch_loss=6.380236\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] #quality_metric: host=algo-1, epoch=154, batch=10 train loss <loss>=6.54529399872\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] Epoch[154] Batch [10]#011Speed: 4870.18 samples/sec#011loss=6.545294\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 318.5131549835205, \"sum\": 318.5131549835205, \"min\": 318.5131549835205}}, \"EndTime\": 1614020090.421753, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020090.102815}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2018.07062289 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] #quality_metric: host=algo-1, epoch=154, train loss <loss>=6.38023562865\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] Epoch[155] Batch[0] avg_epoch_loss=5.778557\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] #quality_metric: host=algo-1, epoch=155, batch=0 train loss <loss>=5.77855730057\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] Epoch[155] Batch[5] avg_epoch_loss=5.906432\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] #quality_metric: host=algo-1, epoch=155, batch=5 train loss <loss>=5.90643207232\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] Epoch[155] Batch [5]#011Speed: 4783.91 samples/sec#011loss=5.906432\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 339.14709091186523, \"sum\": 339.14709091186523, \"min\": 339.14709091186523}}, \"EndTime\": 1614020090.761404, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020090.421827}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1830.48741825 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] #quality_metric: host=algo-1, epoch=155, train loss <loss>=5.88560538292\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] Epoch[156] Batch[0] avg_epoch_loss=5.509476\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:50 INFO 140707827689280] #quality_metric: host=algo-1, epoch=156, batch=0 train loss <loss>=5.50947618484\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] Epoch[156] Batch[5] avg_epoch_loss=5.810408\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] #quality_metric: host=algo-1, epoch=156, batch=5 train loss <loss>=5.81040843328\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] Epoch[156] Batch [5]#011Speed: 4344.22 samples/sec#011loss=5.810408\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] Epoch[156] Batch[10] avg_epoch_loss=5.627479\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] #quality_metric: host=algo-1, epoch=156, batch=10 train loss <loss>=5.40796260834\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] Epoch[156] Batch [10]#011Speed: 5287.16 samples/sec#011loss=5.407963\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 304.6989440917969, \"sum\": 304.6989440917969, \"min\": 304.6989440917969}}, \"EndTime\": 1614020091.066678, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020090.761472}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2116.09349738 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] #quality_metric: host=algo-1, epoch=156, train loss <loss>=5.62747851285\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] Saved checkpoint to \"/opt/ml/model/state_de501814-d66f-4851-a6aa-f030eacddabc-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 10.45083999633789, \"sum\": 10.45083999633789, \"min\": 10.45083999633789}}, \"EndTime\": 1614020091.077674, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020091.066752}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] Epoch[157] Batch[0] avg_epoch_loss=5.782831\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] #quality_metric: host=algo-1, epoch=157, batch=0 train loss <loss>=5.78283119202\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] Epoch[157] Batch[5] avg_epoch_loss=5.987662\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] #quality_metric: host=algo-1, epoch=157, batch=5 train loss <loss>=5.98766215642\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] Epoch[157] Batch [5]#011Speed: 4321.17 samples/sec#011loss=5.987662\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] Epoch[157] Batch[10] avg_epoch_loss=5.631343\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] #quality_metric: host=algo-1, epoch=157, batch=10 train loss <loss>=5.20376000404\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] Epoch[157] Batch [10]#011Speed: 4280.58 samples/sec#011loss=5.203760\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 364.04991149902344, \"sum\": 364.04991149902344, \"min\": 364.04991149902344}}, \"EndTime\": 1614020091.441835, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020091.077735}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1771.23280622 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] #quality_metric: host=algo-1, epoch=157, train loss <loss>=5.63134299625\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] Epoch[158] Batch[0] avg_epoch_loss=5.678819\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] #quality_metric: host=algo-1, epoch=158, batch=0 train loss <loss>=5.6788187027\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] Epoch[158] Batch[5] avg_epoch_loss=5.877331\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] #quality_metric: host=algo-1, epoch=158, batch=5 train loss <loss>=5.87733133634\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] Epoch[158] Batch [5]#011Speed: 4249.17 samples/sec#011loss=5.877331\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] Epoch[158] Batch[10] avg_epoch_loss=5.922733\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] #quality_metric: host=algo-1, epoch=158, batch=10 train loss <loss>=5.97721557617\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] Epoch[158] Batch [10]#011Speed: 4308.66 samples/sec#011loss=5.977216\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 327.833890914917, \"sum\": 327.833890914917, \"min\": 327.833890914917}}, \"EndTime\": 1614020091.770219, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020091.441909}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1972.8746206 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] #quality_metric: host=algo-1, epoch=158, train loss <loss>=5.92273326354\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] Epoch[159] Batch[0] avg_epoch_loss=5.994736\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:51 INFO 140707827689280] #quality_metric: host=algo-1, epoch=159, batch=0 train loss <loss>=5.99473619461\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] Epoch[159] Batch[5] avg_epoch_loss=6.091158\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] #quality_metric: host=algo-1, epoch=159, batch=5 train loss <loss>=6.09115791321\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] Epoch[159] Batch [5]#011Speed: 5374.90 samples/sec#011loss=6.091158\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 337.1310234069824, \"sum\": 337.1310234069824, \"min\": 337.1310234069824}}, \"EndTime\": 1614020092.107849, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020091.770294}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1841.4030579 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] #quality_metric: host=algo-1, epoch=159, train loss <loss>=5.96204504967\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] Epoch[160] Batch[0] avg_epoch_loss=5.676054\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] #quality_metric: host=algo-1, epoch=160, batch=0 train loss <loss>=5.67605352402\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] Epoch[160] Batch[5] avg_epoch_loss=6.051549\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] #quality_metric: host=algo-1, epoch=160, batch=5 train loss <loss>=6.05154935519\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] Epoch[160] Batch [5]#011Speed: 4826.17 samples/sec#011loss=6.051549\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] Epoch[160] Batch[10] avg_epoch_loss=5.771512\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] #quality_metric: host=algo-1, epoch=160, batch=10 train loss <loss>=5.43546800613\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] Epoch[160] Batch [10]#011Speed: 3963.93 samples/sec#011loss=5.435468\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 335.66999435424805, \"sum\": 335.66999435424805, \"min\": 335.66999435424805}}, \"EndTime\": 1614020092.444051, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020092.107925}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1947.70993475 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] #quality_metric: host=algo-1, epoch=160, train loss <loss>=5.77151237835\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] Epoch[161] Batch[0] avg_epoch_loss=6.017319\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] #quality_metric: host=algo-1, epoch=161, batch=0 train loss <loss>=6.01731920242\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] Epoch[161] Batch[5] avg_epoch_loss=5.947428\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] #quality_metric: host=algo-1, epoch=161, batch=5 train loss <loss>=5.94742846489\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] Epoch[161] Batch [5]#011Speed: 4003.11 samples/sec#011loss=5.947428\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] Epoch[161] Batch[10] avg_epoch_loss=6.089574\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] #quality_metric: host=algo-1, epoch=161, batch=10 train loss <loss>=6.26014928818\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] Epoch[161] Batch [10]#011Speed: 4385.73 samples/sec#011loss=6.260149\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] processed a total of 686 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 402.2550582885742, \"sum\": 402.2550582885742, \"min\": 402.2550582885742}}, \"EndTime\": 1614020092.846829, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020092.444125}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1705.02082261 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] #quality_metric: host=algo-1, epoch=161, train loss <loss>=6.08957429366\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:52 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] Epoch[162] Batch[0] avg_epoch_loss=5.770868\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] #quality_metric: host=algo-1, epoch=162, batch=0 train loss <loss>=5.77086830139\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] Epoch[162] Batch[5] avg_epoch_loss=6.108231\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] #quality_metric: host=algo-1, epoch=162, batch=5 train loss <loss>=6.10823074977\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] Epoch[162] Batch [5]#011Speed: 4648.20 samples/sec#011loss=6.108231\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] Epoch[162] Batch[10] avg_epoch_loss=5.906090\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] #quality_metric: host=algo-1, epoch=162, batch=10 train loss <loss>=5.6635216713\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] Epoch[162] Batch [10]#011Speed: 5175.82 samples/sec#011loss=5.663522\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 302.825927734375, \"sum\": 302.825927734375, \"min\": 302.825927734375}}, \"EndTime\": 1614020093.150117, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020092.846883}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2231.5167044 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] #quality_metric: host=algo-1, epoch=162, train loss <loss>=5.90609025955\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] Epoch[163] Batch[0] avg_epoch_loss=6.567984\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] #quality_metric: host=algo-1, epoch=163, batch=0 train loss <loss>=6.56798362732\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] Epoch[163] Batch[5] avg_epoch_loss=6.099247\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] #quality_metric: host=algo-1, epoch=163, batch=5 train loss <loss>=6.09924713771\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] Epoch[163] Batch [5]#011Speed: 4741.30 samples/sec#011loss=6.099247\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 289.76893424987793, \"sum\": 289.76893424987793, \"min\": 289.76893424987793}}, \"EndTime\": 1614020093.440439, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020093.150186}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2173.26097934 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] #quality_metric: host=algo-1, epoch=163, train loss <loss>=6.00586924553\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] Epoch[164] Batch[0] avg_epoch_loss=6.226917\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] #quality_metric: host=algo-1, epoch=164, batch=0 train loss <loss>=6.22691726685\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] Epoch[164] Batch[5] avg_epoch_loss=5.914350\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] #quality_metric: host=algo-1, epoch=164, batch=5 train loss <loss>=5.91434987386\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] Epoch[164] Batch [5]#011Speed: 4541.66 samples/sec#011loss=5.914350\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] processed a total of 602 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 310.60791015625, \"sum\": 310.60791015625, \"min\": 310.60791015625}}, \"EndTime\": 1614020093.751601, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020093.440519}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1937.49679293 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] #quality_metric: host=algo-1, epoch=164, train loss <loss>=6.11844372749\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] Epoch[165] Batch[0] avg_epoch_loss=6.197488\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] #quality_metric: host=algo-1, epoch=165, batch=0 train loss <loss>=6.19748783112\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] Epoch[165] Batch[5] avg_epoch_loss=5.874635\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] #quality_metric: host=algo-1, epoch=165, batch=5 train loss <loss>=5.8746351401\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:53 INFO 140707827689280] Epoch[165] Batch [5]#011Speed: 4292.37 samples/sec#011loss=5.874635\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] processed a total of 609 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 289.5491123199463, \"sum\": 289.5491123199463, \"min\": 289.5491123199463}}, \"EndTime\": 1614020094.0417, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020093.751666}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2102.45820404 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] #quality_metric: host=algo-1, epoch=165, train loss <loss>=5.8071788311\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] Epoch[166] Batch[0] avg_epoch_loss=5.693814\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] #quality_metric: host=algo-1, epoch=166, batch=0 train loss <loss>=5.69381380081\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] Epoch[166] Batch[5] avg_epoch_loss=5.925128\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] #quality_metric: host=algo-1, epoch=166, batch=5 train loss <loss>=5.92512830098\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] Epoch[166] Batch [5]#011Speed: 4809.64 samples/sec#011loss=5.925128\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] Epoch[166] Batch[10] avg_epoch_loss=5.761949\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] #quality_metric: host=algo-1, epoch=166, batch=10 train loss <loss>=5.56613454819\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] Epoch[166] Batch [10]#011Speed: 5151.50 samples/sec#011loss=5.566135\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 353.6410331726074, \"sum\": 353.6410331726074, \"min\": 353.6410331726074}}, \"EndTime\": 1614020094.395882, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020094.041777}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1834.63397071 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] #quality_metric: host=algo-1, epoch=166, train loss <loss>=5.76194932244\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] Epoch[167] Batch[0] avg_epoch_loss=5.574367\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] #quality_metric: host=algo-1, epoch=167, batch=0 train loss <loss>=5.57436656952\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] Epoch[167] Batch[5] avg_epoch_loss=6.007600\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] #quality_metric: host=algo-1, epoch=167, batch=5 train loss <loss>=6.00760030746\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] Epoch[167] Batch [5]#011Speed: 4753.34 samples/sec#011loss=6.007600\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 300.1389503479004, \"sum\": 300.1389503479004, \"min\": 300.1389503479004}}, \"EndTime\": 1614020094.696517, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020094.395956}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2031.66736413 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] #quality_metric: host=algo-1, epoch=167, train loss <loss>=5.81767725945\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] Epoch[168] Batch[0] avg_epoch_loss=6.331850\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] #quality_metric: host=algo-1, epoch=168, batch=0 train loss <loss>=6.33185005188\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] Epoch[168] Batch[5] avg_epoch_loss=5.947644\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] #quality_metric: host=algo-1, epoch=168, batch=5 train loss <loss>=5.94764359792\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:54 INFO 140707827689280] Epoch[168] Batch [5]#011Speed: 4850.61 samples/sec#011loss=5.947644\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] Epoch[168] Batch[10] avg_epoch_loss=5.927688\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] #quality_metric: host=algo-1, epoch=168, batch=10 train loss <loss>=5.90374126434\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] Epoch[168] Batch [10]#011Speed: 5319.41 samples/sec#011loss=5.903741\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 316.23101234436035, \"sum\": 316.23101234436035, \"min\": 316.23101234436035}}, \"EndTime\": 1614020095.013271, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020094.696589}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2064.22088052 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] #quality_metric: host=algo-1, epoch=168, train loss <loss>=5.92768799175\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] Epoch[169] Batch[0] avg_epoch_loss=6.489110\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] #quality_metric: host=algo-1, epoch=169, batch=0 train loss <loss>=6.48910999298\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] Epoch[169] Batch[5] avg_epoch_loss=6.155398\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] #quality_metric: host=algo-1, epoch=169, batch=5 train loss <loss>=6.15539844831\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] Epoch[169] Batch [5]#011Speed: 4429.55 samples/sec#011loss=6.155398\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 312.4549388885498, \"sum\": 312.4549388885498, \"min\": 312.4549388885498}}, \"EndTime\": 1614020095.326231, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020095.013347}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2037.9304451 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] #quality_metric: host=algo-1, epoch=169, train loss <loss>=6.10378861427\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] Epoch[170] Batch[0] avg_epoch_loss=5.634437\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=5.63443660736\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] Epoch[170] Batch[5] avg_epoch_loss=6.073667\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=6.07366665204\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] Epoch[170] Batch [5]#011Speed: 4637.81 samples/sec#011loss=6.073667\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] Epoch[170] Batch[10] avg_epoch_loss=5.832752\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] #quality_metric: host=algo-1, epoch=170, batch=10 train loss <loss>=5.54365420341\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] Epoch[170] Batch [10]#011Speed: 5270.18 samples/sec#011loss=5.543654\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 323.8179683685303, \"sum\": 323.8179683685303, \"min\": 323.8179683685303}}, \"EndTime\": 1614020095.6506, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020095.326311}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2003.50732666 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] #quality_metric: host=algo-1, epoch=170, train loss <loss>=5.83275190267\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] Epoch[171] Batch[0] avg_epoch_loss=5.697579\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=5.69757890701\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] Epoch[171] Batch[5] avg_epoch_loss=5.889078\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=5.88907798131\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] Epoch[171] Batch [5]#011Speed: 4618.74 samples/sec#011loss=5.889078\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] Epoch[171] Batch[10] avg_epoch_loss=5.884849\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] #quality_metric: host=algo-1, epoch=171, batch=10 train loss <loss>=5.87977323532\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] Epoch[171] Batch [10]#011Speed: 4885.71 samples/sec#011loss=5.879773\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 323.4591484069824, \"sum\": 323.4591484069824, \"min\": 323.4591484069824}}, \"EndTime\": 1614020095.974572, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020095.650677}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1999.53041315 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] #quality_metric: host=algo-1, epoch=171, train loss <loss>=5.88484855132\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:55 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] Epoch[172] Batch[0] avg_epoch_loss=6.206182\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=6.20618247986\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] Epoch[172] Batch[5] avg_epoch_loss=6.005004\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=6.00500408808\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] Epoch[172] Batch [5]#011Speed: 4375.89 samples/sec#011loss=6.005004\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 297.91784286499023, \"sum\": 297.91784286499023, \"min\": 297.91784286499023}}, \"EndTime\": 1614020096.273015, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020095.974654}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2147.50770009 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] #quality_metric: host=algo-1, epoch=172, train loss <loss>=6.11466388702\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] Epoch[173] Batch[0] avg_epoch_loss=6.171162\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=6.17116165161\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] Epoch[173] Batch[5] avg_epoch_loss=6.084804\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=6.08480374018\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] Epoch[173] Batch [5]#011Speed: 5325.26 samples/sec#011loss=6.084804\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] Epoch[173] Batch[10] avg_epoch_loss=5.918742\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] #quality_metric: host=algo-1, epoch=173, batch=10 train loss <loss>=5.71946878433\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] Epoch[173] Batch [10]#011Speed: 4360.03 samples/sec#011loss=5.719469\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 309.16500091552734, \"sum\": 309.16500091552734, \"min\": 309.16500091552734}}, \"EndTime\": 1614020096.582724, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020096.273083}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2150.30163608 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] #quality_metric: host=algo-1, epoch=173, train loss <loss>=5.91874239661\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] Epoch[174] Batch[0] avg_epoch_loss=6.602104\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=6.60210371017\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] Epoch[174] Batch[5] avg_epoch_loss=5.969212\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=5.96921213468\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] Epoch[174] Batch [5]#011Speed: 5309.46 samples/sec#011loss=5.969212\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] Epoch[174] Batch[10] avg_epoch_loss=5.945616\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] #quality_metric: host=algo-1, epoch=174, batch=10 train loss <loss>=5.91730098724\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] Epoch[174] Batch [10]#011Speed: 5295.65 samples/sec#011loss=5.917301\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] processed a total of 705 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 309.28802490234375, \"sum\": 309.28802490234375, \"min\": 309.28802490234375}}, \"EndTime\": 1614020096.892507, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020096.582783}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2278.62597432 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] #quality_metric: host=algo-1, epoch=174, train loss <loss>=6.16220239798\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:56 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] Epoch[175] Batch[0] avg_epoch_loss=5.821544\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=5.82154417038\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] Epoch[175] Batch[5] avg_epoch_loss=6.016895\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=6.01689521472\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] Epoch[175] Batch [5]#011Speed: 5248.74 samples/sec#011loss=6.016895\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] Epoch[175] Batch[10] avg_epoch_loss=6.146459\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] #quality_metric: host=algo-1, epoch=175, batch=10 train loss <loss>=6.30193471909\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] Epoch[175] Batch [10]#011Speed: 5121.31 samples/sec#011loss=6.301935\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 287.4281406402588, \"sum\": 287.4281406402588, \"min\": 287.4281406402588}}, \"EndTime\": 1614020097.180509, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020096.892577}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2236.23318392 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] #quality_metric: host=algo-1, epoch=175, train loss <loss>=6.14645862579\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] Epoch[176] Batch[0] avg_epoch_loss=6.314234\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=6.31423425674\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] Epoch[176] Batch[5] avg_epoch_loss=6.131970\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=6.1319697698\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] Epoch[176] Batch [5]#011Speed: 4695.72 samples/sec#011loss=6.131970\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 279.91294860839844, \"sum\": 279.91294860839844, \"min\": 279.91294860839844}}, \"EndTime\": 1614020097.460938, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020097.180581}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2264.10665323 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] #quality_metric: host=algo-1, epoch=176, train loss <loss>=6.04029569626\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] Epoch[177] Batch[0] avg_epoch_loss=6.767961\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] #quality_metric: host=algo-1, epoch=177, batch=0 train loss <loss>=6.7679605484\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] Epoch[177] Batch[5] avg_epoch_loss=6.314627\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] #quality_metric: host=algo-1, epoch=177, batch=5 train loss <loss>=6.31462661425\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] Epoch[177] Batch [5]#011Speed: 5163.45 samples/sec#011loss=6.314627\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] Epoch[177] Batch[10] avg_epoch_loss=6.005460\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] #quality_metric: host=algo-1, epoch=177, batch=10 train loss <loss>=5.63445906639\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] Epoch[177] Batch [10]#011Speed: 4269.50 samples/sec#011loss=5.634459\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 300.886869430542, \"sum\": 300.886869430542, \"min\": 300.886869430542}}, \"EndTime\": 1614020097.762402, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020097.461008}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2142.86309033 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] #quality_metric: host=algo-1, epoch=177, train loss <loss>=6.00545954704\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] Epoch[178] Batch[0] avg_epoch_loss=5.799686\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:57 INFO 140707827689280] #quality_metric: host=algo-1, epoch=178, batch=0 train loss <loss>=5.79968595505\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] Epoch[178] Batch[5] avg_epoch_loss=5.924887\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] #quality_metric: host=algo-1, epoch=178, batch=5 train loss <loss>=5.92488670349\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] Epoch[178] Batch [5]#011Speed: 5247.72 samples/sec#011loss=5.924887\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 312.9580020904541, \"sum\": 312.9580020904541, \"min\": 312.9580020904541}}, \"EndTime\": 1614020098.075888, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020097.762478}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2009.0584597 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] #quality_metric: host=algo-1, epoch=178, train loss <loss>=5.88245844841\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] Epoch[179] Batch[0] avg_epoch_loss=5.387805\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] #quality_metric: host=algo-1, epoch=179, batch=0 train loss <loss>=5.38780498505\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] Epoch[179] Batch[5] avg_epoch_loss=6.141788\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] #quality_metric: host=algo-1, epoch=179, batch=5 train loss <loss>=6.14178832372\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] Epoch[179] Batch [5]#011Speed: 5253.92 samples/sec#011loss=6.141788\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] Epoch[179] Batch[10] avg_epoch_loss=6.373981\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] #quality_metric: host=algo-1, epoch=179, batch=10 train loss <loss>=6.65261116028\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] Epoch[179] Batch [10]#011Speed: 5147.92 samples/sec#011loss=6.652611\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 302.95586585998535, \"sum\": 302.95586585998535, \"min\": 302.95586585998535}}, \"EndTime\": 1614020098.379385, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020098.075964}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2138.1328802 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] #quality_metric: host=algo-1, epoch=179, train loss <loss>=6.37398052216\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] Epoch[180] Batch[0] avg_epoch_loss=5.773910\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] #quality_metric: host=algo-1, epoch=180, batch=0 train loss <loss>=5.77391004562\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] Epoch[180] Batch[5] avg_epoch_loss=6.100671\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] #quality_metric: host=algo-1, epoch=180, batch=5 train loss <loss>=6.10067137082\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] Epoch[180] Batch [5]#011Speed: 5163.55 samples/sec#011loss=6.100671\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] Epoch[180] Batch[10] avg_epoch_loss=6.084297\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] #quality_metric: host=algo-1, epoch=180, batch=10 train loss <loss>=6.06464824677\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] Epoch[180] Batch [10]#011Speed: 4810.22 samples/sec#011loss=6.064648\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] processed a total of 677 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 313.40789794921875, \"sum\": 313.40789794921875, \"min\": 313.40789794921875}}, \"EndTime\": 1614020098.693307, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020098.37946}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2159.35875601 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] #quality_metric: host=algo-1, epoch=180, train loss <loss>=6.08429722352\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] Epoch[181] Batch[0] avg_epoch_loss=5.429780\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] #quality_metric: host=algo-1, epoch=181, batch=0 train loss <loss>=5.42978048325\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] Epoch[181] Batch[5] avg_epoch_loss=5.553994\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] #quality_metric: host=algo-1, epoch=181, batch=5 train loss <loss>=5.55399401983\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] Epoch[181] Batch [5]#011Speed: 5229.28 samples/sec#011loss=5.553994\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 285.9928607940674, \"sum\": 285.9928607940674, \"min\": 285.9928607940674}}, \"EndTime\": 1614020098.979869, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020098.693382}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2188.00852992 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] #quality_metric: host=algo-1, epoch=181, train loss <loss>=5.75469369888\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:58 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] Epoch[182] Batch[0] avg_epoch_loss=6.008093\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] #quality_metric: host=algo-1, epoch=182, batch=0 train loss <loss>=6.00809288025\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] Epoch[182] Batch[5] avg_epoch_loss=5.936229\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] #quality_metric: host=algo-1, epoch=182, batch=5 train loss <loss>=5.93622891108\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] Epoch[182] Batch [5]#011Speed: 5327.92 samples/sec#011loss=5.936229\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] Epoch[182] Batch[10] avg_epoch_loss=6.183097\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] #quality_metric: host=algo-1, epoch=182, batch=10 train loss <loss>=6.47933778763\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] Epoch[182] Batch [10]#011Speed: 4654.28 samples/sec#011loss=6.479338\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 296.7410087585449, \"sum\": 296.7410087585449, \"min\": 296.7410087585449}}, \"EndTime\": 1614020099.27713, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020098.979942}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2189.65129232 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] #quality_metric: host=algo-1, epoch=182, train loss <loss>=6.18309658224\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] Epoch[183] Batch[0] avg_epoch_loss=5.760100\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] #quality_metric: host=algo-1, epoch=183, batch=0 train loss <loss>=5.76010036469\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] Epoch[183] Batch[5] avg_epoch_loss=5.953124\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] #quality_metric: host=algo-1, epoch=183, batch=5 train loss <loss>=5.95312364896\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] Epoch[183] Batch [5]#011Speed: 5321.88 samples/sec#011loss=5.953124\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] Epoch[183] Batch[10] avg_epoch_loss=6.064207\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] #quality_metric: host=algo-1, epoch=183, batch=10 train loss <loss>=6.19750709534\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] Epoch[183] Batch [10]#011Speed: 4466.03 samples/sec#011loss=6.197507\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 311.2649917602539, \"sum\": 311.2649917602539, \"min\": 311.2649917602539}}, \"EndTime\": 1614020099.588896, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020099.277204}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2135.68914572 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] #quality_metric: host=algo-1, epoch=183, train loss <loss>=6.06420703368\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\n",
      "2021-02-22 18:55:13 Uploading - Uploading generated training model\n",
      "2021-02-22 18:55:13 Completed - Training job completed\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] Epoch[184] Batch[0] avg_epoch_loss=6.254968\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] #quality_metric: host=algo-1, epoch=184, batch=0 train loss <loss>=6.25496816635\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] Epoch[184] Batch[5] avg_epoch_loss=5.990637\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] #quality_metric: host=algo-1, epoch=184, batch=5 train loss <loss>=5.99063650767\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] Epoch[184] Batch [5]#011Speed: 4843.41 samples/sec#011loss=5.990637\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] Epoch[184] Batch[10] avg_epoch_loss=5.900124\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] #quality_metric: host=algo-1, epoch=184, batch=10 train loss <loss>=5.79150829315\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] Epoch[184] Batch [10]#011Speed: 3949.01 samples/sec#011loss=5.791508\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 339.86902236938477, \"sum\": 339.86902236938477, \"min\": 339.86902236938477}}, \"EndTime\": 1614020099.929264, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020099.58897}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1932.56890225 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] #quality_metric: host=algo-1, epoch=184, train loss <loss>=5.90012368289\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:54:59 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] Epoch[185] Batch[0] avg_epoch_loss=5.977178\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] #quality_metric: host=algo-1, epoch=185, batch=0 train loss <loss>=5.97717761993\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] Epoch[185] Batch[5] avg_epoch_loss=5.943094\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] #quality_metric: host=algo-1, epoch=185, batch=5 train loss <loss>=5.9430937767\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] Epoch[185] Batch [5]#011Speed: 3928.11 samples/sec#011loss=5.943094\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] Epoch[185] Batch[10] avg_epoch_loss=5.873898\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] #quality_metric: host=algo-1, epoch=185, batch=10 train loss <loss>=5.79086380005\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] Epoch[185] Batch [10]#011Speed: 4822.11 samples/sec#011loss=5.790864\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] processed a total of 687 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 323.26412200927734, \"sum\": 323.26412200927734, \"min\": 323.26412200927734}}, \"EndTime\": 1614020100.253038, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020099.929324}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2124.45448714 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] #quality_metric: host=algo-1, epoch=185, train loss <loss>=5.87389833277\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] Epoch[186] Batch[0] avg_epoch_loss=6.314520\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] #quality_metric: host=algo-1, epoch=186, batch=0 train loss <loss>=6.31452035904\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] Epoch[186] Batch[5] avg_epoch_loss=5.874634\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] #quality_metric: host=algo-1, epoch=186, batch=5 train loss <loss>=5.87463394801\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] Epoch[186] Batch [5]#011Speed: 4818.84 samples/sec#011loss=5.874634\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 295.5451011657715, \"sum\": 295.5451011657715, \"min\": 295.5451011657715}}, \"EndTime\": 1614020100.549093, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020100.253116}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2083.64383175 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] #quality_metric: host=algo-1, epoch=186, train loss <loss>=6.05368590355\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] Epoch[187] Batch[0] avg_epoch_loss=6.180181\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] #quality_metric: host=algo-1, epoch=187, batch=0 train loss <loss>=6.18018054962\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] Epoch[187] Batch[5] avg_epoch_loss=6.089290\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] #quality_metric: host=algo-1, epoch=187, batch=5 train loss <loss>=6.08929006259\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] Epoch[187] Batch [5]#011Speed: 5413.27 samples/sec#011loss=6.089290\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] Epoch[187] Batch[10] avg_epoch_loss=6.021550\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] #quality_metric: host=algo-1, epoch=187, batch=10 train loss <loss>=5.94026136398\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] Epoch[187] Batch [10]#011Speed: 4991.51 samples/sec#011loss=5.940261\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 300.40693283081055, \"sum\": 300.40693283081055, \"min\": 300.40693283081055}}, \"EndTime\": 1614020100.850052, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020100.549151}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2199.53520608 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] #quality_metric: host=algo-1, epoch=187, train loss <loss>=6.02154974504\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:00 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] Epoch[188] Batch[0] avg_epoch_loss=5.558436\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] #quality_metric: host=algo-1, epoch=188, batch=0 train loss <loss>=5.55843639374\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] Epoch[188] Batch[5] avg_epoch_loss=5.861295\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] #quality_metric: host=algo-1, epoch=188, batch=5 train loss <loss>=5.86129546165\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] Epoch[188] Batch [5]#011Speed: 4878.27 samples/sec#011loss=5.861295\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] Epoch[188] Batch[10] avg_epoch_loss=6.204191\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] #quality_metric: host=algo-1, epoch=188, batch=10 train loss <loss>=6.61566534042\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] Epoch[188] Batch [10]#011Speed: 4761.13 samples/sec#011loss=6.615665\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 352.186918258667, \"sum\": 352.186918258667, \"min\": 352.186918258667}}, \"EndTime\": 1614020101.202735, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020100.850126}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1833.7058134 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] #quality_metric: host=algo-1, epoch=188, train loss <loss>=6.2041908611\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] Epoch[189] Batch[0] avg_epoch_loss=6.537394\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] #quality_metric: host=algo-1, epoch=189, batch=0 train loss <loss>=6.53739404678\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] Epoch[189] Batch[5] avg_epoch_loss=5.981950\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] #quality_metric: host=algo-1, epoch=189, batch=5 train loss <loss>=5.98195036252\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] Epoch[189] Batch [5]#011Speed: 4756.61 samples/sec#011loss=5.981950\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] Epoch[189] Batch[10] avg_epoch_loss=6.296883\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] #quality_metric: host=algo-1, epoch=189, batch=10 train loss <loss>=6.67480230331\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] Epoch[189] Batch [10]#011Speed: 5250.20 samples/sec#011loss=6.674802\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 296.8440055847168, \"sum\": 296.8440055847168, \"min\": 296.8440055847168}}, \"EndTime\": 1614020101.500054, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020101.202807}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2161.97244647 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] #quality_metric: host=algo-1, epoch=189, train loss <loss>=6.29688306288\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] Epoch[190] Batch[0] avg_epoch_loss=5.865815\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] #quality_metric: host=algo-1, epoch=190, batch=0 train loss <loss>=5.86581516266\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] Epoch[190] Batch[5] avg_epoch_loss=6.183226\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] #quality_metric: host=algo-1, epoch=190, batch=5 train loss <loss>=6.18322563171\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] Epoch[190] Batch [5]#011Speed: 4301.53 samples/sec#011loss=6.183226\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] Epoch[190] Batch[10] avg_epoch_loss=6.311345\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] #quality_metric: host=algo-1, epoch=190, batch=10 train loss <loss>=6.46508769989\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] Epoch[190] Batch [10]#011Speed: 4289.94 samples/sec#011loss=6.465088\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 324.7041702270508, \"sum\": 324.7041702270508, \"min\": 324.7041702270508}}, \"EndTime\": 1614020101.825259, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020101.500127}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2080.47893105 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] #quality_metric: host=algo-1, epoch=190, train loss <loss>=6.31134475361\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:01 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] Epoch[191] Batch[0] avg_epoch_loss=6.469603\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] #quality_metric: host=algo-1, epoch=191, batch=0 train loss <loss>=6.46960258484\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] Epoch[191] Batch[5] avg_epoch_loss=5.976582\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] #quality_metric: host=algo-1, epoch=191, batch=5 train loss <loss>=5.97658173243\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] Epoch[191] Batch [5]#011Speed: 5120.41 samples/sec#011loss=5.976582\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 323.84490966796875, \"sum\": 323.84490966796875, \"min\": 323.84490966796875}}, \"EndTime\": 1614020102.150194, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020101.825421}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=1944.65551031 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] #quality_metric: host=algo-1, epoch=191, train loss <loss>=5.8892469883\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] Epoch[192] Batch[0] avg_epoch_loss=5.912282\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] #quality_metric: host=algo-1, epoch=192, batch=0 train loss <loss>=5.91228199005\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] Epoch[192] Batch[5] avg_epoch_loss=5.936866\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] #quality_metric: host=algo-1, epoch=192, batch=5 train loss <loss>=5.93686620394\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] Epoch[192] Batch [5]#011Speed: 4358.91 samples/sec#011loss=5.936866\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] Epoch[192] Batch[10] avg_epoch_loss=6.252021\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] #quality_metric: host=algo-1, epoch=192, batch=10 train loss <loss>=6.63020620346\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] Epoch[192] Batch [10]#011Speed: 4575.81 samples/sec#011loss=6.630206\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 322.08895683288574, \"sum\": 322.08895683288574, \"min\": 322.08895683288574}}, \"EndTime\": 1614020102.472853, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020102.150275}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2020.45987446 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] #quality_metric: host=algo-1, epoch=192, train loss <loss>=6.25202074918\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] Epoch[193] Batch[0] avg_epoch_loss=5.829720\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] #quality_metric: host=algo-1, epoch=193, batch=0 train loss <loss>=5.82972049713\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] Epoch[193] Batch[5] avg_epoch_loss=6.098138\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] #quality_metric: host=algo-1, epoch=193, batch=5 train loss <loss>=6.09813769658\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] Epoch[193] Batch [5]#011Speed: 5235.09 samples/sec#011loss=6.098138\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] Epoch[193] Batch[10] avg_epoch_loss=6.037403\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] #quality_metric: host=algo-1, epoch=193, batch=10 train loss <loss>=5.96452102661\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] Epoch[193] Batch [10]#011Speed: 4557.35 samples/sec#011loss=5.964521\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] processed a total of 682 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 302.5679588317871, \"sum\": 302.5679588317871, \"min\": 302.5679588317871}}, \"EndTime\": 1614020102.775957, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020102.472929}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2253.18151621 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] #quality_metric: host=algo-1, epoch=193, train loss <loss>=6.0374028466\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] Epoch[194] Batch[0] avg_epoch_loss=5.945376\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:02 INFO 140707827689280] #quality_metric: host=algo-1, epoch=194, batch=0 train loss <loss>=5.94537639618\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] Epoch[194] Batch[5] avg_epoch_loss=6.290021\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #quality_metric: host=algo-1, epoch=194, batch=5 train loss <loss>=6.29002141953\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] Epoch[194] Batch [5]#011Speed: 4409.89 samples/sec#011loss=6.290021\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] Epoch[194] Batch[10] avg_epoch_loss=5.749368\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #quality_metric: host=algo-1, epoch=194, batch=10 train loss <loss>=5.10058400631\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] Epoch[194] Batch [10]#011Speed: 5004.86 samples/sec#011loss=5.100584\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 303.9441108703613, \"sum\": 303.9441108703613, \"min\": 303.9441108703613}}, \"EndTime\": 1614020103.080395, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020102.776034}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2141.10886636 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #quality_metric: host=algo-1, epoch=194, train loss <loss>=5.74936804988\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] Epoch[195] Batch[0] avg_epoch_loss=5.938215\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #quality_metric: host=algo-1, epoch=195, batch=0 train loss <loss>=5.93821525574\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] Epoch[195] Batch[5] avg_epoch_loss=6.171831\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #quality_metric: host=algo-1, epoch=195, batch=5 train loss <loss>=6.17183057467\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] Epoch[195] Batch [5]#011Speed: 5334.40 samples/sec#011loss=6.171831\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] processed a total of 597 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 278.1989574432373, \"sum\": 278.1989574432373, \"min\": 278.1989574432373}}, \"EndTime\": 1614020103.35912, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020103.080464}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2145.03625146 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #quality_metric: host=algo-1, epoch=195, train loss <loss>=6.34115400314\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] Epoch[196] Batch[0] avg_epoch_loss=6.448211\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #quality_metric: host=algo-1, epoch=196, batch=0 train loss <loss>=6.44821071625\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] Epoch[196] Batch[5] avg_epoch_loss=5.804145\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #quality_metric: host=algo-1, epoch=196, batch=5 train loss <loss>=5.80414477984\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] Epoch[196] Batch [5]#011Speed: 4683.15 samples/sec#011loss=5.804145\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] processed a total of 589 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 283.17880630493164, \"sum\": 283.17880630493164, \"min\": 283.17880630493164}}, \"EndTime\": 1614020103.642886, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020103.359199}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #throughput_metric: host=algo-1, train throughput=2079.03019857 records/second\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #quality_metric: host=algo-1, epoch=196, train loss <loss>=6.06508779526\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] loss did not improve\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] Loading parameters from best epoch (156)\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.deserialize.time\": {\"count\": 1, \"max\": 5.132913589477539, \"sum\": 5.132913589477539, \"min\": 5.132913589477539}}, \"EndTime\": 1614020103.648675, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020103.642975}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] stopping training now\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] Final loss: 5.62747851285 (occurred at epoch 156)\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #quality_metric: host=algo-1, train final_loss <loss>=5.62747851285\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 WARNING 140707827689280] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 32.60612487792969, \"sum\": 32.60612487792969, \"min\": 32.60612487792969}}, \"EndTime\": 1614020103.682029, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020103.648719}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 47.94502258300781, \"sum\": 47.94502258300781, \"min\": 47.94502258300781}}, \"EndTime\": 1614020103.697334, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020103.682075}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 2.7129650115966797, \"sum\": 2.7129650115966797, \"min\": 2.7129650115966797}}, \"EndTime\": 1614020103.700144, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020103.697393}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.bind.time\": {\"count\": 1, \"max\": 0.03600120544433594, \"sum\": 0.03600120544433594, \"min\": 0.03600120544433594}}, \"EndTime\": 1614020103.700782, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020103.700186}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.score.time\": {\"count\": 1, \"max\": 280.12800216674805, \"sum\": 280.12800216674805, \"min\": 280.12800216674805}}, \"EndTime\": 1614020103.980874, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020103.70083}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #test_score (algo-1, RMSE): 4241.91318864\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #test_score (algo-1, mean_absolute_QuantileLoss): 58834.16579861111\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #test_score (algo-1, mean_wQuantileLoss): 0.02806108030066638\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #test_score (algo-1, wQuantileLoss[0.1]): 0.015219376811970928\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #test_score (algo-1, wQuantileLoss[0.2]): 0.019631643018982934\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #test_score (algo-1, wQuantileLoss[0.3]): 0.02594116813444708\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #test_score (algo-1, wQuantileLoss[0.4]): 0.027807997497432208\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #test_score (algo-1, wQuantileLoss[0.5]): 0.03365192344059907\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #test_score (algo-1, wQuantileLoss[0.6]): 0.037647788086832945\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #test_score (algo-1, wQuantileLoss[0.7]): 0.03536989231971151\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #test_score (algo-1, wQuantileLoss[0.8]): 0.032449726861442776\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #test_score (algo-1, wQuantileLoss[0.9]): 0.02483020653457795\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.0280610803007\u001b[0m\n",
      "\u001b[34m[02/22/2021 18:55:03 INFO 140707827689280] #quality_metric: host=algo-1, test RMSE <loss>=4241.91318864\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 63106.38499259949, \"sum\": 63106.38499259949, \"min\": 63106.38499259949}, \"setuptime\": {\"count\": 1, \"max\": 9.19198989868164, \"sum\": 9.19198989868164, \"min\": 9.19198989868164}}, \"EndTime\": 1614020103.988693, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1614020103.980959}\n",
      "\u001b[0m\n",
      "Training seconds: 126\n",
      "Billable seconds: 126\n",
      "CPU times: user 855 ms, sys: 60.7 ms, total: 916 ms\n",
      "Wall time: 4min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_channels = {\n",
    "    \"train\": train_path,\n",
    "    \"test\": test_path\n",
    "}\n",
    "\n",
    "estimator.fit(inputs=data_channels, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "structural-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/deepar_electricity/DeepAR-Electricity.ipynb\n",
    "class DeepARPredictor(sagemaker.predictor.Predictor):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(\n",
    "            *args,              \n",
    "            serializer=IdentitySerializer(content_type='application/json'),\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "    def predict(self, ts, cat=None, dynamic_feat=None, num_samples=100, return_samples=False, quantiles=['0.1', '0.5', '0.9']):\n",
    "        '''Requests the prediction of for the time series listed in `ts`, each with the (optional)\n",
    "        corresponding category listed in `cat`.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        ts (pandas.Series object) : The time series to predict\n",
    "        cat (int) : The group associated to the time series (default: None)\n",
    "        num_samples (int) : number of samples to compute at prediction time (default: 100)\n",
    "        return_samples : boolean indicating whether to include samples in the response (default: False)\n",
    "        quantiles : list of strings specifying the quantiles to compute (default: [\"0.1\", \"0.5\", \"0.9\"])\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        List of `pandas.DataFrame` objects, each containing the predictions.\n",
    "        '''\n",
    "        \n",
    "        prediction_time = ts.index[-1] + ts.index.freq\n",
    "        quantiles = [str(q) for q in quantiles]\n",
    "        req = self.__encode_request(ts, cat, dynamic_feat, num_samples, return_samples, quantiles)\n",
    "        res = super(DeepARPredictor, self).predict(req)\n",
    "        return self.__decode_response(res, ts.index.freq, prediction_time, return_samples)\n",
    "    \n",
    "    def __encode_request(self, ts, cat, dynamic_feat, num_samples, return_samples, quantiles):\n",
    "        instance = series_to_dict(ts, cat if cat is not None else None, dynamic_feat if dynamic_feat else None)\n",
    "        \n",
    "        configuration = {\n",
    "            \"num_samples\": num_samples,\n",
    "            \"output_types\": [\"quantiles\", \"samples\"] if return_samples else [\"quantiles\"],\n",
    "            \"quantiles\": quantiles\n",
    "        }\n",
    "        \n",
    "        http_request_data = {\n",
    "            \"instances\": [instance],\n",
    "            \"configuration\": configuration\n",
    "        }\n",
    "        \n",
    "        return json.dumps(http_request_data).encode('utf-8')\n",
    "    \n",
    "    def __decode_response(self, response, freq, prediction_time, return_samples):\n",
    "        # we only sent one time series so we only receive one in return\n",
    "        # however, if possible one will pass multiple time series as predictions will then be faster\n",
    "        predictions = json.loads(response.decode('utf-8'))['predictions'][0]\n",
    "        prediction_length = len(next(iter(predictions['quantiles'].values())))\n",
    "        prediction_index = pd.date_range(start=prediction_time, freq=freq, periods=prediction_length)\n",
    "        if return_samples:\n",
    "            dict_of_samples = {'sample_' + str(i): s for i, s in enumerate(predictions['samples'])}\n",
    "        else:\n",
    "            dict_of_samples = {}\n",
    "        return pd.DataFrame(data={**predictions['quantiles'], **dict_of_samples}, index=prediction_index)\n",
    "\n",
    "    def set_frequency(self, freq):\n",
    "        self.freq = freq\n",
    "        \n",
    "def encode_target(ts):\n",
    "    return [x if np.isfinite(x) else \"NaN\" for x in ts]        \n",
    "\n",
    "def series_to_dict(ts, cat=None, dynamic_feat=None):\n",
    "    '''Given a pandas.Series object, returns a dictionary encoding the time series.\n",
    "\n",
    "    Paramenters\n",
    "    -----------\n",
    "    ts : a pands.Series object with the target time series\n",
    "    cat : an integer indicating the time series category\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A dictionary\n",
    "    '''\n",
    "    \n",
    "    obj = {\"start\": str(ts.index[0]), \"target\": encode_target(ts)}\n",
    "    if cat is not None:\n",
    "        obj[\"cat\"] = cat\n",
    "    if dynamic_feat is not None:\n",
    "        obj[\"dynamic_feat\"] = dynamic_feat        \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-persian",
   "metadata": {},
   "source": [
    "# Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-flush",
   "metadata": {},
   "source": [
    "<img src='img/time-series-cross-validation.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "champion-chart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!CPU times: user 239 ms, sys: 12 ms, total: 251 ms\n",
      "Wall time: 6min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    predictor_cls=DeepARPredictor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "capital-marina",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mape = []\n",
    "for i in [20, 15, 10, 5]:\n",
    "    y_pred = predictor.predict(ts=ts.co2.iloc[:-i], quantiles=[0.10, 0.5, 0.90])\n",
    "    y_true = ts.co2.iloc[-i:].iloc[:5]\n",
    "\n",
    "    y_pred['0.5'].plot(ls='--', label='Prediction')\n",
    "    y_true.plot(label='Real')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    mape.append(np.mean(np.abs(y_true.values - y_pred['0.5'].values) / y_true.values) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "checked-limitation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE: 2.61\n"
     ]
    }
   ],
   "source": [
    "plt.boxplot(mape)\n",
    "plt.title('MAPE')\n",
    "plt.show()\n",
    "\n",
    "print('MAPE:', round(np.median(mape), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "exotic-rebate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>0.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>121852.375000</td>\n",
       "      <td>142414.796875</td>\n",
       "      <td>133337.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31</th>\n",
       "      <td>119931.054688</td>\n",
       "      <td>146639.250000</td>\n",
       "      <td>134327.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31</th>\n",
       "      <td>124009.210938</td>\n",
       "      <td>150208.718750</td>\n",
       "      <td>137953.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31</th>\n",
       "      <td>125330.742188</td>\n",
       "      <td>155582.765625</td>\n",
       "      <td>140860.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31</th>\n",
       "      <td>132758.031250</td>\n",
       "      <td>160360.375000</td>\n",
       "      <td>145655.890625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0.1     Prediction            0.5\n",
       "2020-12-31  121852.375000  142414.796875  133337.375000\n",
       "2021-12-31  119931.054688  146639.250000  134327.468750\n",
       "2022-12-31  124009.210938  150208.718750  137953.093750\n",
       "2023-12-31  125330.742188  155582.765625  140860.031250\n",
       "2024-12-31  132758.031250  160360.375000  145655.890625"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions\n",
    "y_pred = predictor.predict(ts=ts.co2, quantiles=[0.10, 0.5, 0.90])\n",
    "y_pred = y_pred.rename(columns={'0.9': 'Prediction'})\n",
    "y_pred "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-tackle",
   "metadata": {},
   "source": [
    "# Deploy predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "confirmed-sponsorship",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>CO2 emissions</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1750-12-31</td>\n",
       "      <td>46.755000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1751-12-31</td>\n",
       "      <td>46.755000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1752-12-31</td>\n",
       "      <td>46.770000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1753-12-31</td>\n",
       "      <td>46.770000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1754-12-31</td>\n",
       "      <td>46.790000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>142414.796875</td>\n",
       "      <td>142414.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146639.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150208.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155582.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160360.375000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Year  CO2 emissions     Prediction\n",
       "0   1750-12-31      46.755000            NaN\n",
       "1   1751-12-31      46.755000            NaN\n",
       "2   1752-12-31      46.770000            NaN\n",
       "3   1753-12-31      46.770000            NaN\n",
       "4   1754-12-31      46.790000            NaN\n",
       "..         ...            ...            ...\n",
       "270 2020-12-31  142414.796875  142414.796875\n",
       "271 2021-12-31            NaN  146639.250000\n",
       "272 2022-12-31            NaN  150208.718750\n",
       "273 2023-12-31            NaN  155582.765625\n",
       "274 2024-12-31            NaN  160360.375000\n",
       "\n",
       "[275 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data for visualization\n",
    "ts_slice = ts.rename(columns={'co2': 'CO2 emissions'})\n",
    "\n",
    "viz = ts_slice.merge(y_pred[['Prediction']], how='outer', left_index=True, right_index=True)\n",
    "viz = viz.reset_index().rename(columns={'index': 'Year'})\n",
    "viz.iloc[-5, 1] = viz.iloc[-5].Prediction\n",
    "viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "metric-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotly dashboard html file\n",
    "fig = px.line(viz, x='Year', y=viz.columns, title='Global carbon dioxide emission prediction - MAPE: {}%'.format(round(np.median(mape), 2)))\n",
    "\n",
    "fig.update_xaxes(\n",
    "    tickformat='%Y', \n",
    "    rangeslider_visible=True,\n",
    "    rangeselector=dict(\n",
    "        buttons=list([\n",
    "            dict(count=30, label='30 years', step='year', stepmode='backward'),\n",
    "            dict(step='all')\n",
    "        ])\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.write_html('website/file.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "voluntary-brook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-sa-east-1-072590943848/website/file.html'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload html file to s3 bucket\n",
    "website_key = os.path.join('website', 'file.html')\n",
    "sagemaker_session.upload_data(website_key, bucket=bucket, key_prefix='website')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "alike-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
